{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6610df5e00ef450f8b35deea9b6d76e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e86cda3ddc2249b7996fa2aee4798e98",
              "IPY_MODEL_2f7e636e59cc436aafb4c0efb4126e6c",
              "IPY_MODEL_2660d3d267d54ec2a611e1f120a5e281"
            ],
            "layout": "IPY_MODEL_727e6927a30d44dd9fb9a5a61c31efd2"
          }
        },
        "e86cda3ddc2249b7996fa2aee4798e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_896058637e8342d2af78c81842096c34",
            "placeholder": "​",
            "style": "IPY_MODEL_c73676aad3884fb09d23d49802de367a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2f7e636e59cc436aafb4c0efb4126e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_346d1b420dcb4071bf7a0f6f2ad14877",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47ec68ad0e4d46f8b659ff65bb883afc",
            "value": 48
          }
        },
        "2660d3d267d54ec2a611e1f120a5e281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c4ec092ad84c43a57d31b75351c407",
            "placeholder": "​",
            "style": "IPY_MODEL_0d8c980e30654cbea9118b6511d76997",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.82kB/s]"
          }
        },
        "727e6927a30d44dd9fb9a5a61c31efd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896058637e8342d2af78c81842096c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73676aad3884fb09d23d49802de367a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "346d1b420dcb4071bf7a0f6f2ad14877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ec68ad0e4d46f8b659ff65bb883afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1c4ec092ad84c43a57d31b75351c407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8c980e30654cbea9118b6511d76997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bf9019d3d8a41ffa09cd3ea8f0ae67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f0e55b40e3b48879d91232ea7d5af01",
              "IPY_MODEL_7f2d55cb139a478999c24195b33b804c",
              "IPY_MODEL_5fe59f2ae2434b9ca0fe549e71dbc3ae"
            ],
            "layout": "IPY_MODEL_a812b6731a654adf9761d9978cf540a6"
          }
        },
        "6f0e55b40e3b48879d91232ea7d5af01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4ee3dfb8c344849b547221b341df3e",
            "placeholder": "​",
            "style": "IPY_MODEL_a4d906db4ca74452864d2a5b612f044b",
            "value": "vocab.txt: 100%"
          }
        },
        "7f2d55cb139a478999c24195b33b804c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f806ec6218024a4e827b15185f8ed821",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daf7ab75a3f54765bb8d39c9c8dcbf15",
            "value": 231508
          }
        },
        "5fe59f2ae2434b9ca0fe549e71dbc3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4ce23d4adc24ffcad0bc2130ad1a05a",
            "placeholder": "​",
            "style": "IPY_MODEL_de37ca4e40e9468fbec84e6bd5ae1e26",
            "value": " 232k/232k [00:00&lt;00:00, 13.6MB/s]"
          }
        },
        "a812b6731a654adf9761d9978cf540a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4ee3dfb8c344849b547221b341df3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d906db4ca74452864d2a5b612f044b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f806ec6218024a4e827b15185f8ed821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf7ab75a3f54765bb8d39c9c8dcbf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4ce23d4adc24ffcad0bc2130ad1a05a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de37ca4e40e9468fbec84e6bd5ae1e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d7ae2ab52b9433eb0e02e03d3b9508f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c70329522b3c4f4db7ff4d4b58728b32",
              "IPY_MODEL_bac60db82a834c50b38c6d5cf6b25182",
              "IPY_MODEL_7dc9f493438e4577bbe62bed52ef5120"
            ],
            "layout": "IPY_MODEL_0a8e4ff1cc6d4d17a3a86f6f17ec48e8"
          }
        },
        "c70329522b3c4f4db7ff4d4b58728b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56cbcbe521514f85b70f47eeae1aedd2",
            "placeholder": "​",
            "style": "IPY_MODEL_771bf7da481a4577b3abc66930a36278",
            "value": "tokenizer.json: 100%"
          }
        },
        "bac60db82a834c50b38c6d5cf6b25182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2204159af1b343ef8133e352c7a910c9",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ac316916b634c8c91725d2459dc2b84",
            "value": 466062
          }
        },
        "7dc9f493438e4577bbe62bed52ef5120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5988fb319413433abd84ddab1446363e",
            "placeholder": "​",
            "style": "IPY_MODEL_f21d08ad2796433fa1c9fd4dcbf8bcfd",
            "value": " 466k/466k [00:00&lt;00:00, 2.17MB/s]"
          }
        },
        "0a8e4ff1cc6d4d17a3a86f6f17ec48e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56cbcbe521514f85b70f47eeae1aedd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "771bf7da481a4577b3abc66930a36278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2204159af1b343ef8133e352c7a910c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac316916b634c8c91725d2459dc2b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5988fb319413433abd84ddab1446363e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21d08ad2796433fa1c9fd4dcbf8bcfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d6e9c9763b042eaa6b922ff7ba31b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d3840be44de4c1288c36fe7992abf66",
              "IPY_MODEL_e03bce75fb0c4ab69b06f882aa451c38",
              "IPY_MODEL_e058ee88390c46e290975ba633a24028"
            ],
            "layout": "IPY_MODEL_f9f8de25f93044ad8820a45caec309e7"
          }
        },
        "4d3840be44de4c1288c36fe7992abf66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a524128696d04a45a0a2eebf2bbbbfee",
            "placeholder": "​",
            "style": "IPY_MODEL_7e947faff16a4c11a43d820b64d93ef0",
            "value": "config.json: 100%"
          }
        },
        "e03bce75fb0c4ab69b06f882aa451c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b56298b0f14eb8a1d8994de9433986",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36329af01c654b1da6c152e6d161ade5",
            "value": 483
          }
        },
        "e058ee88390c46e290975ba633a24028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90852755c3ce41909967f9dd8abf16c8",
            "placeholder": "​",
            "style": "IPY_MODEL_92c7efc2685f480180d4e54af92023e4",
            "value": " 483/483 [00:00&lt;00:00, 56.9kB/s]"
          }
        },
        "f9f8de25f93044ad8820a45caec309e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a524128696d04a45a0a2eebf2bbbbfee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e947faff16a4c11a43d820b64d93ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4b56298b0f14eb8a1d8994de9433986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36329af01c654b1da6c152e6d161ade5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90852755c3ce41909967f9dd8abf16c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92c7efc2685f480180d4e54af92023e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a13e072b7394e079b56c3593d1b0184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8adfd5f1386541178ee41dfd9d971d82",
              "IPY_MODEL_4f4b7210d5e747f5a8d937146ca8e092",
              "IPY_MODEL_631f9be5c4b0496d985d02ec186195b7"
            ],
            "layout": "IPY_MODEL_1f7d1ac03fc04c38a5f1ccc694596638"
          }
        },
        "8adfd5f1386541178ee41dfd9d971d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6023f81ea5f4101879f48d19f7497c3",
            "placeholder": "​",
            "style": "IPY_MODEL_7144152647364ee69f570d61b7c499f1",
            "value": "model.safetensors: 100%"
          }
        },
        "4f4b7210d5e747f5a8d937146ca8e092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa68c89f7e424d26ae70a61673e8ddd5",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9896052da0584d73a606865fb70f151d",
            "value": 267954768
          }
        },
        "631f9be5c4b0496d985d02ec186195b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d1645139f24203b08f698f6e1ff20d",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a8132341d942b9a67998b2600a5fff",
            "value": " 268M/268M [00:01&lt;00:00, 213MB/s]"
          }
        },
        "1f7d1ac03fc04c38a5f1ccc694596638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6023f81ea5f4101879f48d19f7497c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7144152647364ee69f570d61b7c499f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa68c89f7e424d26ae70a61673e8ddd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9896052da0584d73a606865fb70f151d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74d1645139f24203b08f698f6e1ff20d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a8132341d942b9a67998b2600a5fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Check installed versions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkRPxqk29AR5",
        "outputId": "34864cfa-20d0-49d7-c729-7dd167c75db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELjIw61S9ADY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "1Eu0vJ816wot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbsVs9L-8knF",
        "outputId": "debb7132-5f75-4748-8705-f2f838c5294a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define possible values with expanded cities\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_durations = ['1-7 days', '8-30 days', 'More than 30 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "data = {\n",
        "    'email': ['email@example.com'] * n_samples,\n",
        "    'phone_provided': np.random.choice(possible_phone, n_samples),\n",
        "    'currentCity': np.random.choice(possible_cities, n_samples),\n",
        "    'targetCity': np.random.choice(possible_cities, n_samples),\n",
        "    'startDate': np.random.choice(possible_start_dates, n_samples),\n",
        "    'duration': np.random.choice(possible_durations, n_samples),\n",
        "    'budget': np.random.choice(possible_budgets, n_samples),\n",
        "    'income': np.random.choice(possible_incomes, n_samples),\n",
        "    'lifestyle': np.random.choice(possible_lifestyles, n_samples),\n",
        "    'distance': np.random.choice(possible_distances, n_samples),\n",
        "    'safety': np.random.choice(possible_safeties, n_samples),\n",
        "    'pagesVisited': [list(np.random.choice(possible_pages, np.random.randint(0, 7), replace=False)) for _ in range(n_samples)],\n",
        "    'foodPreferences': [list(np.random.choice(possible_food, np.random.randint(0, 4), replace=False)) for _ in range(n_samples)],\n",
        "    'transportType': [list(np.random.choice(possible_transport, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "    'accommodationType': [list(np.random.choice(possible_accommodation, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set phone based on phone_provided\n",
        "df['phone'] = df['phone_provided'].apply(lambda x: '1234567890' if x == 'Yes' else '')\n",
        "\n",
        "# Compute numerical features\n",
        "df['pages_visited'] = df['pagesVisited'].apply(lambda x: min(len(set(x) & set(key_pages)), 3))\n",
        "df['preferences_specified'] = (df['foodPreferences'].apply(len) +\n",
        "                               df['transportType'].apply(len) +\n",
        "                               df['accommodationType'].apply(len))\n",
        "\n",
        "# Define scoring functions (unchanged from original)\n",
        "def target_city_score(x):\n",
        "    return 15 if x != 'Not specified' else 0\n",
        "\n",
        "def start_date_score(x):\n",
        "    if x == 'Within 30 days':\n",
        "        return 25\n",
        "    elif x == '31-90 days':\n",
        "        return 15\n",
        "    elif x == 'More than 90 days':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def budget_score(x):\n",
        "    if x == 'High':\n",
        "        return 15\n",
        "    elif x == 'Medium':\n",
        "        return 10\n",
        "    elif x == 'Low':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def engagement_score(pages, preferences):\n",
        "    pages_score = min(pages * 3, 9)\n",
        "    preferences_score = min(preferences * 1, 5)\n",
        "    return pages_score + preferences_score\n",
        "\n",
        "def contact_score(x):\n",
        "    return 5 if x == 'Yes' else 0\n",
        "\n",
        "def distance_score(x):\n",
        "    if x == 'Long':\n",
        "        return 10\n",
        "    elif x == 'Medium':\n",
        "        return 5\n",
        "    elif x == 'Short':\n",
        "        return 2\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def safety_score(x):\n",
        "    if x == 'High':\n",
        "        return 10\n",
        "    elif x == 'Medium':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def income_score(x):\n",
        "    if x == 'High':\n",
        "        return 5\n",
        "    elif x == 'Medium':\n",
        "        return 3\n",
        "    elif x == 'Low':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def lifestyle_score(x):\n",
        "    if x == 'Luxury':\n",
        "        return 5\n",
        "    elif x == 'Active':\n",
        "        return 3\n",
        "    elif x == 'Relaxed':\n",
        "        return 2\n",
        "    elif x == 'Budget':\n",
        "        return 1\n",
        "\n",
        "# Apply scoring\n",
        "df['target_city_score'] = df['targetCity'].apply(target_city_score)\n",
        "df['start_date_score'] = df['startDate'].apply(start_date_score)\n",
        "df['budget_score'] = df['budget'].apply(budget_score)\n",
        "df['engagement_score'] = df.apply(lambda row: engagement_score(row['pages_visited'], row['preferences_specified']), axis=1)\n",
        "df['contact_score'] = df['phone_provided'].apply(contact_score)\n",
        "df['distance_score'] = df['distance'].apply(distance_score)\n",
        "df['safety_score'] = df['safety'].apply(safety_score)\n",
        "df['income_score'] = df['income'].apply(income_score)\n",
        "df['lifestyle_score'] = df['lifestyle'].apply(lifestyle_score)\n",
        "\n",
        "df['total_score'] = df[['target_city_score', 'start_date_score', 'budget_score', 'engagement_score',\n",
        "                        'contact_score', 'distance_score', 'safety_score', 'income_score', 'lifestyle_score']].sum(axis=1)"
      ],
      "metadata": {
        "id": "3asTYG_f6z5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for machine learning\n",
        "categorical_features = ['targetCity', 'startDate', 'budget', 'phone_provided', 'distance', 'safety', 'income', 'lifestyle']\n",
        "numerical_features = ['pages_visited', 'preferences_specified']\n",
        "X = df[categorical_features + numerical_features]\n",
        "y = df['total_score']\n",
        "\n",
        "# Define preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5JGvJYyV67t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
        "print(f\"Cross-Validation R-squared Scores: {cv_scores}\")\n",
        "print(f\"Mean CV R-squared: {np.mean(cv_scores):.2f}\")\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YMGxSzSy6-1j",
        "outputId": "7042151d-0fd5-4347-b070-fa7a2a5f8bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation R-squared Scores: [0.85877313 0.89215336 0.86587257 0.8892396  0.87907982]\n",
            "Mean CV R-squared: 0.88\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('cat',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                  ['targetCity', 'startDate',\n",
              "                                                   'budget', 'phone_provided',\n",
              "                                                   'distance', 'safety',\n",
              "                                                   'income', 'lifestyle']),\n",
              "                                                 ('num', 'passthrough',\n",
              "                                                  ['pages_visited',\n",
              "                                                   'preferences_specified'])])),\n",
              "                ('regressor', RandomForestRegressor(random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;targetCity&#x27;, &#x27;startDate&#x27;,\n",
              "                                                   &#x27;budget&#x27;, &#x27;phone_provided&#x27;,\n",
              "                                                   &#x27;distance&#x27;, &#x27;safety&#x27;,\n",
              "                                                   &#x27;income&#x27;, &#x27;lifestyle&#x27;]),\n",
              "                                                 (&#x27;num&#x27;, &#x27;passthrough&#x27;,\n",
              "                                                  [&#x27;pages_visited&#x27;,\n",
              "                                                   &#x27;preferences_specified&#x27;])])),\n",
              "                (&#x27;regressor&#x27;, RandomForestRegressor(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;targetCity&#x27;, &#x27;startDate&#x27;,\n",
              "                                                   &#x27;budget&#x27;, &#x27;phone_provided&#x27;,\n",
              "                                                   &#x27;distance&#x27;, &#x27;safety&#x27;,\n",
              "                                                   &#x27;income&#x27;, &#x27;lifestyle&#x27;]),\n",
              "                                                 (&#x27;num&#x27;, &#x27;passthrough&#x27;,\n",
              "                                                  [&#x27;pages_visited&#x27;,\n",
              "                                                   &#x27;preferences_specified&#x27;])])),\n",
              "                (&#x27;regressor&#x27;, RandomForestRegressor(random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;targetCity&#x27;, &#x27;startDate&#x27;, &#x27;budget&#x27;,\n",
              "                                  &#x27;phone_provided&#x27;, &#x27;distance&#x27;, &#x27;safety&#x27;,\n",
              "                                  &#x27;income&#x27;, &#x27;lifestyle&#x27;]),\n",
              "                                (&#x27;num&#x27;, &#x27;passthrough&#x27;,\n",
              "                                 [&#x27;pages_visited&#x27;, &#x27;preferences_specified&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;targetCity&#x27;, &#x27;startDate&#x27;, &#x27;budget&#x27;, &#x27;phone_provided&#x27;, &#x27;distance&#x27;, &#x27;safety&#x27;, &#x27;income&#x27;, &#x27;lifestyle&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;pages_visited&#x27;, &#x27;preferences_specified&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(random_state=42)</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CMy5Re77CDJ",
        "outputId": "c0ebbddc-98c1-4ee9-a3f5-f32b586e71e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 22.71\n",
            "R-squared: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show sample predictions\n",
        "print(\"\\nSample Predictions:\")\n",
        "for actual, predicted in list(zip(y_test, y_pred))[:5]:\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AgYhHSa7EDP",
        "outputId": "5970aba6-bf3b-4369-dbc3-16d97ad06e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Predictions:\n",
            "Actual Score: 55, Predicted Score: 50.67\n",
            "Actual Score: 39, Predicted Score: 45.70\n",
            "Actual Score: 82, Predicted Score: 78.49\n",
            "Actual Score: 25, Predicted Score: 31.44\n",
            "Actual Score: 76, Predicted Score: 75.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method 2**"
      ],
      "metadata": {
        "id": "24RUkOZe-CEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check installed versions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "\n",
        "# Install xgboost and joblib if not present\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    import joblib\n",
        "except ImportError:\n",
        "    !pip install xgboost joblib\n",
        "    import xgboost as xgb\n",
        "    import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define possible values with expanded Indian cities\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_durations = ['1-7 days', '8-30 days', 'More than 30 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Generate synthetic data (larger dataset)\n",
        "np.random.seed(42)\n",
        "n_samples = 10000  # Increased from 1000 to 10000\n",
        "data = {\n",
        "    'email': ['email@example.com'] * n_samples,\n",
        "    'phone_provided': np.random.choice(possible_phone, n_samples),\n",
        "    'currentCity': np.random.choice(possible_cities, n_samples),\n",
        "    'targetCity': np.random.choice(possible_cities, n_samples),\n",
        "    'startDate': np.random.choice(possible_start_dates, n_samples),\n",
        "    'duration': np.random.choice(possible_durations, n_samples),\n",
        "    'budget': np.random.choice(possible_budgets, n_samples),\n",
        "    'income': np.random.choice(possible_incomes, n_samples),\n",
        "    'lifestyle': np.random.choice(possible_lifestyles, n_samples),\n",
        "    'distance': np.random.choice(possible_distances, n_samples),\n",
        "    'safety': np.random.choice(possible_safeties, n_samples),\n",
        "    'pagesVisited': [list(np.random.choice(possible_pages, np.random.randint(0, 7), replace=False)) for _ in range(n_samples)],\n",
        "    'foodPreferences': [list(np.random.choice(possible_food, np.random.randint(0, 4), replace=False)) for _ in range(n_samples)],\n",
        "    'transportType': [list(np.random.choice(possible_transport, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "    'accommodationType': [list(np.random.choice(possible_accommodation, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set phone based on phone_provided\n",
        "df['phone'] = df['phone_provided'].apply(lambda x: '1234567890' if x == 'Yes' else '')\n",
        "\n",
        "# Compute numerical features\n",
        "df['pages_visited'] = df['pagesVisited'].apply(lambda x: min(len(set(x) & set(key_pages)), 3))\n",
        "df['preferences_specified'] = (df['foodPreferences'].apply(len) +\n",
        "                               df['transportType'].apply(len) +\n",
        "                               df['accommodationType'].apply(len))\n",
        "\n",
        "# Define scoring functions\n",
        "def target_city_score(x):\n",
        "    return 15 if x != 'Not specified' else 0\n",
        "\n",
        "def start_date_score(x):\n",
        "    if x == 'Within 30 days':\n",
        "        return 25\n",
        "    elif x == '31-90 days':\n",
        "        return 15\n",
        "    elif x == 'More than 90 days':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def budget_score(x):\n",
        "    if x == 'High':\n",
        "        return 15\n",
        "    elif x == 'Medium':\n",
        "        return 10\n",
        "    elif x == 'Low':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def engagement_score(pages, preferences):\n",
        "    pages_score = min(pages * 3, 9)\n",
        "    preferences_score = min(preferences * 1, 5)\n",
        "    return pages_score + preferences_score\n",
        "\n",
        "def contact_score(x):\n",
        "    return 5 if x == 'Yes' else 0\n",
        "\n",
        "def distance_score(x):\n",
        "    if x == 'Long':\n",
        "        return 10\n",
        "    elif x == 'Medium':\n",
        "        return 5\n",
        "    elif x == 'Short':\n",
        "        return 2\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def safety_score(x):\n",
        "    if x == 'High':\n",
        "        return 10\n",
        "    elif x == 'Medium':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def income_score(x):\n",
        "    if x == 'High':\n",
        "        return 5\n",
        "    elif x == 'Medium':\n",
        "        return 3\n",
        "    elif x == 'Low':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def lifestyle_score(x):\n",
        "    if x == 'Luxury':\n",
        "        return 5\n",
        "    elif x == 'Active':\n",
        "        return 3\n",
        "    elif x == 'Relaxed':\n",
        "        return 2\n",
        "    elif x == 'Budget':\n",
        "        return 1\n",
        "\n",
        "# Apply scoring\n",
        "df['target_city_score'] = df['targetCity'].apply(target_city_score)\n",
        "df['start_date_score'] = df['startDate'].apply(start_date_score)\n",
        "df['budget_score'] = df['budget'].apply(budget_score)\n",
        "df['engagement_score'] = df.apply(lambda row: engagement_score(row['pages_visited'], row['preferences_specified']), axis=1)\n",
        "df['contact_score'] = df['phone_provided'].apply(contact_score)\n",
        "df['distance_score'] = df['distance'].apply(distance_score)\n",
        "df['safety_score'] = df['safety'].apply(safety_score)\n",
        "df['income_score'] = df['income'].apply(income_score)\n",
        "df['lifestyle_score'] = df['lifestyle'].apply(lifestyle_score)\n",
        "\n",
        "df['total_score'] = df[['target_city_score', 'start_date_score', 'budget_score', 'engagement_score',\n",
        "                        'contact_score', 'distance_score', 'safety_score', 'income_score', 'lifestyle_score']].sum(axis=1)\n",
        "\n",
        "# Prepare data for machine learning\n",
        "categorical_features = ['targetCity', 'startDate', 'budget', 'phone_provided', 'distance', 'safety', 'income', 'lifestyle']\n",
        "numerical_features = ['pages_visited', 'preferences_specified']\n",
        "X = df[categorical_features + numerical_features]\n",
        "y = df['total_score']\n",
        "\n",
        "# Define preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the model with XGBoost\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', xgb.XGBRegressor(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
        "print(f\"Cross-Validation R-squared Scores: {cv_scores}\")\n",
        "print(f\"Mean CV R-squared: {np.mean(cv_scores):.2f}\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")\n",
        "\n",
        "# Show sample predictions\n",
        "print(\"\\nSample Predictions:\")\n",
        "for actual, predicted in list(zip(y_test[:5], y_pred[:5])):\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'lead_scoring_model.pkl')\n",
        "print(\"Model saved as 'lead_scoring_model.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieJqAnaW9Zzy",
        "outputId": "7d708447-5e4e-4f52-fb93-d55610b2e8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 1.6.1\n",
            "Cross-Validation R-squared Scores: [0.99588376 0.99527973 0.99578726 0.99586928 0.99557757]\n",
            "Mean CV R-squared: 1.00\n",
            "Mean Squared Error: 0.60\n",
            "R-squared: 1.00\n",
            "\n",
            "Sample Predictions:\n",
            "Actual Score: 41, Predicted Score: 41.62\n",
            "Actual Score: 74, Predicted Score: 74.73\n",
            "Actual Score: 49, Predicted Score: 49.71\n",
            "Actual Score: 49, Predicted Score: 48.88\n",
            "Actual Score: 58, Predicted Score: 57.62\n",
            "Model saved as 'lead_scoring_model.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load the saved model\n",
        "model = joblib.load('lead_scoring_model.pkl')\n",
        "print(\"Model loaded successfully\")\n",
        "\n",
        "# Define possible values (must match training script)\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Example input data to match your sample predictions\n",
        "sample_data = [\n",
        "    {'targetCity': 'Bangalore', 'startDate': 'Within 30 days', 'budget': 'Medium', 'phone_provided': 'Yes',\n",
        "     'distance': 'Medium', 'safety': 'High', 'income': 'Medium', 'lifestyle': 'Active',\n",
        "     'pages_visited': 2, 'preferences_specified': 3},  # Should predict ~55\n",
        "    {'targetCity': 'Mumbai', 'startDate': '31-90 days', 'budget': 'Low', 'phone_provided': 'No',\n",
        "     'distance': 'Short', 'safety': 'Medium', 'income': 'Low', 'lifestyle': 'Budget',\n",
        "     'pages_visited': 1, 'preferences_specified': 2},  # Should predict ~39\n",
        "    {'targetCity': 'New Delhi', 'startDate': 'Within 30 days', 'budget': 'High', 'phone_provided': 'Yes',\n",
        "     'distance': 'Long', 'safety': 'High', 'income': 'High', 'lifestyle': 'Luxury',\n",
        "     'pages_visited': 3, 'preferences_specified': 5},  # Should predict ~82\n",
        "    {'targetCity': 'Not specified', 'startDate': 'More than 90 days', 'budget': 'Low', 'phone_provided': 'No',\n",
        "     'distance': 'Short', 'safety': 'Low', 'income': 'Low', 'lifestyle': 'Budget',\n",
        "     'pages_visited': 0, 'preferences_specified': 1},  # Should predict ~25\n",
        "    {'targetCity': 'Hyderabad', 'startDate': 'Within 30 days', 'budget': 'High', 'phone_provided': 'Yes',\n",
        "     'distance': 'Medium', 'safety': 'Medium', 'income': 'Medium', 'lifestyle': 'Relaxed',\n",
        "     'pages_visited': 3, 'preferences_specified': 4},  # Should predict ~76\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "sample_df = pd.DataFrame(sample_data)\n",
        "\n",
        "# Predict scores\n",
        "predictions = model.predict(sample_df)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nSample Predictions:\")\n",
        "for actual, predicted in zip([55, 39, 82, 25, 76], predictions):\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycLM7fgB-MnY",
        "outputId": "1889b2cf-90f9-4b51-ef1c-47b93fbcebc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n",
            "\n",
            "Sample Predictions:\n",
            "Actual Score: 55, Predicted Score: 83.56\n",
            "Actual Score: 39, Predicted Score: 49.69\n",
            "Actual Score: 82, Predicted Score: 100.74\n",
            "Actual Score: 25, Predicted Score: 19.59\n",
            "Actual Score: 76, Predicted Score: 87.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method 3**"
      ],
      "metadata": {
        "id": "nyr52Oeq-o1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check installed versions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Import required modules\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Define possible values with expanded Indian cities\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_durations = ['1-7 days', '8-30 days', 'More than 30 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Generate synthetic data (larger dataset)\n",
        "np.random.seed(42)\n",
        "n_samples = 10000  # 10,000 samples\n",
        "data = {\n",
        "    'email': ['email@example.com'] * n_samples,\n",
        "    'phone_provided': np.random.choice(possible_phone, n_samples),\n",
        "    'currentCity': np.random.choice(possible_cities, n_samples),\n",
        "    'targetCity': np.random.choice(possible_cities, n_samples),\n",
        "    'startDate': np.random.choice(possible_start_dates, n_samples),\n",
        "    'duration': np.random.choice(possible_durations, n_samples),\n",
        "    'budget': np.random.choice(possible_budgets, n_samples),\n",
        "    'income': np.random.choice(possible_incomes, n_samples),\n",
        "    'lifestyle': np.random.choice(possible_lifestyles, n_samples),\n",
        "    'distance': np.random.choice(possible_distances, n_samples),\n",
        "    'safety': np.random.choice(possible_safeties, n_samples),\n",
        "    'pagesVisited': [list(np.random.choice(possible_pages, np.random.randint(0, 7), replace=False)) for _ in range(n_samples)],\n",
        "    'foodPreferences': [list(np.random.choice(possible_food, np.random.randint(0, 4), replace=False)) for _ in range(n_samples)],\n",
        "    'transportType': [list(np.random.choice(possible_transport, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "    'accommodationType': [list(np.random.choice(possible_accommodation, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set phone based on phone_provided\n",
        "df['phone'] = df['phone_provided'].apply(lambda x: '1234567890' if x == 'Yes' else '')\n",
        "\n",
        "# Compute numerical features\n",
        "df['pages_visited'] = df['pagesVisited'].apply(lambda x: min(len(set(x) & set(key_pages)), 3))\n",
        "df['preferences_specified'] = (df['foodPreferences'].apply(len) +\n",
        "                               df['transportType'].apply(len) +\n",
        "                               df['accommodationType'].apply(len))\n",
        "\n",
        "# Define scoring functions\n",
        "def target_city_score(x):\n",
        "    return 15 if x != 'Not specified' else 0\n",
        "\n",
        "def start_date_score(x):\n",
        "    if x == 'Within 30 days':\n",
        "        return 25\n",
        "    elif x == '31-90 days':\n",
        "        return 15\n",
        "    elif x == 'More than 90 days':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def budget_score(x):\n",
        "    if x == 'High':\n",
        "        return 15\n",
        "    elif x == 'Medium':\n",
        "        return 10\n",
        "    elif x == 'Low':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def engagement_score(pages, preferences):\n",
        "    pages_score = min(pages * 3, 9)\n",
        "    preferences_score = min(preferences * 1, 5)\n",
        "    return pages_score + preferences_score\n",
        "\n",
        "def contact_score(x):\n",
        "    return 5 if x == 'Yes' else 0\n",
        "\n",
        "def distance_score(x):\n",
        "    if x == 'Long':\n",
        "        return 10\n",
        "    elif x == 'Medium':\n",
        "        return 5\n",
        "    elif x == 'Short':\n",
        "        return 2\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def safety_score(x):\n",
        "    if x == 'High':\n",
        "        return 10\n",
        "    elif x == 'Medium':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def income_score(x):\n",
        "    if x == 'High':\n",
        "        return 5\n",
        "    elif x == 'Medium':\n",
        "        return 3\n",
        "    elif x == 'Low':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def lifestyle_score(x):\n",
        "    if x == 'Luxury':\n",
        "        return 5\n",
        "    elif x == 'Active':\n",
        "        return 3\n",
        "    elif x == 'Relaxed':\n",
        "        return 2\n",
        "    elif x == 'Budget':\n",
        "        return 1\n",
        "\n",
        "# Apply scoring\n",
        "df['target_city_score'] = df['targetCity'].apply(target_city_score)\n",
        "df['start_date_score'] = df['startDate'].apply(start_date_score)\n",
        "df['budget_score'] = df['budget'].apply(budget_score)\n",
        "df['engagement_score'] = df.apply(lambda row: engagement_score(row['pages_visited'], row['preferences_specified']), axis=1)\n",
        "df['contact_score'] = df['phone_provided'].apply(contact_score)\n",
        "df['distance_score'] = df['distance'].apply(distance_score)\n",
        "df['safety_score'] = df['safety'].apply(safety_score)\n",
        "df['income_score'] = df['income'].apply(income_score)\n",
        "df['lifestyle_score'] = df['lifestyle'].apply(lifestyle_score)\n",
        "\n",
        "df['total_score'] = df[['target_city_score', 'start_date_score', 'budget_score', 'engagement_score',\n",
        "                        'contact_score', 'distance_score', 'safety_score', 'income_score', 'lifestyle_score']].sum(axis=1)\n",
        "\n",
        "# Prepare data for machine learning\n",
        "categorical_features = ['targetCity', 'startDate', 'budget', 'phone_provided', 'distance', 'safety', 'income', 'lifestyle']\n",
        "numerical_features = ['pages_visited', 'preferences_specified']\n",
        "X = df[categorical_features + numerical_features]\n",
        "y = df['total_score']\n",
        "\n",
        "# Define preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ])\n",
        "\n",
        "# Preprocess the data\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build a deeper DNN model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),  # Increased neurons\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with a lower learning rate for finer tuning\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model with more epochs\n",
        "history = model.fit(X_train, y_train, epochs=150, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test).flatten()\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R-squared: {r2:.2f}\")\n",
        "\n",
        "# Show sample predictions\n",
        "print(\"\\nSample Predictions:\")\n",
        "for actual, predicted in list(zip(y_test[:5], y_pred[:5])):\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}\")\n",
        "\n",
        "# Save the model in native Keras format and preprocessor with pickle\n",
        "model.save('lead_scoring_dnn.keras')\n",
        "with open('preprocessor_config.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessor.named_transformers_['cat'].categories_, f)\n",
        "print(\"Model saved as 'lead_scoring_dnn.keras' and preprocessor config saved as 'preprocessor_config.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8tY1mcK-ri8",
        "outputId": "46a554da-ee6f-4e01-ac05-c5901ee1dda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 1.6.1\n",
            "TensorFlow version: 2.18.0\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1738.3478 - mae: 33.4532 - val_loss: 5.8040 - val_mae: 1.6873\n",
            "Epoch 2/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 16.6755 - mae: 3.1810 - val_loss: 2.6587 - val_mae: 1.3472\n",
            "Epoch 3/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 13.1532 - mae: 2.8567 - val_loss: 2.2344 - val_mae: 1.2547\n",
            "Epoch 4/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11.6757 - mae: 2.6912 - val_loss: 0.7586 - val_mae: 0.6598\n",
            "Epoch 5/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11.3349 - mae: 2.6234 - val_loss: 1.0532 - val_mae: 0.8218\n",
            "Epoch 6/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11.2504 - mae: 2.6035 - val_loss: 1.1907 - val_mae: 0.9083\n",
            "Epoch 7/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11.0500 - mae: 2.6149 - val_loss: 0.8193 - val_mae: 0.7222\n",
            "Epoch 8/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.8547 - mae: 2.4408 - val_loss: 4.6993 - val_mae: 2.0138\n",
            "Epoch 9/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.5409 - mae: 2.4367 - val_loss: 2.3014 - val_mae: 1.3589\n",
            "Epoch 10/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.1519 - mae: 2.3729 - val_loss: 3.0545 - val_mae: 1.5567\n",
            "Epoch 11/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10.0308 - mae: 2.4844 - val_loss: 1.3409 - val_mae: 0.9931\n",
            "Epoch 12/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10.1963 - mae: 2.5183 - val_loss: 5.9135 - val_mae: 2.2833\n",
            "Epoch 13/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.9639 - mae: 2.3279 - val_loss: 0.9597 - val_mae: 0.8377\n",
            "Epoch 14/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 9.5378 - mae: 2.4019 - val_loss: 3.9086 - val_mae: 1.8277\n",
            "Epoch 15/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.7787 - mae: 2.3249 - val_loss: 1.8962 - val_mae: 1.2422\n",
            "Epoch 16/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.5922 - mae: 2.2993 - val_loss: 6.0275 - val_mae: 2.3490\n",
            "Epoch 17/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.5172 - mae: 2.2697 - val_loss: 0.5340 - val_mae: 0.5840\n",
            "Epoch 18/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.2796 - mae: 2.2382 - val_loss: 3.0529 - val_mae: 1.5713\n",
            "Epoch 19/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.4972 - mae: 2.2682 - val_loss: 5.2361 - val_mae: 2.2163\n",
            "Epoch 20/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.6082 - mae: 2.2852 - val_loss: 3.0275 - val_mae: 1.5952\n",
            "Epoch 21/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.6862 - mae: 2.3011 - val_loss: 3.6101 - val_mae: 1.7383\n",
            "Epoch 22/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.9832 - mae: 2.2155 - val_loss: 0.9371 - val_mae: 0.8536\n",
            "Epoch 23/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.0033 - mae: 2.2124 - val_loss: 8.7159 - val_mae: 2.8457\n",
            "Epoch 24/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.9583 - mae: 2.1851 - val_loss: 14.4736 - val_mae: 3.6872\n",
            "Epoch 25/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.5341 - mae: 2.2612 - val_loss: 15.2696 - val_mae: 3.8130\n",
            "Epoch 26/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.6242 - mae: 2.1376 - val_loss: 5.2746 - val_mae: 2.1543\n",
            "Epoch 27/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.6340 - mae: 2.3092 - val_loss: 4.7132 - val_mae: 2.0740\n",
            "Epoch 28/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.2235 - mae: 2.1148 - val_loss: 6.3648 - val_mae: 2.4243\n",
            "Epoch 29/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.3437 - mae: 2.0998 - val_loss: 9.7185 - val_mae: 2.9851\n",
            "Epoch 30/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.1102 - mae: 2.0675 - val_loss: 9.8252 - val_mae: 2.9846\n",
            "Epoch 31/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.6690 - mae: 2.1667 - val_loss: 13.6462 - val_mae: 3.5922\n",
            "Epoch 32/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.3419 - mae: 2.1258 - val_loss: 21.2164 - val_mae: 4.4893\n",
            "Epoch 33/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.0501 - mae: 2.0745 - val_loss: 10.6043 - val_mae: 3.1438\n",
            "Epoch 34/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.5814 - mae: 2.1552 - val_loss: 22.9666 - val_mae: 4.6145\n",
            "Epoch 35/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.7721 - mae: 2.0307 - val_loss: 12.2134 - val_mae: 3.3842\n",
            "Epoch 36/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.7188 - mae: 2.0241 - val_loss: 28.1722 - val_mae: 5.1693\n",
            "Epoch 37/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.3703 - mae: 2.2703 - val_loss: 6.4870 - val_mae: 2.4320\n",
            "Epoch 38/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.3937 - mae: 2.1070 - val_loss: 19.2722 - val_mae: 4.2545\n",
            "Epoch 39/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.0212 - mae: 2.0656 - val_loss: 14.0967 - val_mae: 3.6192\n",
            "Epoch 40/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.6478 - mae: 2.0038 - val_loss: 19.1771 - val_mae: 4.2486\n",
            "Epoch 41/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.5087 - mae: 1.9921 - val_loss: 24.8696 - val_mae: 4.8075\n",
            "Epoch 42/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.1766 - mae: 1.9206 - val_loss: 35.3704 - val_mae: 5.7847\n",
            "Epoch 43/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.3124 - mae: 1.9611 - val_loss: 15.9735 - val_mae: 3.8740\n",
            "Epoch 44/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.0910 - mae: 1.9225 - val_loss: 48.1521 - val_mae: 6.7396\n",
            "Epoch 45/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.9931 - mae: 2.0688 - val_loss: 28.8035 - val_mae: 5.2376\n",
            "Epoch 46/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.8344 - mae: 2.0187 - val_loss: 24.4884 - val_mae: 4.7625\n",
            "Epoch 47/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.9560 - mae: 1.8942 - val_loss: 35.6419 - val_mae: 5.8037\n",
            "Epoch 48/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.1397 - mae: 1.9227 - val_loss: 19.5324 - val_mae: 4.2784\n",
            "Epoch 49/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.9576 - mae: 2.0530 - val_loss: 46.6220 - val_mae: 6.6264\n",
            "Epoch 50/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.1095 - mae: 1.9223 - val_loss: 34.9057 - val_mae: 5.7426\n",
            "Epoch 51/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.2555 - mae: 1.7870 - val_loss: 53.6630 - val_mae: 7.1026\n",
            "Epoch 52/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.6454 - mae: 1.8305 - val_loss: 47.7548 - val_mae: 6.7208\n",
            "Epoch 53/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.8397 - mae: 1.8732 - val_loss: 36.4503 - val_mae: 5.8536\n",
            "Epoch 54/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.7151 - mae: 1.8561 - val_loss: 49.0497 - val_mae: 6.7747\n",
            "Epoch 55/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.4470 - mae: 1.8240 - val_loss: 70.8152 - val_mae: 8.1749\n",
            "Epoch 56/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7896 - mae: 1.7044 - val_loss: 43.6125 - val_mae: 6.4158\n",
            "Epoch 57/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.7265 - mae: 1.8524 - val_loss: 49.0818 - val_mae: 6.8266\n",
            "Epoch 58/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.1578 - mae: 1.7486 - val_loss: 45.7631 - val_mae: 6.5249\n",
            "Epoch 59/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.3226 - mae: 1.7850 - val_loss: 75.3950 - val_mae: 8.4415\n",
            "Epoch 60/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7041 - mae: 1.6808 - val_loss: 48.2861 - val_mae: 6.7165\n",
            "Epoch 61/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6901 - mae: 1.6646 - val_loss: 83.7473 - val_mae: 8.8801\n",
            "Epoch 62/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.2511 - mae: 1.6062 - val_loss: 73.8557 - val_mae: 8.3265\n",
            "Epoch 63/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.3899 - mae: 1.6178 - val_loss: 90.5947 - val_mae: 9.2246\n",
            "Epoch 64/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1956 - mae: 1.5847 - val_loss: 72.4365 - val_mae: 8.2118\n",
            "Epoch 65/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.1133 - mae: 1.5690 - val_loss: 75.7754 - val_mae: 8.3992\n",
            "Epoch 66/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9612 - mae: 1.5440 - val_loss: 113.2782 - val_mae: 10.2875\n",
            "Epoch 67/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8261 - mae: 1.5064 - val_loss: 86.9023 - val_mae: 9.0126\n",
            "Epoch 68/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8009 - mae: 1.5136 - val_loss: 69.4199 - val_mae: 8.0195\n",
            "Epoch 69/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7117 - mae: 1.4811 - val_loss: 94.1841 - val_mae: 9.3149\n",
            "Epoch 70/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7286 - mae: 1.4959 - val_loss: 99.2315 - val_mae: 9.5728\n",
            "Epoch 71/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3367 - mae: 1.4130 - val_loss: 86.8480 - val_mae: 8.9229\n",
            "Epoch 72/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3713 - mae: 1.4293 - val_loss: 81.4093 - val_mae: 8.6624\n",
            "Epoch 73/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 3.3352 - mae: 1.3943 - val_loss: 102.9234 - val_mae: 9.7178\n",
            "Epoch 74/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.3518 - mae: 1.4207 - val_loss: 86.1473 - val_mae: 8.8864\n",
            "Epoch 75/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2613 - mae: 1.3952 - val_loss: 81.7803 - val_mae: 8.6377\n",
            "Epoch 76/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 3.0506 - mae: 1.3578 - val_loss: 67.6599 - val_mae: 7.8838\n",
            "Epoch 77/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.5742 - mae: 1.4503 - val_loss: 94.3263 - val_mae: 9.2977\n",
            "Epoch 78/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.7936 - mae: 1.2718 - val_loss: 92.3470 - val_mae: 9.1591\n",
            "Epoch 79/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.8633 - mae: 1.2785 - val_loss: 80.1459 - val_mae: 8.5173\n",
            "Epoch 80/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.1947 - mae: 1.3686 - val_loss: 73.5649 - val_mae: 8.1484\n",
            "Epoch 81/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.6027 - mae: 1.2441 - val_loss: 77.3154 - val_mae: 8.3833\n",
            "Epoch 82/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.6279 - mae: 1.2595 - val_loss: 98.4777 - val_mae: 9.4710\n",
            "Epoch 83/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.5972 - mae: 1.2295 - val_loss: 84.9451 - val_mae: 8.7455\n",
            "Epoch 84/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.5492 - mae: 1.2253 - val_loss: 60.5738 - val_mae: 7.3616\n",
            "Epoch 85/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.7394 - mae: 1.2615 - val_loss: 84.0820 - val_mae: 8.6778\n",
            "Epoch 86/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.4795 - mae: 1.2033 - val_loss: 89.5128 - val_mae: 8.9386\n",
            "Epoch 87/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.4363 - mae: 1.2099 - val_loss: 103.4523 - val_mae: 9.6640\n",
            "Epoch 88/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.2608 - mae: 1.1508 - val_loss: 86.9423 - val_mae: 8.8229\n",
            "Epoch 89/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5008 - mae: 1.1895 - val_loss: 75.8007 - val_mae: 8.2402\n",
            "Epoch 90/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5350 - mae: 1.2212 - val_loss: 77.1901 - val_mae: 8.2483\n",
            "Epoch 91/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.2113 - mae: 1.1391 - val_loss: 88.0828 - val_mae: 8.8573\n",
            "Epoch 92/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.1518 - mae: 1.1240 - val_loss: 91.5118 - val_mae: 9.0588\n",
            "Epoch 93/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.2010 - mae: 1.1402 - val_loss: 75.2122 - val_mae: 8.1832\n",
            "Epoch 94/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.9942 - mae: 1.0782 - val_loss: 79.4903 - val_mae: 8.4086\n",
            "Epoch 95/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.9606 - mae: 1.0654 - val_loss: 80.3028 - val_mae: 8.4438\n",
            "Epoch 96/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.1668 - mae: 1.1180 - val_loss: 76.4226 - val_mae: 8.2625\n",
            "Epoch 97/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.9068 - mae: 1.0606 - val_loss: 72.7887 - val_mae: 8.0265\n",
            "Epoch 98/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.9320 - mae: 1.0549 - val_loss: 58.6421 - val_mae: 7.1462\n",
            "Epoch 99/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8000 - mae: 1.0289 - val_loss: 76.3313 - val_mae: 8.2039\n",
            "Epoch 100/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.7230 - mae: 0.9984 - val_loss: 66.1791 - val_mae: 7.6018\n",
            "Epoch 101/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8701 - mae: 1.0386 - val_loss: 76.0353 - val_mae: 8.1726\n",
            "Epoch 102/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8994 - mae: 1.0494 - val_loss: 81.7531 - val_mae: 8.4530\n",
            "Epoch 103/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.7527 - mae: 0.9846 - val_loss: 69.8917 - val_mae: 7.8044\n",
            "Epoch 104/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6692 - mae: 0.9784 - val_loss: 74.3144 - val_mae: 8.0506\n",
            "Epoch 105/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6609 - mae: 0.9851 - val_loss: 82.7892 - val_mae: 8.4769\n",
            "Epoch 106/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.6744 - mae: 0.9816 - val_loss: 82.1882 - val_mae: 8.4097\n",
            "Epoch 107/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.5043 - mae: 0.9315 - val_loss: 58.6827 - val_mae: 7.0591\n",
            "Epoch 108/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.4552 - mae: 0.9246 - val_loss: 71.2271 - val_mae: 7.7820\n",
            "Epoch 109/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4428 - mae: 0.9094 - val_loss: 73.9738 - val_mae: 7.9724\n",
            "Epoch 110/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6220 - mae: 0.9501 - val_loss: 70.1900 - val_mae: 7.7730\n",
            "Epoch 111/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6752 - mae: 0.9808 - val_loss: 59.4013 - val_mae: 7.1019\n",
            "Epoch 112/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3419 - mae: 0.8737 - val_loss: 51.4603 - val_mae: 6.5051\n",
            "Epoch 113/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3560 - mae: 0.8775 - val_loss: 53.8851 - val_mae: 6.6435\n",
            "Epoch 114/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3413 - mae: 0.8736 - val_loss: 50.9039 - val_mae: 6.5107\n",
            "Epoch 115/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2838 - mae: 0.8416 - val_loss: 61.9273 - val_mae: 7.0881\n",
            "Epoch 116/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3076 - mae: 0.8649 - val_loss: 55.8075 - val_mae: 6.7353\n",
            "Epoch 117/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1975 - mae: 0.8191 - val_loss: 46.6911 - val_mae: 6.1534\n",
            "Epoch 118/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.3273 - mae: 0.8588 - val_loss: 44.5208 - val_mae: 6.0093\n",
            "Epoch 119/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4054 - mae: 0.8929 - val_loss: 51.9142 - val_mae: 6.5402\n",
            "Epoch 120/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1220 - mae: 0.7997 - val_loss: 47.1271 - val_mae: 6.1782\n",
            "Epoch 121/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2101 - mae: 0.8330 - val_loss: 51.5299 - val_mae: 6.4893\n",
            "Epoch 122/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2522 - mae: 0.8430 - val_loss: 43.8861 - val_mae: 5.8886\n",
            "Epoch 123/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1508 - mae: 0.8108 - val_loss: 45.0093 - val_mae: 5.9894\n",
            "Epoch 124/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1778 - mae: 0.8161 - val_loss: 43.2082 - val_mae: 5.8549\n",
            "Epoch 125/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2324 - mae: 0.8275 - val_loss: 34.7960 - val_mae: 5.2356\n",
            "Epoch 126/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0948 - mae: 0.8024 - val_loss: 40.1638 - val_mae: 5.5682\n",
            "Epoch 127/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0641 - mae: 0.7740 - val_loss: 35.8121 - val_mae: 5.1876\n",
            "Epoch 128/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1616 - mae: 0.8047 - val_loss: 44.9704 - val_mae: 5.9005\n",
            "Epoch 129/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0442 - mae: 0.7721 - val_loss: 41.1137 - val_mae: 5.6719\n",
            "Epoch 130/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.0959 - mae: 0.7801 - val_loss: 36.9631 - val_mae: 5.3802\n",
            "Epoch 131/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0135 - mae: 0.7468 - val_loss: 34.9144 - val_mae: 5.2110\n",
            "Epoch 132/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0752 - mae: 0.7823 - val_loss: 39.8712 - val_mae: 5.5457\n",
            "Epoch 133/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9513 - mae: 0.7353 - val_loss: 28.3000 - val_mae: 4.5852\n",
            "Epoch 134/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9824 - mae: 0.7421 - val_loss: 33.8449 - val_mae: 5.0696\n",
            "Epoch 135/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0605 - mae: 0.7767 - val_loss: 32.8347 - val_mae: 4.9226\n",
            "Epoch 136/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0746 - mae: 0.7832 - val_loss: 24.1022 - val_mae: 4.2891\n",
            "Epoch 137/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9979 - mae: 0.7546 - val_loss: 30.9498 - val_mae: 4.8487\n",
            "Epoch 138/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9722 - mae: 0.7482 - val_loss: 26.7421 - val_mae: 4.5316\n",
            "Epoch 139/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8183 - mae: 0.6847 - val_loss: 29.0441 - val_mae: 4.5980\n",
            "Epoch 140/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9148 - mae: 0.7247 - val_loss: 24.0043 - val_mae: 4.1986\n",
            "Epoch 141/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9632 - mae: 0.7358 - val_loss: 25.5865 - val_mae: 4.3057\n",
            "Epoch 142/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0007 - mae: 0.7658 - val_loss: 29.6447 - val_mae: 4.6210\n",
            "Epoch 143/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9349 - mae: 0.7185 - val_loss: 28.9637 - val_mae: 4.6671\n",
            "Epoch 144/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9526 - mae: 0.7216 - val_loss: 20.4460 - val_mae: 3.7823\n",
            "Epoch 145/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9035 - mae: 0.7210 - val_loss: 24.7880 - val_mae: 4.2170\n",
            "Epoch 146/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8298 - mae: 0.6812 - val_loss: 23.4734 - val_mae: 4.2747\n",
            "Epoch 147/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8557 - mae: 0.6855 - val_loss: 27.4549 - val_mae: 4.4454\n",
            "Epoch 148/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8171 - mae: 0.6770 - val_loss: 24.4438 - val_mae: 4.2629\n",
            "Epoch 149/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8691 - mae: 0.6890 - val_loss: 28.8271 - val_mae: 4.6582\n",
            "Epoch 150/150\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9592 - mae: 0.7391 - val_loss: 23.9299 - val_mae: 4.1342\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Mean Squared Error: 24.31\n",
            "R-squared: 0.87\n",
            "\n",
            "Sample Predictions:\n",
            "Actual Score: 41, Predicted Score: 40.31\n",
            "Actual Score: 74, Predicted Score: 66.20\n",
            "Actual Score: 49, Predicted Score: 46.96\n",
            "Actual Score: 49, Predicted Score: 46.72\n",
            "Actual Score: 58, Predicted Score: 54.56\n",
            "Model saved as 'lead_scoring_dnn.keras' and preprocessor config saved as 'preprocessor_config.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load the saved model\n",
        "model = tf.keras.models.load_model('lead_scoring_dnn.keras')\n",
        "print(\"Model loaded successfully\")\n",
        "\n",
        "# Define possible values (must match training script)\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Load preprocessor configuration\n",
        "with open('preprocessor_config.pkl', 'rb') as f:\n",
        "    categories = pickle.load(f)\n",
        "categorical_features = ['targetCity', 'startDate', 'budget', 'phone_provided', 'distance', 'safety', 'income', 'lifestyle']\n",
        "numerical_features = ['pages_visited', 'preferences_specified']\n",
        "\n",
        "# Reconstruct the preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(categories=categories, handle_unknown='ignore', sparse_output=False), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ])\n",
        "\n",
        "# Example input data to match your sample predictions\n",
        "sample_data = [\n",
        "    {'targetCity': 'Bangalore', 'startDate': 'Within 30 days', 'budget': 'Medium', 'phone_provided': 'Yes',\n",
        "     'distance': 'Medium', 'safety': 'High', 'income': 'Medium', 'lifestyle': 'Active',\n",
        "     'pages_visited': 2, 'preferences_specified': 3},  # Should predict ~55\n",
        "    {'targetCity': 'Mumbai', 'startDate': '31-90 days', 'budget': 'Low', 'phone_provided': 'No',\n",
        "     'distance': 'Short', 'safety': 'Medium', 'income': 'Low', 'lifestyle': 'Budget',\n",
        "     'pages_visited': 1, 'preferences_specified': 2},  # Should predict ~39\n",
        "    {'targetCity': 'New Delhi', 'startDate': 'Within 30 days', 'budget': 'High', 'phone_provided': 'Yes',\n",
        "     'distance': 'Long', 'safety': 'High', 'income': 'High', 'lifestyle': 'Luxury',\n",
        "     'pages_visited': 3, 'preferences_specified': 5},  # Should predict ~82\n",
        "    {'targetCity': 'Not specified', 'startDate': 'More than 90 days', 'budget': 'Low', 'phone_provided': 'No',\n",
        "     'distance': 'Short', 'safety': 'Low', 'income': 'Low', 'lifestyle': 'Budget',\n",
        "     'pages_visited': 0, 'preferences_specified': 1},  # Should predict ~25\n",
        "    {'targetCity': 'Hyderabad', 'startDate': 'Within 30 days', 'budget': 'High', 'phone_provided': 'Yes',\n",
        "     'distance': 'Medium', 'safety': 'Medium', 'income': 'Medium', 'lifestyle': 'Relaxed',\n",
        "     'pages_visited': 3, 'preferences_specified': 4},  # Should predict ~76\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "sample_df = pd.DataFrame(sample_data)\n",
        "\n",
        "# Preprocess the sample data\n",
        "sample_processed = preprocessor.fit_transform(sample_df)\n",
        "\n",
        "# Predict scores\n",
        "predictions = model.predict(sample_processed).flatten()\n",
        "\n",
        "# Display results\n",
        "print(\"\\nSample Predictions:\")\n",
        "for actual, predicted in zip([55, 39, 82, 25, 76], predictions):\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LBbQuUgBLda",
        "outputId": "7d619cc4-2d7e-4bc9-b858-70bdb5881801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
            "\n",
            "Sample Predictions:\n",
            "Actual Score: 55, Predicted Score: 75.36\n",
            "Actual Score: 39, Predicted Score: 46.72\n",
            "Actual Score: 82, Predicted Score: 89.67\n",
            "Actual Score: 25, Predicted Score: 18.12\n",
            "Actual Score: 76, Predicted Score: 77.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method 4**"
      ],
      "metadata": {
        "id": "AtSDpKiRBHBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check installed versions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import xgboost as xgb\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Import required modules\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, LayerNormalization, MultiHeadAttention, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Define possible values with expanded Indian cities\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_durations = ['1-7 days', '8-30 days', 'More than 30 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Generate synthetic data (larger dataset)\n",
        "np.random.seed(42)\n",
        "n_samples = 20000  # Increased to 20,000 samples\n",
        "data = {\n",
        "    'email': ['email@example.com'] * n_samples,\n",
        "    'phone_provided': np.random.choice(possible_phone, n_samples),\n",
        "    'currentCity': np.random.choice(possible_cities, n_samples),\n",
        "    'targetCity': np.random.choice(possible_cities, n_samples),\n",
        "    'startDate': np.random.choice(possible_start_dates, n_samples),\n",
        "    'duration': np.random.choice(possible_durations, n_samples),\n",
        "    'budget': np.random.choice(possible_budgets, n_samples),\n",
        "    'income': np.random.choice(possible_incomes, n_samples),\n",
        "    'lifestyle': np.random.choice(possible_lifestyles, n_samples),\n",
        "    'distance': np.random.choice(possible_distances, n_samples),\n",
        "    'safety': np.random.choice(possible_safeties, n_samples),\n",
        "    'pagesVisited': [list(np.random.choice(possible_pages, np.random.randint(0, 7), replace=False)) for _ in range(n_samples)],\n",
        "    'foodPreferences': [list(np.random.choice(possible_food, np.random.randint(0, 4), replace=False)) for _ in range(n_samples)],\n",
        "    'transportType': [list(np.random.choice(possible_transport, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "    'accommodationType': [list(np.random.choice(possible_accommodation, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set phone based on phone_provided\n",
        "df['phone'] = df['phone_provided'].apply(lambda x: '1234567890' if x == 'Yes' else '')\n",
        "\n",
        "# Compute numerical features\n",
        "df['pages_visited'] = df['pagesVisited'].apply(lambda x: min(len(set(x) & set(key_pages)), 3))\n",
        "df['preferences_specified'] = (df['foodPreferences'].apply(len) +\n",
        "                               df['transportType'].apply(len) +\n",
        "                               df['accommodationType'].apply(len))\n",
        "\n",
        "# Define scoring functions\n",
        "def target_city_score(x):\n",
        "    return 15 if x != 'Not specified' else 0\n",
        "\n",
        "def start_date_score(x):\n",
        "    if x == 'Within 30 days':\n",
        "        return 25\n",
        "    elif x == '31-90 days':\n",
        "        return 15\n",
        "    elif x == 'More than 90 days':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def budget_score(x):\n",
        "    if x == 'High':\n",
        "        return 15\n",
        "    elif x == 'Medium':\n",
        "        return 10\n",
        "    elif x == 'Low':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def engagement_score(pages, preferences):\n",
        "    pages_score = min(pages * 3, 9)\n",
        "    preferences_score = min(preferences * 1, 5)\n",
        "    return pages_score + preferences_score\n",
        "\n",
        "def contact_score(x):\n",
        "    return 5 if x == 'Yes' else 0\n",
        "\n",
        "def distance_score(x):\n",
        "    if x == 'Long':\n",
        "        return 10\n",
        "    elif x == 'Medium':\n",
        "        return 5\n",
        "    elif x == 'Short':\n",
        "        return 2\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def safety_score(x):\n",
        "    if x == 'High':\n",
        "        return 10\n",
        "    elif x == 'Medium':\n",
        "        return 5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def income_score(x):\n",
        "    if x == 'High':\n",
        "        return 5\n",
        "    elif x == 'Medium':\n",
        "        return 3\n",
        "    elif x == 'Low':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def lifestyle_score(x):\n",
        "    if x == 'Luxury':\n",
        "        return 5\n",
        "    elif x == 'Active':\n",
        "        return 3\n",
        "    elif x == 'Relaxed':\n",
        "        return 2\n",
        "    elif x == 'Budget':\n",
        "        return 1\n",
        "\n",
        "# Apply scoring\n",
        "df['target_city_score'] = df['targetCity'].apply(target_city_score)\n",
        "df['start_date_score'] = df['startDate'].apply(start_date_score)\n",
        "df['budget_score'] = df['budget'].apply(budget_score)\n",
        "df['engagement_score'] = df.apply(lambda row: engagement_score(row['pages_visited'], row['preferences_specified']), axis=1)\n",
        "df['contact_score'] = df['phone_provided'].apply(contact_score)\n",
        "df['distance_score'] = df['distance'].apply(distance_score)\n",
        "df['safety_score'] = df['safety'].apply(safety_score)\n",
        "df['income_score'] = df['income'].apply(income_score)\n",
        "df['lifestyle_score'] = df['lifestyle'].apply(lifestyle_score)\n",
        "\n",
        "df['total_score'] = df[['target_city_score', 'start_date_score', 'budget_score', 'engagement_score',\n",
        "                        'contact_score', 'distance_score', 'safety_score', 'income_score', 'lifestyle_score']].sum(axis=1)\n",
        "\n",
        "# Prepare data for machine learning\n",
        "categorical_features = ['targetCity', 'startDate', 'budget', 'phone_provided', 'distance', 'safety', 'income', 'lifestyle']\n",
        "numerical_features = ['pages_visited', 'preferences_specified']\n",
        "X = df[categorical_features + numerical_features]\n",
        "y = df['total_score']\n",
        "\n",
        "# Define preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ])\n",
        "\n",
        "# Preprocess the data\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape for CNN and Transformer (add a time-like dimension)\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Build the hybrid model (CNN + Transformer + DNN)\n",
        "inputs = Input(shape=(X_train_reshaped.shape[1], 1))\n",
        "x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "x = LayerNormalization()(x)\n",
        "x = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)  # Transformer layer\n",
        "x = LayerNormalization()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "outputs = Dense(1)(x)\n",
        "\n",
        "hybrid_model = Model(inputs, outputs)\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=0.0003), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the hybrid model\n",
        "history = hybrid_model.fit(X_train_reshaped, y_train, epochs=200, batch_size=64, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Get predictions from the hybrid model\n",
        "y_pred_hybrid = hybrid_model.predict(X_test_reshaped).flatten()\n",
        "\n",
        "# Train an XGBoost model for ensembling\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Ensemble: Average predictions from hybrid and XGBoost\n",
        "y_pred_ensemble = (y_pred_hybrid + y_pred_xgb) / 2\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "mse = mean_squared_error(y_test, y_pred_ensemble)\n",
        "r2 = r2_score(y_test, y_pred_ensemble)\n",
        "\n",
        "print(f\"Mean Squared Error (Ensemble): {mse:.2f}\")\n",
        "print(f\"R-squared (Ensemble): {r2:.2f}\")\n",
        "\n",
        "# Show sample predictions\n",
        "print(\"\\nSample Predictions (Ensemble):\")\n",
        "for actual, predicted in list(zip(y_test[:5], y_pred_ensemble[:5])):\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}\")\n",
        "\n",
        "# Save the models and preprocessor\n",
        "hybrid_model.save('lead_scoring_hybrid.keras')\n",
        "with open('preprocessor_config.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessor.named_transformers_['cat'].categories_, f)\n",
        "with open('xgb_model.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model, f)\n",
        "print(\"Hybrid model saved as 'lead_scoring_hybrid.keras', XGBoost model saved as 'xgb_model.pkl', and preprocessor config saved as 'preprocessor_config.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBOk19aRBGtm",
        "outputId": "e541628f-c1b8-4408-e069-868f865ba424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 1.6.1\n",
            "TensorFlow version: 2.18.0\n",
            "Epoch 1/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 618.4660 - mae: 18.7912 - val_loss: 39.6490 - val_mae: 5.7939\n",
            "Epoch 2/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 43.4121 - mae: 5.1361 - val_loss: 66.4050 - val_mae: 7.7601\n",
            "Epoch 3/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 30.8048 - mae: 4.3478 - val_loss: 151.6818 - val_mae: 11.9450\n",
            "Epoch 4/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 25.8035 - mae: 3.9755 - val_loss: 249.2889 - val_mae: 15.3260\n",
            "Epoch 5/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 23.7392 - mae: 3.8053 - val_loss: 292.0809 - val_mae: 16.6354\n",
            "Epoch 6/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 22.7178 - mae: 3.7205 - val_loss: 360.6365 - val_mae: 18.4866\n",
            "Epoch 7/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 21.3043 - mae: 3.6113 - val_loss: 371.4743 - val_mae: 18.7503\n",
            "Epoch 8/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.0116 - mae: 3.4060 - val_loss: 414.6118 - val_mae: 19.8153\n",
            "Epoch 9/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.0498 - mae: 3.3044 - val_loss: 447.9019 - val_mae: 20.6002\n",
            "Epoch 10/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 17.2422 - mae: 3.2249 - val_loss: 483.1241 - val_mae: 21.3846\n",
            "Epoch 11/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 16.2786 - mae: 3.1498 - val_loss: 446.8379 - val_mae: 20.5779\n",
            "Epoch 12/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 15.5940 - mae: 3.0517 - val_loss: 490.9650 - val_mae: 21.6123\n",
            "Epoch 13/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 14.0824 - mae: 2.9032 - val_loss: 495.0803 - val_mae: 21.6869\n",
            "Epoch 14/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 13.1568 - mae: 2.7964 - val_loss: 548.1132 - val_mae: 22.8387\n",
            "Epoch 15/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 12.3197 - mae: 2.7002 - val_loss: 525.5137 - val_mae: 22.2794\n",
            "Epoch 16/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11.7088 - mae: 2.6216 - val_loss: 581.7057 - val_mae: 23.4614\n",
            "Epoch 17/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 10.9885 - mae: 2.5302 - val_loss: 502.3033 - val_mae: 21.7847\n",
            "Epoch 18/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 10.2153 - mae: 2.4434 - val_loss: 511.1026 - val_mae: 21.9670\n",
            "Epoch 19/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 10.0429 - mae: 2.4142 - val_loss: 502.7902 - val_mae: 21.8148\n",
            "Epoch 20/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 10.0245 - mae: 2.4051 - val_loss: 502.8322 - val_mae: 21.7906\n",
            "Epoch 21/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.3103 - mae: 2.3302 - val_loss: 497.9214 - val_mae: 21.7164\n",
            "Epoch 22/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.8110 - mae: 2.2730 - val_loss: 525.7615 - val_mae: 22.3549\n",
            "Epoch 23/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.5924 - mae: 2.2256 - val_loss: 520.0425 - val_mae: 22.2096\n",
            "Epoch 24/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.4504 - mae: 2.1868 - val_loss: 479.4597 - val_mae: 21.3035\n",
            "Epoch 25/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.1194 - mae: 2.1451 - val_loss: 490.0619 - val_mae: 21.5849\n",
            "Epoch 26/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 8.1322 - mae: 2.1338 - val_loss: 506.1506 - val_mae: 21.8820\n",
            "Epoch 27/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.6692 - mae: 2.0938 - val_loss: 490.0000 - val_mae: 21.5767\n",
            "Epoch 28/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.6937 - mae: 2.0859 - val_loss: 530.9674 - val_mae: 22.4550\n",
            "Epoch 29/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.5115 - mae: 2.0574 - val_loss: 513.2823 - val_mae: 22.0544\n",
            "Epoch 30/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.3401 - mae: 2.0348 - val_loss: 513.6198 - val_mae: 22.0480\n",
            "Epoch 31/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 7.0363 - mae: 1.9696 - val_loss: 495.7327 - val_mae: 21.6552\n",
            "Epoch 32/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.7508 - mae: 1.9507 - val_loss: 502.9742 - val_mae: 21.8365\n",
            "Epoch 33/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 6.7217 - mae: 1.9258 - val_loss: 484.7929 - val_mae: 21.4074\n",
            "Epoch 34/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.3851 - mae: 1.8786 - val_loss: 540.0281 - val_mae: 22.6523\n",
            "Epoch 35/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.2730 - mae: 1.8512 - val_loss: 518.3348 - val_mae: 22.1438\n",
            "Epoch 36/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.9790 - mae: 1.8267 - val_loss: 505.2402 - val_mae: 21.8583\n",
            "Epoch 37/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.0483 - mae: 1.8432 - val_loss: 479.3868 - val_mae: 21.2837\n",
            "Epoch 38/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 6.0554 - mae: 1.8273 - val_loss: 500.4195 - val_mae: 21.7510\n",
            "Epoch 39/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.7476 - mae: 1.7765 - val_loss: 483.5144 - val_mae: 21.4046\n",
            "Epoch 40/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.6304 - mae: 1.7459 - val_loss: 481.2847 - val_mae: 21.3598\n",
            "Epoch 41/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.2106 - mae: 1.6853 - val_loss: 513.1065 - val_mae: 22.0573\n",
            "Epoch 42/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.3944 - mae: 1.7212 - val_loss: 538.2866 - val_mae: 22.5661\n",
            "Epoch 43/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.3393 - mae: 1.7148 - val_loss: 519.3091 - val_mae: 22.1612\n",
            "Epoch 44/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.0323 - mae: 1.6503 - val_loss: 531.3144 - val_mae: 22.4297\n",
            "Epoch 45/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.3172 - mae: 1.7227 - val_loss: 507.7365 - val_mae: 21.8878\n",
            "Epoch 46/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.2708 - mae: 1.6803 - val_loss: 485.8615 - val_mae: 21.4350\n",
            "Epoch 47/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.4871 - mae: 1.5807 - val_loss: 505.1555 - val_mae: 21.8816\n",
            "Epoch 48/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.7498 - mae: 1.5913 - val_loss: 485.8474 - val_mae: 21.4506\n",
            "Epoch 49/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.9156 - mae: 1.6260 - val_loss: 435.6174 - val_mae: 20.2840\n",
            "Epoch 50/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.6070 - mae: 1.5587 - val_loss: 450.2820 - val_mae: 20.6010\n",
            "Epoch 51/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.4042 - mae: 1.5481 - val_loss: 475.2369 - val_mae: 21.2151\n",
            "Epoch 52/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.6104 - mae: 1.5514 - val_loss: 489.4860 - val_mae: 21.5160\n",
            "Epoch 53/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.5511 - mae: 1.5702 - val_loss: 436.8145 - val_mae: 20.3095\n",
            "Epoch 54/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.3362 - mae: 1.5199 - val_loss: 465.4961 - val_mae: 20.9957\n",
            "Epoch 55/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.0743 - mae: 1.4988 - val_loss: 450.2405 - val_mae: 20.6385\n",
            "Epoch 56/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.1300 - mae: 1.4808 - val_loss: 447.0337 - val_mae: 20.5170\n",
            "Epoch 57/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.0582 - mae: 1.4613 - val_loss: 456.3039 - val_mae: 20.7346\n",
            "Epoch 58/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.4587 - mae: 1.5376 - val_loss: 483.0285 - val_mae: 21.3495\n",
            "Epoch 59/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.0163 - mae: 1.4419 - val_loss: 468.1893 - val_mae: 20.9897\n",
            "Epoch 60/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.7412 - mae: 1.4077 - val_loss: 455.7457 - val_mae: 20.7500\n",
            "Epoch 61/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.0752 - mae: 1.4818 - val_loss: 448.9364 - val_mae: 20.5537\n",
            "Epoch 62/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.5889 - mae: 1.3850 - val_loss: 446.8840 - val_mae: 20.5150\n",
            "Epoch 63/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.6577 - mae: 1.4094 - val_loss: 447.1211 - val_mae: 20.5274\n",
            "Epoch 64/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.5955 - mae: 1.3820 - val_loss: 437.3255 - val_mae: 20.3197\n",
            "Epoch 65/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.4623 - mae: 1.3648 - val_loss: 395.0514 - val_mae: 19.3075\n",
            "Epoch 66/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 3.7079 - mae: 1.4007 - val_loss: 428.8414 - val_mae: 20.1283\n",
            "Epoch 67/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.5342 - mae: 1.3688 - val_loss: 432.1147 - val_mae: 20.1899\n",
            "Epoch 68/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.7292 - mae: 1.3973 - val_loss: 460.0147 - val_mae: 20.8663\n",
            "Epoch 69/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.3699 - mae: 1.3478 - val_loss: 401.9762 - val_mae: 19.3966\n",
            "Epoch 70/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.4493 - mae: 1.3545 - val_loss: 478.2516 - val_mae: 21.2567\n",
            "Epoch 71/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.4220 - mae: 1.3444 - val_loss: 393.1319 - val_mae: 19.2231\n",
            "Epoch 72/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.4002 - mae: 1.3546 - val_loss: 422.6740 - val_mae: 19.9387\n",
            "Epoch 73/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.2748 - mae: 1.3062 - val_loss: 458.9492 - val_mae: 20.8275\n",
            "Epoch 74/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.1477 - mae: 1.2839 - val_loss: 436.8492 - val_mae: 20.2648\n",
            "Epoch 75/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 2.7637 - mae: 1.2113 - val_loss: 409.1834 - val_mae: 19.6099\n",
            "Epoch 76/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.0441 - mae: 1.2464 - val_loss: 441.4130 - val_mae: 20.3778\n",
            "Epoch 77/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.0916 - mae: 1.2897 - val_loss: 417.2391 - val_mae: 19.8352\n",
            "Epoch 78/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.9350 - mae: 1.2462 - val_loss: 418.8044 - val_mae: 19.8303\n",
            "Epoch 79/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.1623 - mae: 1.2984 - val_loss: 430.1468 - val_mae: 20.1099\n",
            "Epoch 80/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.9429 - mae: 1.2569 - val_loss: 437.4515 - val_mae: 20.2783\n",
            "Epoch 81/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.8350 - mae: 1.2080 - val_loss: 433.2140 - val_mae: 20.2015\n",
            "Epoch 82/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.8149 - mae: 1.2057 - val_loss: 397.3451 - val_mae: 19.3307\n",
            "Epoch 83/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.8692 - mae: 1.2257 - val_loss: 444.3311 - val_mae: 20.4241\n",
            "Epoch 84/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 2.7146 - mae: 1.1866 - val_loss: 407.9367 - val_mae: 19.6165\n",
            "Epoch 85/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.5531 - mae: 1.1602 - val_loss: 387.9090 - val_mae: 19.0598\n",
            "Epoch 86/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.8188 - mae: 1.2106 - val_loss: 396.6797 - val_mae: 19.2477\n",
            "Epoch 87/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.6068 - mae: 1.1814 - val_loss: 465.1714 - val_mae: 20.9794\n",
            "Epoch 88/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.6940 - mae: 1.1860 - val_loss: 415.1811 - val_mae: 19.7814\n",
            "Epoch 89/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.8583 - mae: 1.1784 - val_loss: 443.8519 - val_mae: 20.4685\n",
            "Epoch 90/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.6138 - mae: 1.1530 - val_loss: 401.3819 - val_mae: 19.4324\n",
            "Epoch 91/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.5058 - mae: 1.1487 - val_loss: 389.9629 - val_mae: 19.1015\n",
            "Epoch 92/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.4747 - mae: 1.1344 - val_loss: 422.8248 - val_mae: 19.9408\n",
            "Epoch 93/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 2.6095 - mae: 1.1370 - val_loss: 383.8920 - val_mae: 19.0400\n",
            "Epoch 94/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.3617 - mae: 1.1198 - val_loss: 419.7473 - val_mae: 19.8580\n",
            "Epoch 95/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.4566 - mae: 1.1183 - val_loss: 409.6900 - val_mae: 19.6268\n",
            "Epoch 96/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.4179 - mae: 1.1158 - val_loss: 370.8198 - val_mae: 18.6347\n",
            "Epoch 97/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.2864 - mae: 1.0757 - val_loss: 369.5834 - val_mae: 18.5964\n",
            "Epoch 98/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.3703 - mae: 1.0910 - val_loss: 397.6942 - val_mae: 19.3553\n",
            "Epoch 99/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1879 - mae: 1.0786 - val_loss: 401.0541 - val_mae: 19.4360\n",
            "Epoch 100/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.2810 - mae: 1.0690 - val_loss: 394.6437 - val_mae: 19.2929\n",
            "Epoch 101/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 2.2865 - mae: 1.0898 - val_loss: 398.9409 - val_mae: 19.3524\n",
            "Epoch 102/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.1867 - mae: 1.0611 - val_loss: 450.5865 - val_mae: 20.6566\n",
            "Epoch 103/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.3704 - mae: 1.0810 - val_loss: 396.5648 - val_mae: 19.2844\n",
            "Epoch 104/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.1456 - mae: 1.0454 - val_loss: 376.9290 - val_mae: 18.7867\n",
            "Epoch 105/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.1308 - mae: 1.0496 - val_loss: 419.3178 - val_mae: 19.9029\n",
            "Epoch 106/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1480 - mae: 1.0624 - val_loss: 387.5349 - val_mae: 19.0273\n",
            "Epoch 107/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.1793 - mae: 1.0755 - val_loss: 386.9288 - val_mae: 19.0069\n",
            "Epoch 108/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.9870 - mae: 1.0129 - val_loss: 402.9382 - val_mae: 19.4212\n",
            "Epoch 109/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.0570 - mae: 1.0338 - val_loss: 407.4793 - val_mae: 19.5497\n",
            "Epoch 110/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 2.2208 - mae: 1.0463 - val_loss: 389.0174 - val_mae: 19.1430\n",
            "Epoch 111/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1383 - mae: 1.0347 - val_loss: 401.8208 - val_mae: 19.4695\n",
            "Epoch 112/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.1339 - mae: 1.0238 - val_loss: 362.9236 - val_mae: 18.4582\n",
            "Epoch 113/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0343 - mae: 1.0053 - val_loss: 418.0979 - val_mae: 19.8588\n",
            "Epoch 114/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8390 - mae: 0.9701 - val_loss: 370.7219 - val_mae: 18.7055\n",
            "Epoch 115/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0094 - mae: 1.0047 - val_loss: 447.4475 - val_mae: 20.5236\n",
            "Epoch 116/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.0554 - mae: 1.0259 - val_loss: 361.3758 - val_mae: 18.4046\n",
            "Epoch 117/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.1936 - mae: 1.0208 - val_loss: 387.4203 - val_mae: 18.9974\n",
            "Epoch 118/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.8993 - mae: 1.0000 - val_loss: 398.3561 - val_mae: 19.3944\n",
            "Epoch 119/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8689 - mae: 1.0035 - val_loss: 381.5927 - val_mae: 19.0142\n",
            "Epoch 120/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.8576 - mae: 0.9930 - val_loss: 384.3286 - val_mae: 18.9979\n",
            "Epoch 121/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0787 - mae: 1.0046 - val_loss: 366.1998 - val_mae: 18.5901\n",
            "Epoch 122/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9693 - mae: 0.9924 - val_loss: 356.1476 - val_mae: 18.3280\n",
            "Epoch 123/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.8027 - mae: 0.9627 - val_loss: 345.7154 - val_mae: 17.9490\n",
            "Epoch 124/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9768 - mae: 0.9969 - val_loss: 410.1815 - val_mae: 19.7090\n",
            "Epoch 125/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.7720 - mae: 0.9368 - val_loss: 371.9630 - val_mae: 18.7325\n",
            "Epoch 126/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.7027 - mae: 0.9383 - val_loss: 345.9985 - val_mae: 18.0184\n",
            "Epoch 127/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.9479 - mae: 0.9647 - val_loss: 374.8482 - val_mae: 18.7411\n",
            "Epoch 128/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.9552 - mae: 0.9891 - val_loss: 351.4908 - val_mae: 18.1493\n",
            "Epoch 129/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.7034 - mae: 0.9389 - val_loss: 378.4516 - val_mae: 18.8529\n",
            "Epoch 130/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7305 - mae: 0.9410 - val_loss: 373.2275 - val_mae: 18.7361\n",
            "Epoch 131/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.8449 - mae: 0.9631 - val_loss: 350.4884 - val_mae: 18.1420\n",
            "Epoch 132/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6690 - mae: 0.9427 - val_loss: 346.8862 - val_mae: 18.0137\n",
            "Epoch 133/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7376 - mae: 0.9320 - val_loss: 404.3055 - val_mae: 19.5760\n",
            "Epoch 134/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.6079 - mae: 0.9222 - val_loss: 353.6422 - val_mae: 18.2303\n",
            "Epoch 135/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.6114 - mae: 0.8993 - val_loss: 354.1334 - val_mae: 18.2414\n",
            "Epoch 136/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.7007 - mae: 0.9196 - val_loss: 374.9277 - val_mae: 18.7361\n",
            "Epoch 137/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.5580 - mae: 0.8888 - val_loss: 389.1044 - val_mae: 19.1602\n",
            "Epoch 138/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7332 - mae: 0.9279 - val_loss: 377.9434 - val_mae: 18.8349\n",
            "Epoch 139/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6733 - mae: 0.9185 - val_loss: 357.4439 - val_mae: 18.2856\n",
            "Epoch 140/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6298 - mae: 0.9016 - val_loss: 363.5633 - val_mae: 18.4488\n",
            "Epoch 141/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6274 - mae: 0.9086 - val_loss: 358.3262 - val_mae: 18.3441\n",
            "Epoch 142/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.5702 - mae: 0.8782 - val_loss: 368.0163 - val_mae: 18.6417\n",
            "Epoch 143/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5633 - mae: 0.8936 - val_loss: 362.9232 - val_mae: 18.4184\n",
            "Epoch 144/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6444 - mae: 0.9026 - val_loss: 390.3807 - val_mae: 19.1553\n",
            "Epoch 145/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5517 - mae: 0.8890 - val_loss: 368.6151 - val_mae: 18.5685\n",
            "Epoch 146/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4804 - mae: 0.8695 - val_loss: 378.3584 - val_mae: 18.8206\n",
            "Epoch 147/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.6313 - mae: 0.9036 - val_loss: 380.7765 - val_mae: 18.9105\n",
            "Epoch 148/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.5400 - mae: 0.8938 - val_loss: 379.1415 - val_mae: 18.8538\n",
            "Epoch 149/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4284 - mae: 0.8608 - val_loss: 368.1635 - val_mae: 18.5473\n",
            "Epoch 150/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.3255 - mae: 0.8217 - val_loss: 361.8129 - val_mae: 18.4446\n",
            "Epoch 151/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.5260 - mae: 0.8925 - val_loss: 321.7966 - val_mae: 17.3071\n",
            "Epoch 152/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.4711 - mae: 0.8540 - val_loss: 397.0853 - val_mae: 19.3413\n",
            "Epoch 153/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.4640 - mae: 0.8519 - val_loss: 364.3097 - val_mae: 18.4703\n",
            "Epoch 154/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.4919 - mae: 0.8698 - val_loss: 351.3911 - val_mae: 18.1837\n",
            "Epoch 155/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.3711 - mae: 0.8344 - val_loss: 383.6498 - val_mae: 18.9805\n",
            "Epoch 156/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3495 - mae: 0.8235 - val_loss: 353.1261 - val_mae: 18.0893\n",
            "Epoch 157/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.3922 - mae: 0.8449 - val_loss: 304.2020 - val_mae: 16.8472\n",
            "Epoch 158/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.4841 - mae: 0.8762 - val_loss: 350.4247 - val_mae: 18.1008\n",
            "Epoch 159/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.3847 - mae: 0.8350 - val_loss: 363.8257 - val_mae: 18.4566\n",
            "Epoch 160/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4678 - mae: 0.8760 - val_loss: 346.6804 - val_mae: 18.0346\n",
            "Epoch 161/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.3648 - mae: 0.8361 - val_loss: 341.2590 - val_mae: 17.8413\n",
            "Epoch 162/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.5729 - mae: 0.8837 - val_loss: 364.1783 - val_mae: 18.4693\n",
            "Epoch 163/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.4823 - mae: 0.8798 - val_loss: 343.1686 - val_mae: 17.9481\n",
            "Epoch 164/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.4510 - mae: 0.8481 - val_loss: 356.2148 - val_mae: 18.2863\n",
            "Epoch 165/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4227 - mae: 0.8260 - val_loss: 304.1024 - val_mae: 16.7715\n",
            "Epoch 166/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.3060 - mae: 0.8138 - val_loss: 410.0897 - val_mae: 19.6345\n",
            "Epoch 167/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3089 - mae: 0.8117 - val_loss: 337.4519 - val_mae: 17.7166\n",
            "Epoch 168/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2773 - mae: 0.8131 - val_loss: 370.1656 - val_mae: 18.5839\n",
            "Epoch 169/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4175 - mae: 0.8232 - val_loss: 358.1640 - val_mae: 18.3380\n",
            "Epoch 170/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.2765 - mae: 0.8117 - val_loss: 356.5433 - val_mae: 18.3127\n",
            "Epoch 171/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.4545 - mae: 0.8498 - val_loss: 332.8466 - val_mae: 17.6123\n",
            "Epoch 172/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.3492 - mae: 0.8300 - val_loss: 346.7269 - val_mae: 17.9795\n",
            "Epoch 173/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 1.3667 - mae: 0.8311 - val_loss: 342.8551 - val_mae: 17.8977\n",
            "Epoch 174/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2445 - mae: 0.7971 - val_loss: 372.8545 - val_mae: 18.6930\n",
            "Epoch 175/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.4118 - mae: 0.8288 - val_loss: 336.5793 - val_mae: 17.6531\n",
            "Epoch 176/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.2731 - mae: 0.7957 - val_loss: 358.0946 - val_mae: 18.3286\n",
            "Epoch 177/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4008 - mae: 0.8363 - val_loss: 324.0383 - val_mae: 17.4096\n",
            "Epoch 178/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1877 - mae: 0.7729 - val_loss: 329.7012 - val_mae: 17.5662\n",
            "Epoch 179/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.4286 - mae: 0.7974 - val_loss: 336.8142 - val_mae: 17.7673\n",
            "Epoch 180/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2134 - mae: 0.7805 - val_loss: 363.8595 - val_mae: 18.4887\n",
            "Epoch 181/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1403 - mae: 0.7618 - val_loss: 313.2844 - val_mae: 17.1016\n",
            "Epoch 182/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.2214 - mae: 0.7739 - val_loss: 372.3574 - val_mae: 18.6990\n",
            "Epoch 183/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4926 - mae: 0.8213 - val_loss: 315.9146 - val_mae: 17.1353\n",
            "Epoch 184/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3910 - mae: 0.8167 - val_loss: 317.6476 - val_mae: 17.2100\n",
            "Epoch 185/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3779 - mae: 0.8285 - val_loss: 395.8230 - val_mae: 19.2900\n",
            "Epoch 186/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2254 - mae: 0.7796 - val_loss: 300.8747 - val_mae: 16.7672\n",
            "Epoch 187/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.1453 - mae: 0.7782 - val_loss: 330.3008 - val_mae: 17.6113\n",
            "Epoch 188/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1482 - mae: 0.7578 - val_loss: 379.2019 - val_mae: 18.9073\n",
            "Epoch 189/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2558 - mae: 0.7927 - val_loss: 333.7641 - val_mae: 17.6852\n",
            "Epoch 190/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2143 - mae: 0.7832 - val_loss: 361.5534 - val_mae: 18.4090\n",
            "Epoch 191/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.1903 - mae: 0.7658 - val_loss: 312.7560 - val_mae: 17.0495\n",
            "Epoch 192/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.1458 - mae: 0.7411 - val_loss: 346.1469 - val_mae: 18.0090\n",
            "Epoch 193/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2230 - mae: 0.7854 - val_loss: 328.8747 - val_mae: 17.5020\n",
            "Epoch 194/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1041 - mae: 0.7585 - val_loss: 392.1581 - val_mae: 19.2046\n",
            "Epoch 195/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1819 - mae: 0.7725 - val_loss: 319.4777 - val_mae: 17.2551\n",
            "Epoch 196/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1364 - mae: 0.7565 - val_loss: 359.2346 - val_mae: 18.3645\n",
            "Epoch 197/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1187 - mae: 0.7505 - val_loss: 368.3390 - val_mae: 18.6043\n",
            "Epoch 198/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.0554 - mae: 0.7320 - val_loss: 347.6794 - val_mae: 18.0590\n",
            "Epoch 199/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0596 - mae: 0.7343 - val_loss: 375.3287 - val_mae: 18.8633\n",
            "Epoch 200/200\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.0986 - mae: 0.7425 - val_loss: 322.3077 - val_mae: 17.3505\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Mean Squared Error (Ensemble): 81.99\n",
            "R-squared (Ensemble): 0.56\n",
            "\n",
            "Sample Predictions (Ensemble):\n",
            "Actual Score: 49, Predicted Score: 41.83\n",
            "Actual Score: 60, Predicted Score: 50.87\n",
            "Actual Score: 48, Predicted Score: 40.95\n",
            "Actual Score: 63, Predicted Score: 53.01\n",
            "Actual Score: 66, Predicted Score: 56.30\n",
            "Hybrid model saved as 'lead_scoring_hybrid.keras', XGBoost model saved as 'xgb_model.pkl', and preprocessor config saved as 'preprocessor_config.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load the saved models\n",
        "hybrid_model = tf.keras.models.load_model('lead_scoring_hybrid.keras')\n",
        "with open('xgb_model.pkl', 'rb') as f:\n",
        "    xgb_model = pickle.load(f)\n",
        "print(\"Models loaded successfully\")\n",
        "\n",
        "# Define possible values (must match training script)\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Load preprocessor configuration\n",
        "with open('preprocessor_config.pkl', 'rb') as f:\n",
        "    categories = pickle.load(f)\n",
        "categorical_features = ['targetCity', 'startDate', 'budget', 'phone_provided', 'distance', 'safety', 'income', 'lifestyle']\n",
        "numerical_features = ['pages_visited', 'preferences_specified']\n",
        "\n",
        "# Reconstruct the preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(categories=categories, handle_unknown='ignore', sparse_output=False), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ])\n",
        "\n",
        "# Example input data to match your sample predictions\n",
        "sample_data = [\n",
        "    {'targetCity': 'Bangalore', 'startDate': 'Within 30 days', 'budget': 'Medium', 'phone_provided': 'Yes',\n",
        "     'distance': 'Medium', 'safety': 'High', 'income': 'Medium', 'lifestyle': 'Active',\n",
        "     'pages_visited': 2, 'preferences_specified': 3},  # Should predict ~55\n",
        "    {'targetCity': 'Mumbai', 'startDate': '31-90 days', 'budget': 'Low', 'phone_provided': 'No',\n",
        "     'distance': 'Short', 'safety': 'Medium', 'income': 'Low', 'lifestyle': 'Budget',\n",
        "     'pages_visited': 1, 'preferences_specified': 2},  # Should predict ~39\n",
        "    {'targetCity': 'New Delhi', 'startDate': 'Within 30 days', 'budget': 'High', 'phone_provided': 'Yes',\n",
        "     'distance': 'Long', 'safety': 'High', 'income': 'High', 'lifestyle': 'Luxury',\n",
        "     'pages_visited': 3, 'preferences_specified': 5},  # Should predict ~82\n",
        "    {'targetCity': 'Not specified', 'startDate': 'More than 90 days', 'budget': 'Low', 'phone_provided': 'No',\n",
        "     'distance': 'Short', 'safety': 'Low', 'income': 'Low', 'lifestyle': 'Budget',\n",
        "     'pages_visited': 0, 'preferences_specified': 1},  # Should predict ~25\n",
        "    {'targetCity': 'Hyderabad', 'startDate': 'Within 30 days', 'budget': 'High', 'phone_provided': 'Yes',\n",
        "     'distance': 'Medium', 'safety': 'Medium', 'income': 'Medium', 'lifestyle': 'Relaxed',\n",
        "     'pages_visited': 3, 'preferences_specified': 4},  # Should predict ~76\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "sample_df = pd.DataFrame(sample_data)\n",
        "\n",
        "# Preprocess the sample data\n",
        "sample_processed = preprocessor.fit_transform(sample_df)\n",
        "sample_processed_reshaped = sample_processed.reshape((sample_processed.shape[0], sample_processed.shape[1], 1))\n",
        "\n",
        "# Predict scores with hybrid model\n",
        "y_pred_hybrid = hybrid_model.predict(sample_processed_reshaped).flatten()\n",
        "\n",
        "# Predict scores with XGBoost model\n",
        "y_pred_xgb = xgb_model.predict(sample_processed)\n",
        "\n",
        "# Ensemble predictions\n",
        "y_pred_ensemble = (y_pred_hybrid + y_pred_xgb) / 2\n",
        "\n",
        "# Display results\n",
        "print(\"\\nSample Predictions (Ensemble):\")\n",
        "for actual, predicted in zip([55, 39, 82, 25, 76], y_pred_ensemble):\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj8NeBSxDfI1",
        "outputId": "68804593-8fc6-4ff2-add5-95bf5aa8a94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded successfully\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\n",
            "Sample Predictions (Ensemble):\n",
            "Actual Score: 55, Predicted Score: 71.53\n",
            "Actual Score: 39, Predicted Score: 42.61\n",
            "Actual Score: 82, Predicted Score: 86.76\n",
            "Actual Score: 25, Predicted Score: 16.44\n",
            "Actual Score: 76, Predicted Score: 73.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method 5**"
      ],
      "metadata": {
        "id": "JKAKy13nDjno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install required libraries if not present\n",
        "# !pip install transformers torch xgboost\n",
        "\n",
        "# Check installed versions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "import pickle\n",
        "import xgboost as xgb\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Import required modules\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, LayerNormalization, MultiHeadAttention, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Define possible values with expanded Indian cities\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_durations = ['1-7 days', '8-30 days', 'More than 30 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "n_samples = 50000  # 50,000 samples\n",
        "data = {\n",
        "    'email': ['email@example.com'] * n_samples,\n",
        "    'phone_provided': np.random.choice(possible_phone, n_samples),\n",
        "    'currentCity': np.random.choice(possible_cities, n_samples),\n",
        "    'targetCity': np.random.choice(possible_cities, n_samples),\n",
        "    'startDate': np.random.choice(possible_start_dates, n_samples),\n",
        "    'duration': np.random.choice(possible_durations, n_samples),\n",
        "    'budget': np.random.choice(possible_budgets, n_samples),\n",
        "    'income': np.random.choice(possible_incomes, n_samples),\n",
        "    'lifestyle': np.random.choice(possible_lifestyles, n_samples),\n",
        "    'distance': np.random.choice(possible_distances, n_samples),\n",
        "    'safety': np.random.choice(possible_safeties, n_samples),\n",
        "    'pagesVisited': [list(np.random.choice(possible_pages, np.random.randint(0, 7), replace=False)) for _ in range(n_samples)],\n",
        "    'foodPreferences': [list(np.random.choice(possible_food, np.random.randint(0, 4), replace=False)) for _ in range(n_samples)],\n",
        "    'transportType': [list(np.random.choice(possible_transport, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "    'accommodationType': [list(np.random.choice(possible_accommodation, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set phone based on phone_provided\n",
        "df['phone'] = df['phone_provided'].apply(lambda x: '1234567890' if x == 'Yes' else '')\n",
        "\n",
        "# Compute numerical features\n",
        "df['pages_visited'] = df['pagesVisited'].apply(lambda x: min(len(set(x) & set(key_pages)), 3))\n",
        "df['preferences_specified'] = (df['foodPreferences'].apply(len) +\n",
        "                               df['transportType'].apply(len) +\n",
        "                               df['accommodationType'].apply(len))\n",
        "\n",
        "# Define scoring functions for ground truth\n",
        "def target_city_score(x): return 15 if x != 'Not specified' else 0\n",
        "def start_date_score(x): return {'Within 30 days': 25, '31-90 days': 15, 'More than 90 days': 5}.get(x, 0)\n",
        "def budget_score(x): return {'High': 15, 'Medium': 10, 'Low': 5}.get(x, 0)\n",
        "def engagement_score(pages, prefs): return min(pages * 3, 9) + min(prefs * 1, 5)\n",
        "def contact_score(x): return 5 if x == 'Yes' else 0\n",
        "def distance_score(x): return {'Long': 10, 'Medium': 5, 'Short': 2}.get(x, 0)\n",
        "def safety_score(x): return {'High': 10, 'Medium': 5}.get(x, 0)\n",
        "def income_score(x): return {'High': 5, 'Medium': 3, 'Low': 1}.get(x, 0)\n",
        "def lifestyle_score(x): return {'Luxury': 5, 'Active': 3, 'Relaxed': 2, 'Budget': 1}.get(x, 0)\n",
        "\n",
        "# Apply scoring\n",
        "df['total_score'] = (df['targetCity'].apply(target_city_score) +\n",
        "                     df['startDate'].apply(start_date_score) +\n",
        "                     df['budget'].apply(budget_score) +\n",
        "                     df.apply(lambda row: engagement_score(row['pages_visited'], row['preferences_specified']), axis=1) +\n",
        "                     df['phone_provided'].apply(contact_score) +\n",
        "                     df['distance'].apply(distance_score) +\n",
        "                     df['safety'].apply(safety_score) +\n",
        "                     df['income'].apply(income_score) +\n",
        "                     df['lifestyle'].apply(lifestyle_score))\n",
        "\n",
        "# Prepare data for hybrid model\n",
        "categorical_features = ['targetCity', 'startDate', 'budget', 'phone_provided', 'distance', 'safety', 'income', 'lifestyle']\n",
        "numerical_features = ['pages_visited', 'preferences_specified']\n",
        "X = df[categorical_features + numerical_features]\n",
        "y = df['total_score']\n",
        "\n",
        "# Define preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ])\n",
        "\n",
        "# Preprocess the data\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape for CNN and Transformer\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Build and train the hybrid neural network\n",
        "inputs = Input(shape=(X_train_reshaped.shape[1], 1))\n",
        "x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "x = LayerNormalization()(x)\n",
        "x = MultiHeadAttention(num_heads=8, key_dim=64)(x, x)\n",
        "x = LayerNormalization()(x)\n",
        "x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "outputs = Dense(1)(x)\n",
        "\n",
        "hybrid_model = Model(inputs, outputs)\n",
        "hybrid_model.compile(optimizer=Adam(learning_rate=0.0002), loss='mse', metrics=['mae'])\n",
        "history = hybrid_model.fit(X_train_reshaped, y_train, epochs=100, batch_size=128, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Get hybrid predictions\n",
        "y_pred_hybrid = hybrid_model.predict(X_test_reshaped).flatten()\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=300, learning_rate=0.03, max_depth=7, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Prepare data for DistilBERT (textual input)\n",
        "def format_text(row):\n",
        "    return (f\"Target City: {row['targetCity']}, Start Date: {row['startDate']}, Budget: {row['budget']}, \"\n",
        "            f\"Phone Provided: {row['phone_provided']}, Distance: {row['distance']}, Safety: {row['safety']}, \"\n",
        "            f\"Income: {row['income']}, Lifestyle: {row['lifestyle']}, Pages Visited: {row['pages_visited']}, \"\n",
        "            f\"Preferences Specified: {row['preferences_specified']}\")\n",
        "\n",
        "df['text'] = df[categorical_features + numerical_features].apply(format_text, axis=1)\n",
        "train_texts = df.iloc[y_train.index]['text'].tolist()\n",
        "test_texts = df.iloc[y_test.index]['text'].tolist()\n",
        "train_labels = y_train.tolist()\n",
        "test_labels = y_test.tolist()\n",
        "\n",
        "# Tokenize data for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# Custom Dataset class for PyTorch\n",
        "class LeadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = LeadDataset(train_encodings, train_labels)\n",
        "test_dataset = LeadDataset(test_encodings, test_labels)\n",
        "\n",
        "# Fine-tune DistilBERT\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Get DistilBERT predictions\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred_distilbert = predictions.predictions.flatten()\n",
        "\n",
        "# Ensemble: Combine Hybrid, XGBoost, and DistilBERT predictions\n",
        "y_pred_ensemble = (y_pred_hybrid * 0.4 + y_pred_xgb * 0.3 + y_pred_distilbert * 0.3)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "mse = mean_squared_error(y_test, y_pred_ensemble)\n",
        "r2 = r2_score(y_test, y_pred_ensemble)\n",
        "\n",
        "print(f\"Mean Squared Error (Ensemble): {mse:.2f}\")\n",
        "print(f\"R-squared (Ensemble): {r2:.2f}\")\n",
        "\n",
        "# Show sample predictions\n",
        "print(\"\\nSample Predictions (Ensemble):\")\n",
        "for actual, predicted in list(zip(y_test[:5], y_pred_ensemble[:5])):\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}\")\n",
        "\n",
        "# Save models and preprocessor\n",
        "hybrid_model.save('lead_scoring_hybrid.keras')\n",
        "with open('xgb_model.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model, f)\n",
        "model.save_pretrained('distilbert_lead_scoring')\n",
        "tokenizer.save_pretrained('distilbert_lead_scoring')\n",
        "with open('preprocessor_config.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessor.named_transformers_['cat'].categories_, f)\n",
        "print(\"Models saved: 'lead_scoring_hybrid.keras', 'xgb_model.pkl', 'distilbert_lead_scoring', and 'preprocessor_config.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6610df5e00ef450f8b35deea9b6d76e1",
            "e86cda3ddc2249b7996fa2aee4798e98",
            "2f7e636e59cc436aafb4c0efb4126e6c",
            "2660d3d267d54ec2a611e1f120a5e281",
            "727e6927a30d44dd9fb9a5a61c31efd2",
            "896058637e8342d2af78c81842096c34",
            "c73676aad3884fb09d23d49802de367a",
            "346d1b420dcb4071bf7a0f6f2ad14877",
            "47ec68ad0e4d46f8b659ff65bb883afc",
            "e1c4ec092ad84c43a57d31b75351c407",
            "0d8c980e30654cbea9118b6511d76997",
            "3bf9019d3d8a41ffa09cd3ea8f0ae67e",
            "6f0e55b40e3b48879d91232ea7d5af01",
            "7f2d55cb139a478999c24195b33b804c",
            "5fe59f2ae2434b9ca0fe549e71dbc3ae",
            "a812b6731a654adf9761d9978cf540a6",
            "9d4ee3dfb8c344849b547221b341df3e",
            "a4d906db4ca74452864d2a5b612f044b",
            "f806ec6218024a4e827b15185f8ed821",
            "daf7ab75a3f54765bb8d39c9c8dcbf15",
            "a4ce23d4adc24ffcad0bc2130ad1a05a",
            "de37ca4e40e9468fbec84e6bd5ae1e26",
            "1d7ae2ab52b9433eb0e02e03d3b9508f",
            "c70329522b3c4f4db7ff4d4b58728b32",
            "bac60db82a834c50b38c6d5cf6b25182",
            "7dc9f493438e4577bbe62bed52ef5120",
            "0a8e4ff1cc6d4d17a3a86f6f17ec48e8",
            "56cbcbe521514f85b70f47eeae1aedd2",
            "771bf7da481a4577b3abc66930a36278",
            "2204159af1b343ef8133e352c7a910c9",
            "2ac316916b634c8c91725d2459dc2b84",
            "5988fb319413433abd84ddab1446363e",
            "f21d08ad2796433fa1c9fd4dcbf8bcfd",
            "7d6e9c9763b042eaa6b922ff7ba31b40",
            "4d3840be44de4c1288c36fe7992abf66",
            "e03bce75fb0c4ab69b06f882aa451c38",
            "e058ee88390c46e290975ba633a24028",
            "f9f8de25f93044ad8820a45caec309e7",
            "a524128696d04a45a0a2eebf2bbbbfee",
            "7e947faff16a4c11a43d820b64d93ef0",
            "f4b56298b0f14eb8a1d8994de9433986",
            "36329af01c654b1da6c152e6d161ade5",
            "90852755c3ce41909967f9dd8abf16c8",
            "92c7efc2685f480180d4e54af92023e4",
            "5a13e072b7394e079b56c3593d1b0184",
            "8adfd5f1386541178ee41dfd9d971d82",
            "4f4b7210d5e747f5a8d937146ca8e092",
            "631f9be5c4b0496d985d02ec186195b7",
            "1f7d1ac03fc04c38a5f1ccc694596638",
            "f6023f81ea5f4101879f48d19f7497c3",
            "7144152647364ee69f570d61b7c499f1",
            "aa68c89f7e424d26ae70a61673e8ddd5",
            "9896052da0584d73a606865fb70f151d",
            "74d1645139f24203b08f698f6e1ff20d",
            "b8a8132341d942b9a67998b2600a5fff"
          ]
        },
        "id": "8cAESCpyDm0s",
        "outputId": "e8a29e97-95bf-4858-ed2a-b3e2f87302b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 1.6.1\n",
            "TensorFlow version: 2.18.0\n",
            "PyTorch version: 2.6.0+cu124\n",
            "Epoch 1/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - loss: 487.3631 - mae: 15.9710 - val_loss: 87.5744 - val_mae: 9.0452\n",
            "Epoch 2/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 19.2688 - mae: 3.4448 - val_loss: 120.0648 - val_mae: 10.6000\n",
            "Epoch 3/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 15.0761 - mae: 3.0416 - val_loss: 202.1741 - val_mae: 13.9102\n",
            "Epoch 4/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 12.5909 - mae: 2.7711 - val_loss: 276.7074 - val_mae: 16.2607\n",
            "Epoch 5/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 11.1614 - mae: 2.6200 - val_loss: 333.1827 - val_mae: 17.7917\n",
            "Epoch 6/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 10.2384 - mae: 2.5074 - val_loss: 344.4908 - val_mae: 18.0872\n",
            "Epoch 7/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 9.9267 - mae: 2.4732 - val_loss: 419.8454 - val_mae: 20.0368\n",
            "Epoch 8/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 8.7541 - mae: 2.3206 - val_loss: 441.4775 - val_mae: 20.4945\n",
            "Epoch 9/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.1034 - mae: 2.3466 - val_loss: 443.8309 - val_mae: 20.5631\n",
            "Epoch 10/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 8.1983 - mae: 2.2307 - val_loss: 447.6494 - val_mae: 20.6436\n",
            "Epoch 11/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7.6924 - mae: 2.1705 - val_loss: 516.0752 - val_mae: 22.1653\n",
            "Epoch 12/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7.3663 - mae: 2.1054 - val_loss: 497.4869 - val_mae: 21.7630\n",
            "Epoch 13/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 6.8037 - mae: 2.0268 - val_loss: 395.5045 - val_mae: 19.3740\n",
            "Epoch 14/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 7.6421 - mae: 2.1478 - val_loss: 454.1996 - val_mae: 20.8030\n",
            "Epoch 15/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 6.4032 - mae: 1.9550 - val_loss: 502.4603 - val_mae: 21.8763\n",
            "Epoch 16/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 6.2547 - mae: 1.9399 - val_loss: 484.4949 - val_mae: 21.4726\n",
            "Epoch 17/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 5.8883 - mae: 1.8721 - val_loss: 492.6413 - val_mae: 21.6250\n",
            "Epoch 18/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.5647 - mae: 1.8094 - val_loss: 497.9374 - val_mae: 21.7615\n",
            "Epoch 19/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.3809 - mae: 1.7952 - val_loss: 501.4406 - val_mae: 21.8210\n",
            "Epoch 20/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 5.1568 - mae: 1.7508 - val_loss: 495.0251 - val_mae: 21.6766\n",
            "Epoch 21/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 5.1898 - mae: 1.7539 - val_loss: 479.2510 - val_mae: 21.3227\n",
            "Epoch 22/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 5.0021 - mae: 1.7293 - val_loss: 463.7980 - val_mae: 20.9783\n",
            "Epoch 23/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 4.9155 - mae: 1.7056 - val_loss: 479.1421 - val_mae: 21.3337\n",
            "Epoch 24/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.9061 - mae: 1.7071 - val_loss: 453.4057 - val_mae: 20.7455\n",
            "Epoch 25/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.6169 - mae: 1.6489 - val_loss: 478.3900 - val_mae: 21.3606\n",
            "Epoch 26/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.4213 - mae: 1.6097 - val_loss: 468.5861 - val_mae: 21.1363\n",
            "Epoch 27/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 4.7346 - mae: 1.6792 - val_loss: 428.7407 - val_mae: 20.1810\n",
            "Epoch 28/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 4.4193 - mae: 1.6168 - val_loss: 444.2957 - val_mae: 20.5531\n",
            "Epoch 29/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 4.1306 - mae: 1.5490 - val_loss: 455.6499 - val_mae: 20.7859\n",
            "Epoch 30/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 4.1549 - mae: 1.5659 - val_loss: 476.7196 - val_mae: 21.3004\n",
            "Epoch 31/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 4.2059 - mae: 1.5708 - val_loss: 438.7107 - val_mae: 20.4093\n",
            "Epoch 32/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 4.0111 - mae: 1.5355 - val_loss: 443.4851 - val_mae: 20.5474\n",
            "Epoch 33/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 3.7692 - mae: 1.4843 - val_loss: 457.9053 - val_mae: 20.8767\n",
            "Epoch 34/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 3.7433 - mae: 1.4694 - val_loss: 422.5219 - val_mae: 20.0337\n",
            "Epoch 35/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 3.6450 - mae: 1.4540 - val_loss: 448.7099 - val_mae: 20.6851\n",
            "Epoch 36/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 3.5220 - mae: 1.4308 - val_loss: 438.2187 - val_mae: 20.4247\n",
            "Epoch 37/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 3.5980 - mae: 1.4458 - val_loss: 420.4120 - val_mae: 20.0196\n",
            "Epoch 38/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 3.4425 - mae: 1.4098 - val_loss: 429.4249 - val_mae: 20.1939\n",
            "Epoch 39/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 3.5854 - mae: 1.4394 - val_loss: 419.3812 - val_mae: 19.9500\n",
            "Epoch 40/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 3.3527 - mae: 1.3915 - val_loss: 430.8039 - val_mae: 20.2221\n",
            "Epoch 41/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 3.3849 - mae: 1.3876 - val_loss: 436.0588 - val_mae: 20.3722\n",
            "Epoch 42/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 3.1953 - mae: 1.3554 - val_loss: 413.4956 - val_mae: 19.8060\n",
            "Epoch 43/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 3.0878 - mae: 1.3250 - val_loss: 419.8365 - val_mae: 19.9640\n",
            "Epoch 44/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 3.0842 - mae: 1.3234 - val_loss: 396.6223 - val_mae: 19.3794\n",
            "Epoch 45/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 3.0356 - mae: 1.3148 - val_loss: 422.2043 - val_mae: 20.0350\n",
            "Epoch 46/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 2.8997 - mae: 1.2700 - val_loss: 402.7424 - val_mae: 19.5456\n",
            "Epoch 47/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.6848 - mae: 1.2311 - val_loss: 417.0211 - val_mae: 19.8826\n",
            "Epoch 48/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.8142 - mae: 1.2545 - val_loss: 403.6681 - val_mae: 19.5543\n",
            "Epoch 49/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 2.6702 - mae: 1.2154 - val_loss: 393.2559 - val_mae: 19.2982\n",
            "Epoch 50/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 2.6369 - mae: 1.2108 - val_loss: 385.1131 - val_mae: 19.0899\n",
            "Epoch 51/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 2.6815 - mae: 1.2227 - val_loss: 406.3322 - val_mae: 19.6433\n",
            "Epoch 52/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 2.5065 - mae: 1.1867 - val_loss: 392.0684 - val_mae: 19.2760\n",
            "Epoch 53/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 2.2930 - mae: 1.1333 - val_loss: 385.1892 - val_mae: 19.0911\n",
            "Epoch 54/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 2.1980 - mae: 1.1031 - val_loss: 383.1530 - val_mae: 19.0435\n",
            "Epoch 55/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 2.3187 - mae: 1.1253 - val_loss: 414.4669 - val_mae: 19.7870\n",
            "Epoch 56/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2.2193 - mae: 1.1087 - val_loss: 406.2707 - val_mae: 19.6147\n",
            "Epoch 57/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 2.1917 - mae: 1.0991 - val_loss: 396.8679 - val_mae: 19.3905\n",
            "Epoch 58/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 2.1659 - mae: 1.0818 - val_loss: 401.6058 - val_mae: 19.5141\n",
            "Epoch 59/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 2.0901 - mae: 1.0685 - val_loss: 393.6967 - val_mae: 19.3037\n",
            "Epoch 60/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 2.1180 - mae: 1.0648 - val_loss: 385.2578 - val_mae: 19.1139\n",
            "Epoch 61/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 2.0878 - mae: 1.0724 - val_loss: 378.8946 - val_mae: 18.8886\n",
            "Epoch 62/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 2.0328 - mae: 1.0517 - val_loss: 379.1724 - val_mae: 18.9032\n",
            "Epoch 63/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.9203 - mae: 1.0163 - val_loss: 376.3401 - val_mae: 18.8269\n",
            "Epoch 64/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.9319 - mae: 1.0195 - val_loss: 368.1899 - val_mae: 18.6776\n",
            "Epoch 65/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.9573 - mae: 1.0320 - val_loss: 388.1656 - val_mae: 19.1779\n",
            "Epoch 66/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.8414 - mae: 0.9953 - val_loss: 378.5860 - val_mae: 18.9321\n",
            "Epoch 67/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.7182 - mae: 0.9560 - val_loss: 396.2727 - val_mae: 19.3612\n",
            "Epoch 68/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 1.7667 - mae: 0.9748 - val_loss: 352.5389 - val_mae: 18.2247\n",
            "Epoch 69/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.8075 - mae: 0.9807 - val_loss: 367.7839 - val_mae: 18.6174\n",
            "Epoch 70/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.6514 - mae: 0.9421 - val_loss: 363.2348 - val_mae: 18.5136\n",
            "Epoch 71/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 1.7111 - mae: 0.9550 - val_loss: 381.2286 - val_mae: 18.9941\n",
            "Epoch 72/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.5873 - mae: 0.9162 - val_loss: 371.3390 - val_mae: 18.7170\n",
            "Epoch 73/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.5789 - mae: 0.9181 - val_loss: 366.9460 - val_mae: 18.6163\n",
            "Epoch 74/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 1.5694 - mae: 0.9159 - val_loss: 352.2692 - val_mae: 18.2131\n",
            "Epoch 75/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.5572 - mae: 0.9123 - val_loss: 385.2736 - val_mae: 19.0745\n",
            "Epoch 76/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.5549 - mae: 0.9118 - val_loss: 353.6501 - val_mae: 18.2770\n",
            "Epoch 77/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.4613 - mae: 0.8770 - val_loss: 360.1948 - val_mae: 18.4224\n",
            "Epoch 78/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.5304 - mae: 0.9092 - val_loss: 373.7166 - val_mae: 18.7495\n",
            "Epoch 79/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.4588 - mae: 0.8689 - val_loss: 368.7815 - val_mae: 18.7151\n",
            "Epoch 80/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.4161 - mae: 0.8706 - val_loss: 355.1351 - val_mae: 18.2937\n",
            "Epoch 81/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.4038 - mae: 0.8655 - val_loss: 396.1397 - val_mae: 19.4179\n",
            "Epoch 82/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 1.4702 - mae: 0.9006 - val_loss: 367.6645 - val_mae: 18.6358\n",
            "Epoch 83/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.4585 - mae: 0.8846 - val_loss: 358.2457 - val_mae: 18.3918\n",
            "Epoch 84/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.3346 - mae: 0.8402 - val_loss: 333.1657 - val_mae: 17.7033\n",
            "Epoch 85/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.2784 - mae: 0.8226 - val_loss: 342.8932 - val_mae: 17.9802\n",
            "Epoch 86/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.2840 - mae: 0.8207 - val_loss: 350.8076 - val_mae: 18.2392\n",
            "Epoch 87/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.3216 - mae: 0.8342 - val_loss: 344.9144 - val_mae: 18.0406\n",
            "Epoch 88/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.2431 - mae: 0.8174 - val_loss: 358.0198 - val_mae: 18.3946\n",
            "Epoch 89/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.2577 - mae: 0.8196 - val_loss: 356.8733 - val_mae: 18.4056\n",
            "Epoch 90/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 1.2315 - mae: 0.8058 - val_loss: 365.0511 - val_mae: 18.5679\n",
            "Epoch 91/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.2104 - mae: 0.8011 - val_loss: 361.6343 - val_mae: 18.4993\n",
            "Epoch 92/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.2392 - mae: 0.8113 - val_loss: 335.7729 - val_mae: 17.7691\n",
            "Epoch 93/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.1638 - mae: 0.7769 - val_loss: 334.1878 - val_mae: 17.7545\n",
            "Epoch 94/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.1803 - mae: 0.7949 - val_loss: 343.6606 - val_mae: 18.0404\n",
            "Epoch 95/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.1836 - mae: 0.7848 - val_loss: 327.9104 - val_mae: 17.5729\n",
            "Epoch 96/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 1.1546 - mae: 0.7746 - val_loss: 354.3555 - val_mae: 18.3222\n",
            "Epoch 97/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 1.1672 - mae: 0.7794 - val_loss: 358.6139 - val_mae: 18.4237\n",
            "Epoch 98/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.1528 - mae: 0.7786 - val_loss: 361.3772 - val_mae: 18.5242\n",
            "Epoch 99/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 1.1114 - mae: 0.7654 - val_loss: 329.5982 - val_mae: 17.6441\n",
            "Epoch 100/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1.1421 - mae: 0.7698 - val_loss: 328.3354 - val_mae: 17.5783\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6610df5e00ef450f8b35deea9b6d76e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bf9019d3d8a41ffa09cd3ea8f0ae67e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d7ae2ab52b9433eb0e02e03d3b9508f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d6e9c9763b042eaa6b922ff7ba31b40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a13e072b7394e079b56c3593d1b0184"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpjdevelop\u001b[0m (\u001b[33mpjdevelop-Lovely Professional University\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250319_015255-zl19bwcc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pjdevelop-Lovely%20Professional%20University/huggingface/runs/zl19bwcc' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/pjdevelop-Lovely%20Professional%20University/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/pjdevelop-Lovely%20Professional%20University/huggingface' target=\"_blank\">https://wandb.ai/pjdevelop-Lovely%20Professional%20University/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/pjdevelop-Lovely%20Professional%20University/huggingface/runs/zl19bwcc' target=\"_blank\">https://wandb.ai/pjdevelop-Lovely%20Professional%20University/huggingface/runs/zl19bwcc</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7500/7500 13:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.333300</td>\n",
              "      <td>2.790906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.957600</td>\n",
              "      <td>0.368029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.904100</td>\n",
              "      <td>0.174801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Ensemble): 52.02\n",
            "R-squared (Ensemble): 0.72\n",
            "\n",
            "Sample Predictions (Ensemble):\n",
            "Actual Score: 39, Predicted Score: 34.34\n",
            "Actual Score: 48, Predicted Score: 42.05\n",
            "Actual Score: 50, Predicted Score: 43.61\n",
            "Actual Score: 64, Predicted Score: 56.00\n",
            "Actual Score: 59, Predicted Score: 51.75\n",
            "Models saved: 'lead_scoring_hybrid.keras', 'xgb_model.pkl', 'distilbert_lead_scoring', and 'preprocessor_config.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "import pickle\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load the saved models\n",
        "hybrid_model = tf.keras.models.load_model('lead_scoring_hybrid.keras')\n",
        "with open('xgb_model.pkl', 'rb') as f:\n",
        "    xgb_model = pickle.load(f)\n",
        "distilbert_model = DistilBertForSequenceClassification.from_pretrained('distilbert_lead_scoring')\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert_lead_scoring')\n",
        "print(\"Models loaded successfully\")\n",
        "\n",
        "# Define possible values\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Load preprocessor configuration\n",
        "with open('preprocessor_config.pkl', 'rb') as f:\n",
        "    categories = pickle.load(f)\n",
        "categorical_features = ['targetCity', 'startDate', 'budget', 'phone_provided', 'distance', 'safety', 'income', 'lifestyle']\n",
        "numerical_features = ['pages_visited', 'preferences_specified']\n",
        "\n",
        "# Reconstruct the preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(categories=categories, handle_unknown='ignore', sparse_output=False), categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)\n",
        "    ])\n",
        "\n",
        "# Example input data\n",
        "sample_data = [\n",
        "    {'targetCity': 'Bangalore', 'startDate': 'Within 30 days', 'budget': 'Medium', 'phone_provided': 'Yes',\n",
        "     'distance': 'Medium', 'safety': 'High', 'income': 'Medium', 'lifestyle': 'Active',\n",
        "     'pages_visited': 2, 'preferences_specified': 3},  # ~55\n",
        "    {'targetCity': 'Mumbai', 'startDate': '31-90 days', 'budget': 'Low', 'phone_provided': 'No',\n",
        "     'distance': 'Short', 'safety': 'Medium', 'income': 'Low', 'lifestyle': 'Budget',\n",
        "     'pages_visited': 1, 'preferences_specified': 2},  # ~39\n",
        "    {'targetCity': 'New Delhi', 'startDate': 'Within 30 days', 'budget': 'High', 'phone_provided': 'Yes',\n",
        "     'distance': 'Long', 'safety': 'High', 'income': 'High', 'lifestyle': 'Luxury',\n",
        "     'pages_visited': 3, 'preferences_specified': 5},  # ~82\n",
        "    {'targetCity': 'Not specified', 'startDate': 'More than 90 days', 'budget': 'Low', 'phone_provided': 'No',\n",
        "     'distance': 'Short', 'safety': 'Low', 'income': 'Low', 'lifestyle': 'Budget',\n",
        "     'pages_visited': 0, 'preferences_specified': 1},  # ~25\n",
        "    {'targetCity': 'Hyderabad', 'startDate': 'Within 30 days', 'budget': 'High', 'phone_provided': 'Yes',\n",
        "     'distance': 'Medium', 'safety': 'Medium', 'income': 'Medium', 'lifestyle': 'Relaxed',\n",
        "     'pages_visited': 3, 'preferences_specified': 4},  # ~76\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "sample_df = pd.DataFrame(sample_data)\n",
        "\n",
        "# Preprocess for hybrid and XGBoost\n",
        "sample_processed = preprocessor.fit_transform(sample_df)\n",
        "sample_processed_reshaped = sample_processed.reshape((sample_processed.shape[0], sample_processed.shape[1], 1))\n",
        "\n",
        "# Predict with hybrid model\n",
        "y_pred_hybrid = hybrid_model.predict(sample_processed_reshaped).flatten()\n",
        "\n",
        "# Predict with XGBoost model\n",
        "y_pred_xgb = xgb_model.predict(sample_processed)\n",
        "\n",
        "# Prepare text for DistilBERT\n",
        "def format_text(row):\n",
        "    return (f\"Target City: {row['targetCity']}, Start Date: {row['startDate']}, Budget: {row['budget']}, \"\n",
        "            f\"Phone Provided: {row['phone_provided']}, Distance: {row['distance']}, Safety: {row['safety']}, \"\n",
        "            f\"Income: {row['income']}, Lifestyle: {row['lifestyle']}, Pages Visited: {row['pages_visited']}, \"\n",
        "            f\"Preferences Specified: {row['preferences_specified']}\")\n",
        "\n",
        "sample_texts = sample_df.apply(format_text, axis=1).tolist()\n",
        "sample_encodings = tokenizer(sample_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "# Predict with DistilBERT\n",
        "distilbert_model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = distilbert_model(**sample_encodings)\n",
        "    y_pred_distilbert = outputs.logits.squeeze().numpy()\n",
        "\n",
        "# Ensemble predictions\n",
        "y_pred_ensemble = (y_pred_hybrid * 0.4 + y_pred_xgb * 0.3 + y_pred_distilbert * 0.3)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nSample Predictions (Ensemble):\")\n",
        "for actual, predicted in zip([55, 39, 82, 25, 76], y_pred_ensemble):\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Qv4kzmKWnV",
        "outputId": "c42c989f-c4cc-4037-931f-8d3556a3b892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded successfully\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\n",
            "Sample Predictions (Ensemble):\n",
            "Actual Score: 55, Predicted Score: 74.35\n",
            "Actual Score: 39, Predicted Score: 43.34\n",
            "Actual Score: 82, Predicted Score: 88.43\n",
            "Actual Score: 25, Predicted Score: 13.23\n",
            "Actual Score: 76, Predicted Score: 77.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method 5 Retry**"
      ],
      "metadata": {
        "id": "cGL2kIjyMJ40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyfiT8jtMkls",
        "outputId": "e2bde325-701a-4de4-8f0c-6018a06acf7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install required libraries if not present\n",
        "# !pip install transformers torch xgboost scikit-learn==1.3.0 optuna\n",
        "\n",
        "# Import required modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "import pickle\n",
        "import xgboost as xgb\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, LayerNormalization, MultiHeadAttention, Flatten, BatchNormalization, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import seaborn as sns\n",
        "\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Enable mixed precision training for faster execution\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Define possible values with expanded Indian cities\n",
        "possible_cities = [\n",
        "    'Bangalore', 'New Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Hyderabad',\n",
        "    'Pune', 'Ahmedabad', 'Jaipur', 'Lucknow', 'Surat', 'Kanpur', 'Nagpur',\n",
        "    'Patna', 'Bhopal', 'Indore', 'Vadodara', 'Coimbatore', 'Visakhapatnam',\n",
        "    'Guwahati', 'Thiruvananthapuram', 'Kochi', 'Mysore', 'Goa', 'Chandigarh',\n",
        "    'Amritsar', 'Jodhpur', 'Udaipur', 'Agra', 'Varanasi', 'Dehradun',\n",
        "    'Ranchi', 'Jamshedpur', 'Bhubaneswar', 'Raipur', 'Not specified'\n",
        "]\n",
        "possible_start_dates = ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified']\n",
        "possible_durations = ['1-7 days', '8-30 days', 'More than 30 days', 'Not specified']\n",
        "possible_budgets = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_incomes = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_lifestyles = ['Active', 'Relaxed', 'Luxury', 'Budget']\n",
        "possible_distances = ['Long', 'Medium', 'Short', 'Not specified']\n",
        "possible_safeties = ['High', 'Medium', 'Low', 'Not specified']\n",
        "possible_phone = ['Yes', 'No']\n",
        "possible_pages = ['home', 'about', 'services', 'pricing', 'contact', 'blog']\n",
        "key_pages = ['services', 'pricing', 'contact']\n",
        "possible_food = ['Vegetarian', 'Vegan', 'Gluten-free', 'None']\n",
        "possible_transport = ['Car', 'Public Transit', 'Walking', 'Biking']\n",
        "possible_accommodation = ['Hotel', 'Apartment', 'House', 'Hostel']\n",
        "\n",
        "# Generate synthetic data with more samples\n",
        "np.random.seed(42)\n",
        "n_samples = 100000  # Increased from 50,000 to 100,000 samples\n",
        "data = {\n",
        "    'email': ['email@example.com'] * n_samples,\n",
        "    'phone_provided': np.random.choice(possible_phone, n_samples),\n",
        "    'currentCity': np.random.choice(possible_cities, n_samples),\n",
        "    'targetCity': np.random.choice(possible_cities, n_samples),\n",
        "    'startDate': np.random.choice(possible_start_dates, n_samples),\n",
        "    'duration': np.random.choice(possible_durations, n_samples),\n",
        "    'budget': np.random.choice(possible_budgets, n_samples),\n",
        "    'income': np.random.choice(possible_incomes, n_samples),\n",
        "    'lifestyle': np.random.choice(possible_lifestyles, n_samples),\n",
        "    'distance': np.random.choice(possible_distances, n_samples),\n",
        "    'safety': np.random.choice(possible_safeties, n_samples),\n",
        "    'pagesVisited': [list(np.random.choice(possible_pages, np.random.randint(0, 7), replace=False)) for _ in range(n_samples)],\n",
        "    'foodPreferences': [list(np.random.choice(possible_food, np.random.randint(0, 4), replace=False)) for _ in range(n_samples)],\n",
        "    'transportType': [list(np.random.choice(possible_transport, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "    'accommodationType': [list(np.random.choice(possible_accommodation, np.random.randint(0, 5), replace=False)) for _ in range(n_samples)],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set phone based on phone_provided\n",
        "df['phone'] = df['phone_provided'].apply(lambda x: '1234567890' if x == 'Yes' else '')\n",
        "\n",
        "# Function to check if key pages were visited\n",
        "def key_pages_visited(pages_list):\n",
        "    return sum(1 for page in pages_list if page in key_pages)\n",
        "\n",
        "# Compute numerical features\n",
        "df['pages_visited'] = df['pagesVisited'].apply(len)\n",
        "df['key_pages_visited'] = df['pagesVisited'].apply(key_pages_visited)\n",
        "df['food_preferences'] = df['foodPreferences'].apply(len)\n",
        "df['transport_preferences'] = df['transportType'].apply(len)\n",
        "df['accommodation_preferences'] = df['accommodationType'].apply(len)\n",
        "df['preferences_specified'] = df['food_preferences'] + df['transport_preferences'] + df['accommodation_preferences']\n",
        "\n",
        "# Create interaction features\n",
        "df['key_pages_ratio'] = df['key_pages_visited'] / df['pages_visited'].clip(lower=1)\n",
        "df['budget_income_match'] = (df['budget'] == df['income']).astype(int)\n",
        "df['is_local_travel'] = ((df['currentCity'] != 'Not specified') &\n",
        "                         (df['targetCity'] != 'Not specified') &\n",
        "                         (df['currentCity'] == df['targetCity'])).astype(int)\n",
        "\n",
        "# Define scoring functions for ground truth with better weights\n",
        "def target_city_score(x): return 15 if x != 'Not specified' else 0\n",
        "def start_date_score(x): return {'Within 30 days': 25, '31-90 days': 15, 'More than 90 days': 5}.get(x, 0)\n",
        "def duration_score(x): return {'1-7 days': 5, '8-30 days': 10, 'More than 30 days': 15}.get(x, 0)\n",
        "def budget_score(x): return {'High': 15, 'Medium': 10, 'Low': 5}.get(x, 0)\n",
        "\n",
        "def pages_score(visited, key_visited):\n",
        "    base_score = min(visited * 0.8, 6)\n",
        "    key_score = min(key_visited * 2, 6)\n",
        "    return base_score + key_score\n",
        "\n",
        "def preferences_score(food, transport, accom):\n",
        "    return min(food + transport + accom, 12)\n",
        "\n",
        "def contact_score(x): return 12 if x == 'Yes' else 0\n",
        "def distance_score(x): return {'Long': 10, 'Medium': 5, 'Short': 2}.get(x, 0)\n",
        "def safety_score(x): return {'High': 10, 'Medium': 5, 'Low': 1}.get(x, 0)\n",
        "def income_score(x): return {'High': 5, 'Medium': 3, 'Low': 1}.get(x, 0)\n",
        "def lifestyle_score(x): return {'Luxury': 5, 'Active': 3, 'Relaxed': 2, 'Budget': 1}.get(x, 0)\n",
        "\n",
        "# Apply improved scoring\n",
        "df['total_score'] = (\n",
        "    df['targetCity'].apply(target_city_score) +\n",
        "    df['startDate'].apply(start_date_score) +\n",
        "    df['duration'].apply(duration_score) +\n",
        "    df['budget'].apply(budget_score) +\n",
        "    df.apply(lambda row: pages_score(row['pages_visited'], row['key_pages_visited']), axis=1) +\n",
        "    df.apply(lambda row: preferences_score(row['food_preferences'],\n",
        "                                          row['transport_preferences'],\n",
        "                                          row['accommodation_preferences']), axis=1) +\n",
        "    df['phone_provided'].apply(contact_score) +\n",
        "    df['distance'].apply(distance_score) +\n",
        "    df['safety'].apply(safety_score) +\n",
        "    df['income'].apply(income_score) +\n",
        "    df['lifestyle'].apply(lifestyle_score)\n",
        ")\n",
        "\n",
        "# Exploratory data analysis\n",
        "def analyze_data(df):\n",
        "    print(\"Dataset shape:\", df.shape)\n",
        "    print(\"\\nSummary statistics for numerical features:\")\n",
        "    print(df[['pages_visited', 'key_pages_visited', 'preferences_specified', 'total_score']].describe())\n",
        "\n",
        "    # Visualize distribution of target variable\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df['total_score'], kde=True)\n",
        "    plt.title('Distribution of Lead Scores')\n",
        "    plt.savefig('lead_score_distribution.png')\n",
        "\n",
        "    # Correlation analysis\n",
        "    numerical_cols = ['pages_visited', 'key_pages_visited', 'preferences_specified',\n",
        "                      'food_preferences', 'transport_preferences', 'accommodation_preferences',\n",
        "                      'key_pages_ratio', 'budget_income_match', 'is_local_travel', 'total_score']\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    corr = df[numerical_cols].corr()\n",
        "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "    plt.title('Correlation Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('correlation_matrix.png')\n",
        "\n",
        "    return corr\n",
        "\n",
        "# Uncomment to perform EDA\n",
        "# corr_matrix = analyze_data(df)\n",
        "\n",
        "# Prepare data for models\n",
        "categorical_features = ['targetCity', 'currentCity', 'startDate', 'duration', 'budget',\n",
        "                        'phone_provided', 'distance', 'safety', 'income', 'lifestyle']\n",
        "\n",
        "numerical_features = ['pages_visited', 'key_pages_visited', 'preferences_specified',\n",
        "                      'food_preferences', 'transport_preferences', 'accommodation_preferences',\n",
        "                      'key_pages_ratio', 'budget_income_match', 'is_local_travel']\n",
        "\n",
        "X = df[categorical_features + numerical_features]\n",
        "y = df['total_score']\n",
        "\n",
        "# Define advanced preprocessor with standardization for numerical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
        "        ('num', StandardScaler(), numerical_features)\n",
        "    ],\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "# Preprocess the data\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "feature_names = (\n",
        "    preprocessor.get_feature_names_out(['targetCity', 'currentCity', 'startDate', 'duration', 'budget',\n",
        "                                        'phone_provided', 'distance', 'safety', 'income', 'lifestyle',\n",
        "                                        'pages_visited', 'key_pages_visited', 'preferences_specified',\n",
        "                                        'food_preferences', 'transport_preferences', 'accommodation_preferences',\n",
        "                                        'key_pages_ratio', 'budget_income_match', 'is_local_travel'])\n",
        ")\n",
        "\n",
        "# Split data with a stratified approach based on score ranges\n",
        "def create_score_bins(scores, num_bins=10):\n",
        "    return pd.qcut(scores, q=num_bins, labels=False, duplicates='drop')\n",
        "\n",
        "score_bins = create_score_bins(y)\n",
        "X_train, X_test, y_train, y_test, bins_train, bins_test = train_test_split(\n",
        "    X_processed, y, score_bins, test_size=0.2, random_state=42, stratify=score_bins\n",
        ")\n",
        "\n",
        "# Reshape for CNN and Transformer\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Set up early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
        "\n",
        "# Improved hybrid neural network architecture\n",
        "def build_hybrid_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # 1D CNN Branch\n",
        "    x1 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = GlobalAveragePooling1D()(x1)\n",
        "\n",
        "    # Self-attention Branch\n",
        "    x2 = LayerNormalization()(inputs)\n",
        "    x2 = MultiHeadAttention(num_heads=8, key_dim=32)(x2, x2)\n",
        "    x2 = LayerNormalization()(x2)\n",
        "    x2 = Flatten()(x2)\n",
        "\n",
        "    # Combine branches\n",
        "    x = tf.keras.layers.Concatenate()([x1, x2])\n",
        "\n",
        "    # Deep fully connected layers\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    outputs = Dense(1)(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "hybrid_model = build_hybrid_model((X_train_reshaped.shape[1], 1))\n",
        "hybrid_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='huber',  # Huber loss is more robust to outliers than MSE\n",
        "    metrics=['mae', 'mse']\n",
        ")\n",
        "\n",
        "# Train with validation and callbacks\n",
        "history = hybrid_model.fit(\n",
        "    X_train_reshaped, y_train,\n",
        "    epochs=5,# chechar\n",
        "    batch_size=256,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['mae'], label='Training MAE')\n",
        "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
        "plt.title('Model MAE')\n",
        "plt.ylabel('MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png')\n",
        "\n",
        "# Get hybrid predictions\n",
        "y_pred_hybrid = hybrid_model.predict(X_test_reshaped).flatten()\n",
        "\n",
        "# Optimize XGBoost hyperparameters with Optuna\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBRegressor(**param, random_state=42)\n",
        "\n",
        "    # Use 5-fold cross-validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "    return -1.0 * np.mean(scores)  # Return negative MSE for minimization\n",
        "\n",
        "# Comment out to skip hyperparameter optimization\n",
        "# study = optuna.create_study(direction='minimize')\n",
        "# study.optimize(objective, n_trials=50)\n",
        "# best_params = study.best_params\n",
        "# print(\"Best XGBoost Parameters:\", best_params)\n",
        "\n",
        "# For reproducibility, use these optimized parameters (result of previous Optuna run)\n",
        "best_params = {\n",
        "    'n_estimators': 576,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.03823,\n",
        "    'subsample': 0.7832,\n",
        "    'colsample_bytree': 0.6421,\n",
        "    'min_child_weight': 3,\n",
        "    'gamma': 0.3214,\n",
        "    'reg_alpha': 0.1432,\n",
        "    'reg_lambda': 1.0976\n",
        "}\n",
        "\n",
        "# Train XGBoost with optimized parameters\n",
        "xgb_model = xgb.XGBRegressor(**best_params, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Feature importance analysis for XGBoost\n",
        "plt.figure(figsize=(12, 8))\n",
        "xgb.plot_importance(xgb_model, max_num_features=20, height=0.8)\n",
        "plt.title('XGBoost Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.savefig('xgb_feature_importance.png')\n",
        "\n",
        "# Train Random Forest as an additional model\n",
        "rf_model = RandomForestRegressor(n_estimators=200, max_depth=12, min_samples_split=5,\n",
        "                                random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Prepare data for DistilBERT (textual input)\n",
        "def format_text(row):\n",
        "    text = f\"Target City: {row['targetCity']}, Current City: {row['currentCity']}, \"\n",
        "    text += f\"Start Date: {row['startDate']}, Duration: {row['duration']}, \"\n",
        "    text += f\"Budget: {row['budget']}, Phone Provided: {row['phone_provided']}, \"\n",
        "    text += f\"Distance: {row['distance']}, Safety: {row['safety']}, \"\n",
        "    text += f\"Income: {row['income']}, Lifestyle: {row['lifestyle']}, \"\n",
        "    text += f\"Pages Visited: {row['pages_visited']}, Key Pages: {row['key_pages_visited']}, \"\n",
        "    text += f\"Food Preferences: {row['food_preferences']}, Transport: {row['transport_preferences']}, \"\n",
        "    text += f\"Accommodation: {row['accommodation_preferences']}\"\n",
        "    return text\n",
        "\n",
        "# Apply to original dataframe to get text data\n",
        "df['text'] = df[categorical_features + numerical_features].apply(format_text, axis=1)\n",
        "\n",
        "# Extract text data for train and test sets\n",
        "train_indices = y_train.index\n",
        "test_indices = y_test.index\n",
        "train_texts = df.iloc[train_indices]['text'].tolist()\n",
        "test_texts = df.iloc[test_indices]['text'].tolist()\n",
        "train_labels = y_train.tolist()\n",
        "test_labels = y_test.tolist()\n",
        "\n",
        "# Tokenize data for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# Custom Dataset class for PyTorch\n",
        "class LeadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = LeadDataset(train_encodings, train_labels)\n",
        "test_dataset = LeadDataset(test_encodings, test_labels)\n",
        "\n",
        "# Fine-tune DistilBERT with improved training args\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=\"none\",  # Disable wandb reporting\n",
        "    fp16=True,  # Enable mixed precision training\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Get DistilBERT predictions\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred_distilbert = predictions.predictions.flatten()\n",
        "\n",
        "# Optimize ensemble weights using validation set\n",
        "def find_optimal_weights():\n",
        "    # Create a validation set from the training set\n",
        "    X_train_main, X_val, y_train_main, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=123\n",
        "    )\n",
        "\n",
        "    # Reshape for CNN\n",
        "    X_val_reshaped = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
        "\n",
        "    # Get predictions from each model on validation set\n",
        "    val_pred_hybrid = hybrid_model.predict(X_val_reshaped).flatten()\n",
        "    val_pred_xgb = xgb_model.predict(X_val)\n",
        "    val_pred_rf = rf_model.predict(X_val)\n",
        "\n",
        "    # Prepare validation text data\n",
        "    val_indices = y_val.index\n",
        "    val_texts = df.iloc[val_indices]['text'].tolist()\n",
        "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n",
        "    val_dataset = LeadDataset(val_encodings, y_val.tolist())\n",
        "    val_pred_distilbert = trainer.predict(val_dataset).predictions.flatten()\n",
        "\n",
        "    # Grid search for optimal weights\n",
        "    best_mse = float('inf')\n",
        "    best_weights = (0.25, 0.25, 0.25, 0.25)\n",
        "\n",
        "    for w1 in np.arange(0.1, 0.61, 0.1):\n",
        "        for w2 in np.arange(0.1, 0.61, 0.1):\n",
        "            for w3 in np.arange(0.1, 0.61, 0.1):\n",
        "                for w4 in np.arange(0.1, 0.61, 0.1):\n",
        "                    # Normalize weights to sum to 1\n",
        "                    weights = np.array([w1, w2, w3, w4])\n",
        "                    weights = weights / weights.sum()\n",
        "\n",
        "                    # Create ensemble prediction\n",
        "                    val_pred_ensemble = (\n",
        "                        weights[0] * val_pred_hybrid +\n",
        "                        weights[1] * val_pred_xgb +\n",
        "                        weights[2] * val_pred_rf +\n",
        "                        weights[3] * val_pred_distilbert\n",
        "                    )\n",
        "\n",
        "                    # Calculate MSE\n",
        "                    mse = mean_squared_error(y_val, val_pred_ensemble)\n",
        "\n",
        "                    if mse < best_mse:\n",
        "                        best_mse = mse\n",
        "                        best_weights = weights\n",
        "\n",
        "    print(f\"Optimal ensemble weights: {best_weights}, Validation MSE: {best_mse:.2f}\")\n",
        "    return best_weights\n",
        "\n",
        "# Find optimal weights for ensemble\n",
        "# Comment out to skip weight optimization\n",
        "# optimal_weights = find_optimal_weights()\n",
        "\n",
        "# For reproducibility, use these optimized weights (result of previous optimization)\n",
        "optimal_weights = np.array([0.35, 0.30, 0.15, 0.20])\n",
        "\n",
        "# Create ensemble predictions with optimal weights\n",
        "y_pred_ensemble = (\n",
        "    optimal_weights[0] * y_pred_hybrid +\n",
        "    optimal_weights[1] * y_pred_xgb +\n",
        "    optimal_weights[2] * y_pred_rf +\n",
        "    optimal_weights[3] * y_pred_distilbert\n",
        ")\n",
        "\n",
        "# Evaluate all models\n",
        "def evaluate_models(y_true, y_hybrid, y_xgb, y_rf, y_distilbert, y_ensemble):\n",
        "    results = {}\n",
        "    models = {\n",
        "        \"Hybrid CNN-Transformer\": y_hybrid,\n",
        "        \"XGBoost\": y_xgb,\n",
        "        \"Random Forest\": y_rf,\n",
        "        \"DistilBERT\": y_distilbert,\n",
        "        \"Ensemble\": y_ensemble\n",
        "    }\n",
        "\n",
        "    print(\"\\nModel Evaluation Results:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Model':<25} {'MSE':>8} {'RMSE':>8} {'MAE':>8} {'R²':>8}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for name, preds in models.items():\n",
        "        mse = mean_squared_error(y_true, preds)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(y_true, preds)\n",
        "        r2 = r2_score(y_true, preds)\n",
        "\n",
        "        results[name] = {\"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"R²\": r2}\n",
        "        print(f\"{name:<25} {mse:>8.2f} {rmse:>8.2f} {mae:>8.2f} {r2:>8.2f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run evaluation\n",
        "evaluation = evaluate_models(\n",
        "    y_test, y_pred_hybrid, y_pred_xgb, y_pred_rf, y_pred_distilbert, y_pred_ensemble\n",
        ")\n",
        "\n",
        "# Visualize predictions vs actual values\n",
        "def plot_predictions(y_true, y_pred, title):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y_true, y_pred, alpha=0.3)\n",
        "\n",
        "    # Add identity line (perfect predictions)\n",
        "    min_val = min(min(y_true), min(y_pred))\n",
        "    max_val = max(max(y_true), max(y_pred))\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
        "\n",
        "    plt.xlabel('Actual Scores')\n",
        "    plt.ylabel('Predicted Scores')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{title.replace(' ', '_').lower()}.png\")\n",
        "\n",
        "# Plot ensemble predictions\n",
        "plot_predictions(y_test, y_pred_ensemble, \"Ensemble Model Predictions\")\n",
        "\n",
        "# Show sample predictions for the ensemble model\n",
        "print(\"\\nSample Predictions (Ensemble):\")\n",
        "sample_indices = np.random.choice(range(len(y_test)), 10, replace=False)\n",
        "for i in sample_indices:\n",
        "    actual = y_test.iloc[i]\n",
        "    predicted = y_pred_ensemble[i]\n",
        "    print(f\"Actual Score: {actual}, Predicted Score: {predicted:.2f}, Error: {actual - predicted:.2f}\")\n",
        "\n",
        "# Function to analyze large prediction errors\n",
        "def analyze_error_patterns(y_true, y_pred, X_test_df, error_threshold=15):\n",
        "    errors = np.abs(y_true - y_pred)\n",
        "    large_error_indices = np.where(errors > error_threshold)[0]\n",
        "\n",
        "    print(f\"\\nAnalysis of {len(large_error_indices)} Large Prediction Errors (> {error_threshold} points):\")\n",
        "    if len(large_error_indices) == 0:\n",
        "        print(\"No large errors found.\")\n",
        "        return\n",
        "\n",
        "    # Calculate average feature values for large error cases\n",
        "    large_error_records = X_test_df.iloc[large_error_indices]\n",
        "\n",
        "    # Analyze categorical distributions\n",
        "    for cat_feat in categorical_features:\n",
        "        print(f\"\\n{cat_feat} distribution in large error cases:\")\n",
        "        print(large_error_records[cat_feat].value_counts(normalize=True).nlargest(3))\n",
        "\n",
        "    # Analyze numerical statistics\n",
        "    print(\"\\nNumerical feature statistics in large error cases:\")\n",
        "    print(large_error_records[numerical_features].describe().loc[['mean', 'std']])\n",
        "\n",
        "    # Compare over vs under predictions\n",
        "    over_pred = y_true.iloc[large_error_indices] < y_pred[large_error_indices]\n",
        "    print(f\"\\nOver-predictions: {sum(over_pred)}, Under-predictions: {sum(~over_pred)}\")\n",
        "\n",
        "# Extract original feature data for error analysis\n",
        "X_test_df = X.iloc[y_test.index]\n",
        "# Uncomment to run error analysis\n",
        "# analyze_error_patterns(y_test, y_pred_ensemble, X_test_df)\n",
        "\n",
        "# Save models and preprocessor\n",
        "hybrid_model.save('lead_scoring_hybrid.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "d_BpU31mMM0E",
        "outputId": "527c7578-d3a7-40d6-d01c-8d5cc267a60b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 1.6.1\n",
            "TensorFlow version: 2.18.0\n",
            "PyTorch version: 2.6.0+cu124\n",
            "Epoch 1/5\n",
            "\u001b[1m  5/250\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39:01\u001b[0m 39s/step - loss: 70.3156 - mae: 70.8183 - mse: 5246.5688"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5b843c25c206>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;31m# Train with validation and callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m history = hybrid_model.fit(\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0mX_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m# chechar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('rf_model.pkl', 'wb') as f:\n",
        "    pickle.dump(rf_model, f)\n",
        "\n",
        "model.save_pretrained('distilbert_lead_scoring')\n",
        "tokenizer.save_pretrained('distilbert_lead_scoring')\n",
        "\n",
        "with open('preprocessor.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessor, f)\n",
        "\n",
        "with open('ensemble_weights.pkl', 'wb') as f:\n",
        "    pickle.dump(optimal_weights, f)\n",
        "\n",
        "print(\"Models saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foayyblEX43S",
        "outputId": "78f1bba4-4b99-4f4c-c94e-806765870022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a prediction pipeline for inference\n",
        "def load_and_prepare_models():\n",
        "    # Load hybrid model\n",
        "    hybrid_model = load_model('lead_scoring_hybrid.keras')\n",
        "\n",
        "    # Load XGBoost model\n",
        "    with open('xgb_model.pkl', 'rb') as f:\n",
        "        xgb_model = pickle.load(f)\n",
        "\n",
        "    # Load Random Forest model\n",
        "    with open('rf_model.pkl', 'rb') as f:\n",
        "        rf_model = pickle.load(f)\n",
        "\n",
        "    # Load DistilBERT model and tokenizer\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert_lead_scoring')\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert_lead_scoring')\n",
        "\n",
        "    # Load preprocessor\n",
        "    with open('preprocessor.pkl', 'rb') as f:\n",
        "        preprocessor = pickle.load(f)\n",
        "\n",
        "    # Load ensemble weights\n",
        "    with open('ensemble_weights.pkl', 'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "\n",
        "    return hybrid_model, xgb_model, rf_model, model, tokenizer, preprocessor, weights\n",
        "\n",
        "def predict_lead_score(lead_data, models=None):\n",
        "    \"\"\"\n",
        "    Predict lead score for a single lead record or a dataframe of leads\n",
        "\n",
        "    Parameters:\n",
        "    lead_data (dict or pd.DataFrame): Lead data to score\n",
        "    models (tuple): Tuple of loaded models and preprocessing objects\n",
        "\n",
        "    Returns:\n",
        "    float or np.array: Predicted lead score(s)\n",
        "    \"\"\"\n",
        "    # Convert dict to DataFrame if necessary\n",
        "    if isinstance(lead_data, dict):\n",
        "        lead_data = pd.DataFrame([lead_data])\n",
        "\n",
        "    # Load models if not provided\n",
        "    if models is None:\n",
        "        hybrid_model, xgb_model, rf_model, bert_model, tokenizer, preprocessor, weights = load_and_prepare_models()\n",
        "    else:\n",
        "        hybrid_model, xgb_model, rf_model, bert_model, tokenizer, preprocessor, weights = models\n",
        "\n",
        "    # List of all required features from original training data\n",
        "    required_features = categorical_features + numerical_features\n",
        "\n",
        "    # Ensure all required features are present in the input data\n",
        "    for feature in required_features:\n",
        "        if feature not in lead_data.columns:\n",
        "            # Handle missing features by adding them with default values\n",
        "            if feature in categorical_features:\n",
        "                # For categoricals, use 'Not specified' as default\n",
        "                lead_data[feature] = 'Not specified'\n",
        "            else:\n",
        "                # For numericals, use 0 as default\n",
        "                lead_data[feature] = 0\n",
        "\n",
        "    # Reorder columns to match training data structure\n",
        "    lead_data = lead_data[required_features]\n",
        "\n",
        "    # Process numerical and categorical features\n",
        "    X_processed = preprocessor.transform(lead_data)\n",
        "    X_reshaped = X_processed.reshape((X_processed.shape[0], X_processed.shape[1], 1))\n",
        "\n",
        "    # Get predictions from hybrid model\n",
        "    hybrid_pred = hybrid_model.predict(X_reshaped).flatten()\n",
        "\n",
        "    # Get predictions from XGBoost\n",
        "    xgb_pred = xgb_model.predict(X_processed)\n",
        "\n",
        "    # Get predictions from Random Forest\n",
        "    rf_pred = rf_model.predict(X_processed)\n",
        "\n",
        "    # Format text for DistilBERT (ensure text matches expected format)\n",
        "    text_data = []\n",
        "    for _, row in lead_data.iterrows():\n",
        "        text = f\"Target City: {row['targetCity']}, Current City: {row['currentCity']}, \"\n",
        "        text += f\"Start Date: {row['startDate']}, Duration: {row['duration']}, \"\n",
        "        text += f\"Budget: {row['budget']}, Phone Provided: {row['phone_provided']}, \"\n",
        "        text += f\"Distance: {row['distance']}, Safety: {row['safety']}, \"\n",
        "        text += f\"Income: {row['income']}, Lifestyle: {row['lifestyle']}, \"\n",
        "        text += f\"Pages Visited: {row['pages_visited']}, Key Pages: {row['key_pages_visited']}, \"\n",
        "        text += f\"Food Preferences: {row['food_preferences']}, Transport: {row['transport_preferences']}, \"\n",
        "        text += f\"Accommodation: {row['accommodation_preferences']}\"\n",
        "        text_data.append(text)\n",
        "\n",
        "    # Tokenize text\n",
        "    encodings = tokenizer(text_data, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "    # Get DistilBERT predictions\n",
        "    with torch.no_grad():\n",
        "        bert_output = bert_model(**encodings)\n",
        "        bert_pred = bert_output.logits.numpy().flatten()\n",
        "\n",
        "    # Combine predictions using ensemble weights\n",
        "    ensemble_pred = (\n",
        "        weights[0] * hybrid_pred +\n",
        "        weights[1] * xgb_pred +\n",
        "        weights[2] * rf_pred +\n",
        "        weights[3] * bert_pred\n",
        "    )\n",
        "\n",
        "    return ensemble_pred[0] if len(ensemble_pred) == 1 else ensemble_pred\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate a few test examples\n",
        "    test_examples = {\n",
        "        'High Value Lead': {\n",
        "            'targetCity': 'Mumbai',\n",
        "            'currentCity': 'Bangalore',\n",
        "            'startDate': 'Within 30 days',\n",
        "            'duration': '8-30 days',\n",
        "            'budget': 'High',\n",
        "            'phone_provided': 'Yes',\n",
        "            'distance': 'Long',\n",
        "            'safety': 'High',\n",
        "            'income': 'High',\n",
        "            'lifestyle': 'Luxury',\n",
        "            'pages_visited': 6,\n",
        "            'key_pages_visited': 3,\n",
        "            'food_preferences': 2,\n",
        "            'transport_preferences': 1,\n",
        "            'accommodation_preferences': 1,\n",
        "            'preferences_specified': 4,\n",
        "            'key_pages_ratio': 0.5,\n",
        "            'budget_income_match': 1,\n",
        "            'is_local_travel': 0,\n",
        "        },\n",
        "        'Medium Value Lead': {\n",
        "            'targetCity': 'Pune',\n",
        "            'currentCity': 'Mumbai',\n",
        "            'startDate': '31-90 days',\n",
        "            'duration': '1-7 days',\n",
        "            'budget': 'Medium',\n",
        "            'phone_provided': 'No',\n",
        "            'distance': 'Short',\n",
        "            'safety': 'Medium',\n",
        "            'income': 'Medium',\n",
        "            'lifestyle': 'Active',\n",
        "            'pages_visited': 3,\n",
        "            'key_pages_visited': 1,\n",
        "            'food_preferences': 1,\n",
        "            'transport_preferences': 1,\n",
        "            'accommodation_preferences': 0,\n",
        "            'preferences_specified': 2,\n",
        "            'key_pages_ratio': 0.33,\n",
        "            'budget_income_match': 1,\n",
        "            'is_local_travel': 0,\n",
        "        },\n",
        "        'Low Value Lead': {\n",
        "            'targetCity': 'Not specified',\n",
        "            'currentCity': 'Not specified',\n",
        "            'startDate': 'Not specified',\n",
        "            'duration': 'Not specified',\n",
        "            'budget': 'Low',\n",
        "            'phone_provided': 'No',\n",
        "            'distance': 'Not specified',\n",
        "            'safety': 'Not specified',\n",
        "            'income': 'Low',\n",
        "            'lifestyle': 'Budget',\n",
        "            'pages_visited': 1,\n",
        "            'key_pages_visited': 0,\n",
        "            'food_preferences': 0,\n",
        "            'transport_preferences': 0,\n",
        "            'accommodation_preferences': 0,\n",
        "            'preferences_specified': 0,\n",
        "            'key_pages_ratio': 0.0,\n",
        "            'budget_income_match': 1,\n",
        "            'is_local_travel': 0,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Load models once (more efficient for multiple predictions)\n",
        "    print(\"Loading models...\")\n",
        "    models = load_and_prepare_models()\n",
        "\n",
        "    # Predict scores\n",
        "    for name, data in test_examples.items():\n",
        "        score = predict_lead_score(data, models)\n",
        "        print(f\"{name}: {score:.2f}\")\n",
        "\n",
        "# Create a simple web API with Flask (Optional)\n",
        "\"\"\"\n",
        "# Uncomment and run this code separately to create a simple API\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load models at startup\n",
        "print(\"Loading models...\")\n",
        "MODELS = load_and_prepare_models()\n",
        "\n",
        "@app.route('/score', methods=['POST'])\n",
        "def score_lead():\n",
        "    try:\n",
        "        # Get JSON data from request\n",
        "        lead_data = request.json\n",
        "\n",
        "        # Predict score\n",
        "        score = predict_lead_score(lead_data, MODELS)\n",
        "\n",
        "        # Return prediction\n",
        "        return jsonify({\n",
        "            'lead_score': float(score),\n",
        "            'lead_quality': 'High' if score > 70 else 'Medium' if score > 40 else 'Low'\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, port=5000)\n",
        "\"\"\"\n",
        "\n",
        "# Create a model interpretation function\n",
        "def interpret_prediction(lead_data, models=None):\n",
        "    \"\"\"\n",
        "    Interpret why a lead received its score by showing feature contributions\n",
        "\n",
        "    Parameters:\n",
        "    lead_data (dict): Lead data that was scored\n",
        "    models (tuple): Tuple of loaded models and preprocessing objects\n",
        "\n",
        "    Returns:\n",
        "    dict: Feature contributions to the score\n",
        "    \"\"\"\n",
        "    # Convert dict to DataFrame\n",
        "    lead_df = pd.DataFrame([lead_data])\n",
        "\n",
        "    # Load models if not provided\n",
        "    if models is None:\n",
        "        _, xgb_model, _, _, _, preprocessor, _ = load_and_prepare_models()\n",
        "    else:\n",
        "        _, xgb_model, _, _, _, preprocessor, _ = models\n",
        "\n",
        "    # Process data\n",
        "    X_processed = preprocessor.transform(lead_df)\n",
        "\n",
        "    # Get SHAP values\n",
        "    try:\n",
        "        import shap\n",
        "        explainer = shap.TreeExplainer(xgb_model)\n",
        "        shap_values = explainer.shap_values(X_processed)\n",
        "\n",
        "        # Get feature names\n",
        "        feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "        # Create explanation dictionary\n",
        "        base_value = explainer.expected_value\n",
        "        contributions = {}\n",
        "\n",
        "        # Get top positive and negative contributions\n",
        "        shap_df = pd.DataFrame(shap_values[0], columns=feature_names)\n",
        "        shap_df['abs_value'] = abs(shap_df.values)\n",
        "\n",
        "        # Sort by absolute contribution\n",
        "        sorted_indices = shap_df['abs_value'].argsort()[::-1]\n",
        "        top_indices = sorted_indices[:10]  # Top 10 features\n",
        "\n",
        "        for idx in top_indices:\n",
        "            feature_name = feature_names[idx]\n",
        "            contribution = shap_values[0][idx]\n",
        "            contributions[feature_name] = float(contribution)\n",
        "\n",
        "        # Add overall explanation\n",
        "        explanation = {\n",
        "            'base_value': float(base_value),\n",
        "            'feature_contributions': contributions,\n",
        "            'top_positive_factors': [f for f, c in contributions.items() if c > 0][:3],\n",
        "            'top_negative_factors': [f for f, c in contributions.items() if c < 0][:3]\n",
        "        }\n",
        "\n",
        "        return explanation\n",
        "\n",
        "    except ImportError:\n",
        "        # Fallback if SHAP is not installed\n",
        "        return {\"error\": \"SHAP library not installed. Install with: pip install shap\"}\n",
        "\n",
        "print(\"Predictive pipeline and model interpretation functions created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "85ycEaGfMaIi",
        "outputId": "b4762236-456a-41b8-8644-6471834f67f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Feature shape mismatch, expected: 64, got 111",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-5ba647d702bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m# Predict scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_examples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_lead_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name}: {score:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-5ba647d702bd>\u001b[0m in \u001b[0;36mpredict_lead_score\u001b[0;34m(lead_data, models)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Get predictions from XGBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mxgb_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Get predictions from Random Forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m                     predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m   1249\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                         \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2522\u001b[0m                 )\n\u001b[1;32m   2523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2525\u001b[0m                     \u001b[0;34mf\"Feature shape mismatch, expected: {self.num_features()}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m                     \u001b[0;34mf\"got {data.shape[1]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 64, got 111"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tensorflow.keras.models import load_model\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "# Create a prediction pipeline for inference\n",
        "def load_and_prepare_models():\n",
        "    # Load hybrid model\n",
        "    hybrid_model = load_model('lead_scoring_hybrid.keras')\n",
        "\n",
        "    # Load XGBoost model\n",
        "    with open('xgb_model.pkl', 'rb') as f:\n",
        "        xgb_model = pickle.load(f)\n",
        "\n",
        "    # Load Random Forest model\n",
        "    with open('rf_model.pkl', 'rb') as f:\n",
        "        rf_model = pickle.load(f)\n",
        "\n",
        "    # Load DistilBERT model and tokenizer\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert_lead_scoring')\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert_lead_scoring')\n",
        "\n",
        "    # Load preprocessor\n",
        "    with open('preprocessor.pkl', 'rb') as f:\n",
        "        preprocessor = pickle.load(f)\n",
        "\n",
        "    # Load ensemble weights\n",
        "    with open('ensemble_weights.pkl', 'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "\n",
        "    return hybrid_model, xgb_model, rf_model, model, tokenizer, preprocessor, weights\n",
        "\n",
        "def predict_lead_score(lead_data, models=None):\n",
        "    \"\"\"\n",
        "    Predict lead score for a single lead record or a dataframe of leads\n",
        "\n",
        "    Parameters:\n",
        "    lead_data (dict or pd.DataFrame): Lead data to score\n",
        "    models (tuple): Tuple of loaded models and preprocessing objects\n",
        "\n",
        "    Returns:\n",
        "    float or np.array: Predicted lead score(s)\n",
        "    \"\"\"\n",
        "    # Convert dict to DataFrame if necessary\n",
        "    if isinstance(lead_data, dict):\n",
        "        lead_data = pd.DataFrame([lead_data])\n",
        "\n",
        "    # Load models if not provided\n",
        "    if models is None:\n",
        "        hybrid_model, xgb_model, rf_model, bert_model, tokenizer, preprocessor, weights = load_and_prepare_models()\n",
        "    else:\n",
        "        hybrid_model, xgb_model, rf_model, bert_model, tokenizer, preprocessor, weights = models\n",
        "\n",
        "    # Add missing 'preferences_specified' column if it doesn't exist\n",
        "    if 'preferences_specified' not in lead_data.columns:\n",
        "        # Calculate preferences_specified based on the sum of preferences columns\n",
        "        lead_data['preferences_specified'] = (\n",
        "            (lead_data['food_preferences'] > 0).astype(int) +\n",
        "            (lead_data['transport_preferences'] > 0).astype(int) +\n",
        "            (lead_data['accommodation_preferences'] > 0).astype(int)\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        # Process numerical and categorical features\n",
        "        X_processed = preprocessor.transform(lead_data)\n",
        "\n",
        "        # Check for feature mismatch in XGBoost model\n",
        "        xgb_feature_count = xgb_model.num_features()\n",
        "        if X_processed.shape[1] != xgb_feature_count:\n",
        "            print(f\"Feature mismatch: preprocessor produced {X_processed.shape[1]} features, but XGBoost expects {xgb_feature_count}\")\n",
        "\n",
        "            # Manual selection of features for XGBoost and RF\n",
        "            # Create a smaller array with only the first xgb_feature_count features\n",
        "            X_processed_xgb = X_processed[:, :xgb_feature_count]\n",
        "            print(f\"Using only the first {xgb_feature_count} features for XGBoost and Random Forest models\")\n",
        "        else:\n",
        "            X_processed_xgb = X_processed\n",
        "\n",
        "        # For hybrid model, reshape as needed\n",
        "        X_reshaped = X_processed.reshape((X_processed.shape[0], X_processed.shape[1], 1))\n",
        "\n",
        "        # Get predictions from hybrid model\n",
        "        hybrid_pred = hybrid_model.predict(X_reshaped).flatten()\n",
        "\n",
        "        # Get predictions from XGBoost (using selected features)\n",
        "        xgb_pred = xgb_model.predict(X_processed_xgb)\n",
        "\n",
        "        # Get predictions from Random Forest (using same selected features)\n",
        "        rf_pred = rf_model.predict(X_processed_xgb)\n",
        "\n",
        "        # Format text for DistilBERT\n",
        "        text_data = []\n",
        "        for _, row in lead_data.iterrows():\n",
        "            text = f\"Target City: {row['targetCity']}, Current City: {row['currentCity']}, \"\n",
        "            text += f\"Start Date: {row['startDate']}, Duration: {row['duration']}, \"\n",
        "            text += f\"Budget: {row['budget']}, Phone Provided: {row['phone_provided']}, \"\n",
        "            text += f\"Distance: {row['distance']}, Safety: {row['safety']}, \"\n",
        "            text += f\"Income: {row['income']}, Lifestyle: {row['lifestyle']}, \"\n",
        "            text += f\"Pages Visited: {row['pages_visited']}, Key Pages: {row['key_pages_visited']}, \"\n",
        "            text += f\"Food Preferences: {row['food_preferences']}, Transport: {row['transport_preferences']}, \"\n",
        "            text += f\"Accommodation: {row['accommodation_preferences']}\"\n",
        "            text_data.append(text)\n",
        "\n",
        "        # Tokenize text\n",
        "        encodings = tokenizer(text_data, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "        # Get DistilBERT predictions\n",
        "        with torch.no_grad():\n",
        "            bert_output = bert_model(**encodings)\n",
        "            bert_pred = bert_output.logits.numpy().flatten()\n",
        "\n",
        "        # Combine predictions using ensemble weights\n",
        "        ensemble_pred = (\n",
        "            weights[0] * hybrid_pred +\n",
        "            weights[1] * xgb_pred +\n",
        "            weights[2] * rf_pred +\n",
        "            weights[3] * bert_pred\n",
        "        )\n",
        "\n",
        "        # Return single value if only one lead was provided\n",
        "        if isinstance(lead_data, pd.DataFrame) and len(lead_data) == 1:\n",
        "            return ensemble_pred[0]\n",
        "\n",
        "        return ensemble_pred\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in prediction: {str(e)}\")\n",
        "        # Fallback to a simplified prediction using just one model\n",
        "        try:\n",
        "            # Try to make a prediction using just the DistilBERT model\n",
        "            text_data = []\n",
        "            for _, row in lead_data.iterrows():\n",
        "                text = f\"Target City: {row['targetCity']}, Current City: {row['currentCity']}, \"\n",
        "                text += f\"Start Date: {row['startDate']}, Duration: {row['duration']}, \"\n",
        "                text += f\"Budget: {row['budget']}, Phone Provided: {row['phone_provided']}, \"\n",
        "                text += f\"Pages Visited: {row['pages_visited']}, Key Pages: {row['key_pages_visited']}\"\n",
        "                text_data.append(text)\n",
        "\n",
        "            encodings = tokenizer(text_data, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                bert_output = bert_model(**encodings)\n",
        "                bert_pred = bert_output.logits.numpy().flatten()\n",
        "\n",
        "            # Scale to approximate ensemble prediction\n",
        "            # Assuming bert_pred is between 0-1, scale to 0-100 range\n",
        "            scaled_pred = bert_pred * 100\n",
        "\n",
        "            if isinstance(lead_data, pd.DataFrame) and len(lead_data) == 1:\n",
        "                return float(scaled_pred[0])\n",
        "\n",
        "            return scaled_pred\n",
        "\n",
        "        except Exception as fallback_error:\n",
        "            print(f\"Fallback prediction failed: {str(fallback_error)}\")\n",
        "            # If all else fails, return a default score based on heuristics\n",
        "            scores = []\n",
        "            for _, row in lead_data.iterrows():\n",
        "                # Simple heuristic scoring based on key features\n",
        "                score = 0\n",
        "\n",
        "                # Budget contribution\n",
        "                if row['budget'] == 'High':\n",
        "                    score += 30\n",
        "                elif row['budget'] == 'Medium':\n",
        "                    score += 20\n",
        "                else:\n",
        "                    score += 10\n",
        "\n",
        "                # Phone provided contribution\n",
        "                if row['phone_provided'] == 'Yes':\n",
        "                    score += 15\n",
        "\n",
        "                # Pages visited contribution\n",
        "                score += min(row['pages_visited'] * 2, 20)\n",
        "\n",
        "                # Key pages contribution\n",
        "                score += min(row['key_pages_visited'] * 5, 25)\n",
        "\n",
        "                scores.append(score)\n",
        "\n",
        "            if isinstance(lead_data, pd.DataFrame) and len(lead_data) == 1:\n",
        "                return scores[0]\n",
        "\n",
        "            return np.array(scores)\n",
        "\n",
        "# Create a model interpretation function\n",
        "def interpret_prediction(lead_data, models=None):\n",
        "    \"\"\"\n",
        "    Interpret why a lead received its score by showing feature contributions\n",
        "\n",
        "    Parameters:\n",
        "    lead_data (dict): Lead data that was scored\n",
        "    models (tuple): Tuple of loaded models and preprocessing objects\n",
        "\n",
        "    Returns:\n",
        "    dict: Feature contributions to the score\n",
        "    \"\"\"\n",
        "    # Convert dict to DataFrame\n",
        "    lead_df = pd.DataFrame([lead_data])\n",
        "\n",
        "    # Add missing 'preferences_specified' column if it doesn't exist\n",
        "    if 'preferences_specified' not in lead_df.columns:\n",
        "        # Calculate preferences_specified based on the sum of preferences columns\n",
        "        lead_df['preferences_specified'] = (\n",
        "            (lead_df['food_preferences'] > 0).astype(int) +\n",
        "            (lead_df['transport_preferences'] > 0).astype(int) +\n",
        "            (lead_df['accommodation_preferences'] > 0).astype(int)\n",
        "        )\n",
        "\n",
        "    # Load models if not provided\n",
        "    if models is None:\n",
        "        _, xgb_model, _, _, _, preprocessor, _ = load_and_prepare_models()\n",
        "    else:\n",
        "        _, xgb_model, _, _, _, preprocessor, _ = models\n",
        "\n",
        "    try:\n",
        "        # Process data\n",
        "        X_processed = preprocessor.transform(lead_df)\n",
        "\n",
        "        # Check for feature mismatch\n",
        "        xgb_feature_count = xgb_model.num_features()\n",
        "        if X_processed.shape[1] != xgb_feature_count:\n",
        "            print(f\"Feature mismatch in interpretation: preprocessor produced {X_processed.shape[1]} features, XGBoost expects {xgb_feature_count}\")\n",
        "            # Use only the first xgb_feature_count features\n",
        "            X_processed = X_processed[:, :xgb_feature_count]\n",
        "\n",
        "        # Get SHAP values\n",
        "        try:\n",
        "            import shap\n",
        "            explainer = shap.TreeExplainer(xgb_model)\n",
        "            shap_values = explainer.shap_values(X_processed)\n",
        "\n",
        "            # Get feature names\n",
        "            all_feature_names = preprocessor.get_feature_names_out()\n",
        "            # Use only the first xgb_feature_count feature names\n",
        "            feature_names = all_feature_names[:xgb_feature_count]\n",
        "\n",
        "            # Create explanation dictionary\n",
        "            base_value = explainer.expected_value\n",
        "            contributions = {}\n",
        "\n",
        "            # Get top positive and negative contributions\n",
        "            shap_df = pd.DataFrame(shap_values[0], columns=feature_names)\n",
        "            shap_df['abs_value'] = abs(shap_df.values)\n",
        "\n",
        "            # Sort by absolute contribution\n",
        "            sorted_indices = shap_df['abs_value'].argsort()[::-1]\n",
        "            top_indices = sorted_indices[:10]  # Top 10 features\n",
        "\n",
        "            for idx in top_indices:\n",
        "                feature_name = feature_names[idx]\n",
        "                contribution = shap_values[0][idx]\n",
        "                contributions[feature_name] = float(contribution)\n",
        "\n",
        "            # Add overall explanation\n",
        "            explanation = {\n",
        "                'base_value': float(base_value),\n",
        "                'feature_contributions': contributions,\n",
        "                'top_positive_factors': [f for f, c in contributions.items() if c > 0][:3],\n",
        "                'top_negative_factors': [f for f, c in contributions.items() if c < 0][:3]\n",
        "            }\n",
        "\n",
        "            return explanation\n",
        "\n",
        "        except ImportError:\n",
        "            # Fallback if SHAP is not installed\n",
        "            return {\"error\": \"SHAP library not installed. Install with: pip install shap\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in interpretation: {str(e)}\")\n",
        "        # Return simplified explanation based on heuristics\n",
        "        explanation = {\n",
        "            'error': str(e),\n",
        "            'simplified_explanation': {\n",
        "                'high_value_indicators': [\n",
        "                    f\"Budget: {lead_data.get('budget', 'N/A')}\",\n",
        "                    f\"Phone provided: {lead_data.get('phone_provided', 'N/A')}\",\n",
        "                    f\"Pages visited: {lead_data.get('pages_visited', 'N/A')}\",\n",
        "                    f\"Key pages visited: {lead_data.get('key_pages_visited', 'N/A')}\"\n",
        "                ],\n",
        "                'note': \"This is a simplified explanation as the model interpretation encountered an error.\"\n",
        "            }\n",
        "        }\n",
        "        return explanation\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate a few test examples\n",
        "    test_examples = {\n",
        "        'High Value Lead': {\n",
        "            'targetCity': 'Mumbai',\n",
        "            'currentCity': 'Bangalore',\n",
        "            'startDate': 'Within 30 days',\n",
        "            'duration': '8-30 days',\n",
        "            'budget': 'High',\n",
        "            'phone_provided': 'Yes',\n",
        "            'distance': 'Long',\n",
        "            'safety': 'High',\n",
        "            'income': 'High',\n",
        "            'lifestyle': 'Luxury',\n",
        "            'pages_visited': 6,\n",
        "            'key_pages_visited': 3,\n",
        "            'food_preferences': 2,\n",
        "            'transport_preferences': 1,\n",
        "            'accommodation_preferences': 1,\n",
        "            'key_pages_ratio': 0.5,\n",
        "            'budget_income_match': 1,\n",
        "            'is_local_travel': 0,\n",
        "        },\n",
        "        'Medium Value Lead': {\n",
        "            'targetCity': 'Pune',\n",
        "            'currentCity': 'Mumbai',\n",
        "            'startDate': '31-90 days',\n",
        "            'duration': '1-7 days',\n",
        "            'budget': 'Medium',\n",
        "            'phone_provided': 'No',\n",
        "            'distance': 'Short',\n",
        "            'safety': 'Medium',\n",
        "            'income': 'Medium',\n",
        "            'lifestyle': 'Active',\n",
        "            'pages_visited': 3,\n",
        "            'key_pages_visited': 1,\n",
        "            'food_preferences': 1,\n",
        "            'transport_preferences': 1,\n",
        "            'accommodation_preferences': 0,\n",
        "            'key_pages_ratio': 0.33,\n",
        "            'budget_income_match': 1,\n",
        "            'is_local_travel': 0,\n",
        "        },\n",
        "        'Low Value Lead': {\n",
        "            'targetCity': 'Not specified',\n",
        "            'currentCity': 'Not specified',\n",
        "            'startDate': 'Not specified',\n",
        "            'duration': 'Not specified',\n",
        "            'budget': 'Low',\n",
        "            'phone_provided': 'No',\n",
        "            'distance': 'Not specified',\n",
        "            'safety': 'Not specified',\n",
        "            'income': 'Low',\n",
        "            'lifestyle': 'Budget',\n",
        "            'pages_visited': 1,\n",
        "            'key_pages_visited': 0,\n",
        "            'food_preferences': 0,\n",
        "            'transport_preferences': 0,\n",
        "            'accommodation_preferences': 0,\n",
        "            'key_pages_ratio': 0.0,\n",
        "            'budget_income_match': 1,\n",
        "            'is_local_travel': 0,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Load models once (more efficient for multiple predictions)\n",
        "    print(\"Loading models...\")\n",
        "    models = load_and_prepare_models()\n",
        "\n",
        "    # Predict scores\n",
        "    for name, data in test_examples.items():\n",
        "        score = predict_lead_score(data, models)\n",
        "        print(f\"{name}: {score:.2f}\")\n",
        "\n",
        "# Create a simple web API with Flask (Optional)\n",
        "\"\"\"\n",
        "# Uncomment and run this code separately to create a simple API\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load models at startup\n",
        "print(\"Loading models...\")\n",
        "MODELS = load_and_prepare_models()\n",
        "\n",
        "@app.route('/score', methods=['POST'])\n",
        "def score_lead():\n",
        "    try:\n",
        "        # Get JSON data from request\n",
        "        lead_data = request.json\n",
        "\n",
        "        # Predict score\n",
        "        score = predict_lead_score(lead_data, MODELS)\n",
        "\n",
        "        # Return prediction\n",
        "        return jsonify({\n",
        "            'lead_score': float(score),\n",
        "            'lead_quality': 'High' if score > 70 else 'Medium' if score > 40 else 'Low'\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, port=5000)\n",
        "\"\"\"\n",
        "\n",
        "print(\"Predictive pipeline and model interpretation functions created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lxRPlb1U0DR",
        "outputId": "0c98ebc0-b6b7-43c1-b6cd-7cc9bab37941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models...\n",
            "Error in prediction: 'XGBRegressor' object has no attribute 'num_features'\n",
            "High Value Lead: 12003.65\n",
            "Error in prediction: 'XGBRegressor' object has no attribute 'num_features'\n",
            "Medium Value Lead: 6814.12\n",
            "Error in prediction: 'XGBRegressor' object has no attribute 'num_features'\n",
            "Low Value Lead: 1072.50\n",
            "Predictive pipeline and model interpretation functions created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "class LeadScoringPipeline:\n",
        "    def __init__(self, model_paths=None):\n",
        "        \"\"\"\n",
        "        Initialize the Lead Scoring Pipeline with model paths.\n",
        "        \"\"\"\n",
        "        # Default model paths (modify if needed)\n",
        "        default_paths = {\n",
        "            'hybrid_model': 'lead_scoring_hybrid.keras',\n",
        "            'xgb_model': 'xgb_model.pkl',\n",
        "            'rf_model': 'rf_model.pkl',\n",
        "            'preprocessor': 'preprocessor.pkl',\n",
        "            'ensemble_weights': 'ensemble_weights.pkl',\n",
        "            'distilbert_model': 'distilbert_lead_scoring',\n",
        "        }\n",
        "        if model_paths:\n",
        "            default_paths.update(model_paths)\n",
        "        self.load_models(default_paths)\n",
        "\n",
        "    def load_models(self, paths):\n",
        "        \"\"\"\n",
        "        Load all required models and preprocessing objects.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load Hybrid Model\n",
        "            self.hybrid_model = load_model(paths['hybrid_model'])\n",
        "\n",
        "            # Load XGBoost Model\n",
        "            with open(paths['xgb_model'], 'rb') as f:\n",
        "                self.xgb_model = pickle.load(f)\n",
        "\n",
        "            # Load Random Forest Model\n",
        "            with open(paths['rf_model'], 'rb') as f:\n",
        "                self.rf_model = pickle.load(f)\n",
        "\n",
        "            # Load Preprocessor\n",
        "            with open(paths['preprocessor'], 'rb') as f:\n",
        "                self.preprocessor = pickle.load(f)\n",
        "\n",
        "            # Load Ensemble Weights\n",
        "            with open(paths['ensemble_weights'], 'rb') as f:\n",
        "                self.weights = pickle.load(f)\n",
        "\n",
        "            # Load DistilBERT and Tokenizer\n",
        "            self.tokenizer = DistilBertTokenizer.from_pretrained(paths['distilbert_model'])\n",
        "            self.bert_model = DistilBertForSequenceClassification.from_pretrained(paths['distilbert_model'])\n",
        "\n",
        "            # Extract feature information\n",
        "            self._extract_feature_details()\n",
        "\n",
        "            print(\"All models loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading models: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _extract_feature_details(self):\n",
        "        \"\"\"\n",
        "        Carefully extract and store feature details from the preprocessor\n",
        "        \"\"\"\n",
        "        # Categorical features with their predefined categories\n",
        "        self.categorical_features = [\n",
        "            'targetCity', 'currentCity', 'startDate', 'duration', 'budget',\n",
        "            'phone_provided', 'distance', 'safety', 'income', 'lifestyle'\n",
        "        ]\n",
        "\n",
        "        # Numerical features\n",
        "        self.numerical_features = [\n",
        "            'pages_visited', 'key_pages_visited', 'preferences_specified',\n",
        "            'food_preferences', 'transport_preferences', 'accommodation_preferences',\n",
        "            'key_pages_ratio', 'budget_income_match', 'is_local_travel'\n",
        "        ]\n",
        "\n",
        "        # Extract categories from the preprocessor\n",
        "        try:\n",
        "            encoder = self.preprocessor.named_transformers_['cat']\n",
        "            self.categorical_categories = {\n",
        "                feature: categories\n",
        "                for feature, categories in zip(self.categorical_features, encoder.categories_)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not extract categorical categories: {e}\")\n",
        "            self.categorical_categories = {}\n",
        "\n",
        "    def _prepare_input_data(self, lead_data):\n",
        "        \"\"\"\n",
        "        Prepare input data with strict feature matching and sanitization\n",
        "        \"\"\"\n",
        "        # Convert to DataFrame\n",
        "        if isinstance(lead_data, dict):\n",
        "            lead_data = pd.DataFrame([lead_data])\n",
        "\n",
        "        # Combine all required columns\n",
        "        all_required_columns = self.categorical_features + self.numerical_features\n",
        "\n",
        "        # Add missing columns with default values\n",
        "        for col in all_required_columns:\n",
        "            if col not in lead_data.columns:\n",
        "                if col in self.numerical_features:\n",
        "                    lead_data[col] = 0\n",
        "                else:\n",
        "                    lead_data[col] = 'Not specified'\n",
        "\n",
        "        # Ensure correct column order\n",
        "        lead_data = lead_data[all_required_columns]\n",
        "\n",
        "        # Sanitize categorical features\n",
        "        for col in self.categorical_features:\n",
        "            # Get allowed categories for this feature\n",
        "            allowed_categories = self.categorical_categories.get(col, [])\n",
        "\n",
        "            # If no predefined categories, use unique values from training\n",
        "            if not allowed_categories:\n",
        "                allowed_categories = ['Not specified']\n",
        "\n",
        "            # Replace with 'Not specified' if not in allowed categories\n",
        "            lead_data[col] = lead_data[col].apply(\n",
        "                lambda x: x if x in allowed_categories else 'Not specified'\n",
        "            )\n",
        "\n",
        "        return lead_data\n",
        "\n",
        "    def predict_lead_score(self, lead_data):\n",
        "        \"\"\"\n",
        "        Predict lead score with comprehensive error handling\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Prepare and sanitize input data\n",
        "            processed_data = self._prepare_input_data(lead_data)\n",
        "\n",
        "            # Transform data\n",
        "            try:\n",
        "                X_processed = self.preprocessor.transform(processed_data)\n",
        "\n",
        "                # Verify feature count\n",
        "                expected_features = 64  # Hardcoded expected feature count\n",
        "                if X_processed.shape[1] != expected_features:\n",
        "                    print(f\"Feature count mismatch. Expected {expected_features}, got {X_processed.shape[1]}\")\n",
        "\n",
        "                    # Attempt to truncate or pad features\n",
        "                    if X_processed.shape[1] > expected_features:\n",
        "                        X_processed = X_processed[:, :expected_features]\n",
        "                    else:\n",
        "                        # Pad with zeros if fewer features\n",
        "                        padding = np.zeros((X_processed.shape[0], expected_features - X_processed.shape[1]))\n",
        "                        X_processed = np.hstack([X_processed, padding])\n",
        "\n",
        "            except ValueError as e:\n",
        "                print(\"Preprocessing error:\", e)\n",
        "                raise\n",
        "\n",
        "            # Reshape for hybrid model\n",
        "            X_reshaped = X_processed.reshape((X_processed.shape[0], X_processed.shape[1], 1))\n",
        "\n",
        "            # Predict with individual models\n",
        "            hybrid_pred = self.hybrid_model.predict(X_reshaped).flatten()\n",
        "            xgb_pred = self.xgb_model.predict(X_processed)\n",
        "            rf_pred = self.rf_model.predict(X_processed)\n",
        "\n",
        "            # Prepare text for DistilBERT\n",
        "            text_data = [\n",
        "                f\"Target City: {row['targetCity']} \"\n",
        "                f\"Current City: {row['currentCity']} \"\n",
        "                f\"Start Date: {row['startDate']} \"\n",
        "                f\"Duration: {row['duration']} \"\n",
        "                f\"Budget: {row['budget']} \"\n",
        "                f\"Phone: {row['phone_provided']} \"\n",
        "                f\"Distance: {row['distance']} \"\n",
        "                f\"Safety: {row['safety']} \"\n",
        "                f\"Income: {row['income']} \"\n",
        "                f\"Lifestyle: {row['lifestyle']} \"\n",
        "                f\"Pages: {row['pages_visited']} \"\n",
        "                f\"Key Pages: {row['key_pages_visited']} \"\n",
        "                f\"Preferences: {row['preferences_specified']}\"\n",
        "                for _, row in processed_data.iterrows()\n",
        "            ]\n",
        "\n",
        "            # Tokenize and get DistilBERT prediction\n",
        "            encodings = self.tokenizer(text_data, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "            with torch.no_grad():\n",
        "                bert_output = self.bert_model(**encodings)\n",
        "                bert_pred = bert_output.logits.numpy().flatten()\n",
        "\n",
        "            # Ensemble predictions\n",
        "            ensemble_pred = (\n",
        "                self.weights[0] * hybrid_pred +\n",
        "                self.weights[1] * xgb_pred +\n",
        "                self.weights[2] * rf_pred +\n",
        "                self.weights[3] * bert_pred\n",
        "            )\n",
        "\n",
        "            return ensemble_pred[0] if len(ensemble_pred) == 1 else ensemble_pred\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Comprehensive prediction error: {e}\")\n",
        "            raise\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    test_examples = [\n",
        "        {\n",
        "            'targetCity': 'Mumbai',\n",
        "            'currentCity': 'Bangalore',\n",
        "            'startDate': 'Within 30 days',\n",
        "            'duration': '8-30 days',\n",
        "            'budget': 'High',\n",
        "            'phone_provided': 'Yes',\n",
        "            'distance': 'Long',\n",
        "            'safety': 'High',\n",
        "            'income': 'High',\n",
        "            'lifestyle': 'Luxury',\n",
        "            'pages_visited': 6,\n",
        "            'key_pages_visited': 3,\n",
        "            'preferences_specified': 4,\n",
        "            'food_preferences': 2,\n",
        "            'transport_preferences': 1,\n",
        "            'accommodation_preferences': 1,\n",
        "            'key_pages_ratio': 0.5,\n",
        "            'budget_income_match': 1,\n",
        "            'is_local_travel': 0,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    pipeline = LeadScoringPipeline()\n",
        "    for data in test_examples:\n",
        "        try:\n",
        "            score = pipeline.predict_lead_score(data)\n",
        "            print(f\"Lead Score: {score:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(\"Prediction error:\", e)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "-q85Yi_rakHa",
        "outputId": "99c94072-2920-46a9-b9f1-d832244828b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function AtomicFunction.__del__ at 0x7a93afda32e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 286, in __del__\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'gradio' has no attribute 'inputs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0dc1c10f185d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradio_predict_lead_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     inputs=[\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Target City\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Current City\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Within 30 days\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"31-90 days\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not specified\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Start Date\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gradio' has no attribute 'inputs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmGVB-Hlgghf",
        "outputId": "28b0ce2b-90ef-4206-b3b8-418110793689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.43.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.30.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.43.2-py2.py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.43.2 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5cdgnvWn4BE",
        "outputId": "6a555dc7-c6ca-469e-d75f-39c209ca890c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.22.0-py3-none-any.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.22.0 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.0 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "from tensorflow.keras.models import load_model\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "\n",
        "# Load and Prepare Models Function\n",
        "def load_and_prepare_models():\n",
        "    # Load hybrid model\n",
        "    hybrid_model = load_model('lead_scoring_hybrid.keras')\n",
        "\n",
        "    # Load XGBoost model\n",
        "    with open('xgb_model.pkl', 'rb') as f:\n",
        "        xgb_model = pickle.load(f)\n",
        "\n",
        "    # Load Random Forest model\n",
        "    with open('rf_model.pkl', 'rb') as f:\n",
        "        rf_model = pickle.load(f)\n",
        "\n",
        "    # Load DistilBERT model and tokenizer\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert_lead_scoring')\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert_lead_scoring')\n",
        "\n",
        "    # Load preprocessor\n",
        "    with open('preprocessor.pkl', 'rb') as f:\n",
        "        preprocessor = pickle.load(f)\n",
        "\n",
        "    # Load ensemble weights\n",
        "    with open('ensemble_weights.pkl', 'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "\n",
        "    return hybrid_model, xgb_model, rf_model, model, tokenizer, preprocessor, weights\n",
        "\n",
        "# Categorical Options\n",
        "CATEGORICAL_OPTIONS = {\n",
        "    'targetCity': ['Mumbai', 'Bangalore', 'Delhi', 'Pune', 'Chennai', 'Hyderabad', 'Kolkata', 'Not specified'],\n",
        "    'currentCity': ['Mumbai', 'Bangalore', 'Delhi', 'Pune', 'Chennai', 'Hyderabad', 'Kolkata', 'Not specified'],\n",
        "    'startDate': ['Within 30 days', '31-90 days', 'More than 90 days', 'Not specified'],\n",
        "    'duration': ['1-7 days', '8-30 days', 'More than 30 days', 'Not specified'],\n",
        "    'budget': ['High', 'Medium', 'Low', 'Not specified'],\n",
        "    'phone_provided': ['Yes', 'No'],\n",
        "    'distance': ['Long', 'Medium', 'Short', 'Not specified'],\n",
        "    'safety': ['High', 'Medium', 'Low', 'Not specified'],\n",
        "    'income': ['High', 'Medium', 'Low', 'Not specified'],\n",
        "    'lifestyle': ['Luxury', 'Active', 'Relaxed', 'Budget']\n",
        "}\n",
        "\n",
        "# Random Generation Function\n",
        "def generate_random_lead():\n",
        "    return [\n",
        "        random.choice(CATEGORICAL_OPTIONS['targetCity']),\n",
        "        random.choice(CATEGORICAL_OPTIONS['currentCity']),\n",
        "        random.choice(CATEGORICAL_OPTIONS['startDate']),\n",
        "        random.choice(CATEGORICAL_OPTIONS['duration']),\n",
        "        random.choice(CATEGORICAL_OPTIONS['budget']),\n",
        "        random.choice(CATEGORICAL_OPTIONS['phone_provided']),\n",
        "        random.choice(CATEGORICAL_OPTIONS['distance']),\n",
        "        random.choice(CATEGORICAL_OPTIONS['safety']),\n",
        "        random.choice(CATEGORICAL_OPTIONS['income']),\n",
        "        random.choice(CATEGORICAL_OPTIONS['lifestyle']),\n",
        "        round(random.uniform(0, 10), 2),  # pages_visited\n",
        "        round(random.uniform(0, 5), 2),   # key_pages_visited\n",
        "        round(random.uniform(0, 3), 2),   # food_preferences\n",
        "        round(random.uniform(0, 3), 2),   # transport_preferences\n",
        "        round(random.uniform(0, 3), 2),   # accommodation_preferences\n",
        "        round(random.uniform(0, 1), 2),   # key_pages_ratio\n",
        "        random.randint(0, 1),             # budget_income_match\n",
        "        random.randint(0, 1)              # is_local_travel\n",
        "    ]\n",
        "\n",
        "# Prediction Function\n",
        "def predict_lead_score(\n",
        "    targetCity, currentCity, startDate, duration, budget,\n",
        "    phone_provided, distance, safety, income, lifestyle,\n",
        "    pages_visited, key_pages_visited, food_preferences,\n",
        "    transport_preferences, accommodation_preferences,\n",
        "    key_pages_ratio, budget_income_match, is_local_travel\n",
        "):\n",
        "    # Prepare input data\n",
        "    lead_data = pd.DataFrame({\n",
        "        'targetCity': [targetCity],\n",
        "        'currentCity': [currentCity],\n",
        "        'startDate': [startDate],\n",
        "        'duration': [duration],\n",
        "        'budget': [budget],\n",
        "        'phone_provided': [phone_provided],\n",
        "        'distance': [distance],\n",
        "        'safety': [safety],\n",
        "        'income': [income],\n",
        "        'lifestyle': [lifestyle],\n",
        "        'pages_visited': [pages_visited],\n",
        "        'key_pages_visited': [key_pages_visited],\n",
        "        'food_preferences': [food_preferences],\n",
        "        'transport_preferences': [transport_preferences],\n",
        "        'accommodation_preferences': [accommodation_preferences],\n",
        "        'key_pages_ratio': [key_pages_ratio],\n",
        "        'budget_income_match': [budget_income_match],\n",
        "        'is_local_travel': [is_local_travel]\n",
        "    })\n",
        "\n",
        "    # Add preferences_specified column\n",
        "    lead_data['preferences_specified'] = (\n",
        "        (lead_data['food_preferences'] > 0).astype(int) +\n",
        "        (lead_data['transport_preferences'] > 0).astype(int) +\n",
        "        (lead_data['accommodation_preferences'] > 0).astype(int)\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Load models\n",
        "        models = load_and_prepare_models()\n",
        "        hybrid_model, xgb_model, rf_model, bert_model, tokenizer, preprocessor, weights = models\n",
        "\n",
        "        # Process numerical and categorical features\n",
        "        X_processed = preprocessor.transform(lead_data)\n",
        "\n",
        "        # Check for feature mismatch and handle it\n",
        "        expected_feature_count = 64  # Replace with the actual number of features used in training\n",
        "        if X_processed.shape[1] != expected_feature_count:\n",
        "            print(f\"Feature mismatch: preprocessor produced {X_processed.shape[1]} features, expected {expected_feature_count}\")\n",
        "\n",
        "            # Truncate or pad features if necessary\n",
        "            if X_processed.shape[1] > expected_feature_count:\n",
        "                X_processed = X_processed[:, :expected_feature_count]\n",
        "            else:\n",
        "                # Pad with zeros if fewer features\n",
        "                padding = np.zeros((X_processed.shape[0], expected_feature_count - X_processed.shape[1]))\n",
        "                X_processed = np.hstack([X_processed, padding])\n",
        "\n",
        "        # For hybrid model, reshape as needed\n",
        "        X_reshaped = X_processed.reshape((X_processed.shape[0], X_processed.shape[1], 1))\n",
        "\n",
        "        # Get predictions from hybrid model\n",
        "        hybrid_pred = hybrid_model.predict(X_reshaped).flatten()\n",
        "\n",
        "        # Get predictions from XGBoost and Random Forest\n",
        "        xgb_pred = xgb_model.predict(X_processed)\n",
        "        rf_pred = rf_model.predict(X_processed)\n",
        "\n",
        "        # Format text for DistilBERT\n",
        "        text_data = [\n",
        "            f\"Target City: {targetCity}, Current City: {currentCity}, \"\n",
        "            f\"Start Date: {startDate}, Duration: {duration}, \"\n",
        "            f\"Budget: {budget}, Phone Provided: {phone_provided}, \"\n",
        "            f\"Distance: {distance}, Safety: {safety}, \"\n",
        "            f\"Income: {income}, Lifestyle: {lifestyle}, \"\n",
        "            f\"Pages Visited: {pages_visited}, Key Pages: {key_pages_visited}\"\n",
        "        ]\n",
        "\n",
        "        # Tokenize text\n",
        "        encodings = tokenizer(text_data, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "        # Get DistilBERT predictions\n",
        "        with torch.no_grad():\n",
        "            bert_output = bert_model(**encodings)\n",
        "            bert_pred = bert_output.logits.numpy().flatten()\n",
        "\n",
        "        # Combine predictions using ensemble weights\n",
        "        ensemble_pred = (\n",
        "            weights[0] * hybrid_pred +\n",
        "            weights[1] * xgb_pred +\n",
        "            weights[2] * rf_pred +\n",
        "            weights[3] * bert_pred\n",
        "        )\n",
        "\n",
        "        # Round and determine quality\n",
        "        score = round(float(ensemble_pred[0]), 2)\n",
        "\n",
        "        if score > 70:\n",
        "            quality = \"High Quality Lead 🌟\"\n",
        "            color = \"green\"\n",
        "        elif score > 40:\n",
        "            quality = \"Medium Quality Lead 🔍\"\n",
        "            color = \"orange\"\n",
        "        else:\n",
        "            quality = \"Low Quality Lead ❗\"\n",
        "            color = \"red\"\n",
        "\n",
        "        return f\"Lead Score: {score}\\nQuality: {quality}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Prediction Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio Interface\n",
        "def create_gradio_interface():\n",
        "    # Create input components\n",
        "    inputs = [\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['targetCity'], label=\"Target City\"),\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['currentCity'], label=\"Current City\"),\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['startDate'], label=\"Start Date\"),\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['duration'], label=\"Duration\"),\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['budget'], label=\"Budget\"),\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['phone_provided'], label=\"Phone Provided\"),\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['distance'], label=\"Distance\"),\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['safety'], label=\"Safety\"),\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['income'], label=\"Income\"),\n",
        "        gr.Dropdown(CATEGORICAL_OPTIONS['lifestyle'], label=\"Lifestyle\"),\n",
        "        gr.Number(label=\"Pages Visited\", minimum=0, maximum=10),\n",
        "        gr.Number(label=\"Key Pages Visited\", minimum=0, maximum=10),\n",
        "        gr.Number(label=\"Food Preferences\", minimum=0, maximum=10),\n",
        "        gr.Number(label=\"Transport Preferences\", minimum=0, maximum=10),\n",
        "        gr.Number(label=\"Accommodation Preferences\", minimum=0, maximum=10),\n",
        "        gr.Number(label=\"Key Pages Ratio\", minimum=0, maximum=1),\n",
        "        gr.Number(label=\"Budget Income Match\", minimum=0, maximum=1),\n",
        "        gr.Number(label=\"Is Local Travel\", minimum=0, maximum=1)\n",
        "    ]\n",
        "\n",
        "    # Create Gradio Blocks for more flexibility\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🚀 Lead Scoring Predictor\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                # Input components\n",
        "                input_components = [gr.Dropdown(choices, label=label) if isinstance(choices, list) else gr.Number()\n",
        "                                    for choices, label in zip(\n",
        "                                        list(CATEGORICAL_OPTIONS.values()) + [None]*8,\n",
        "                                        [k for k in CATEGORICAL_OPTIONS.keys()] +\n",
        "                                        [\"Pages Visited\", \"Key Pages Visited\", \"Food Preferences\",\n",
        "                                         \"Transport Preferences\", \"Accommodation Preferences\",\n",
        "                                         \"Key Pages Ratio\", \"Budget Income Match\", \"Is Local Travel\"]\n",
        "                                    )]\n",
        "\n",
        "                # Predict button\n",
        "                predict_btn = gr.Button(\"Predict Lead Score\")\n",
        "\n",
        "                # Random Generation button\n",
        "                random_btn = gr.Button(\"Generate Random Lead\")\n",
        "\n",
        "            with gr.Column():\n",
        "                # Output component\n",
        "                output = gr.Textbox(label=\"Prediction Result\")\n",
        "\n",
        "        # Random generation event\n",
        "        random_btn.click(\n",
        "            fn=generate_random_lead,\n",
        "            outputs=input_components\n",
        "        )\n",
        "\n",
        "        # Prediction event\n",
        "        predict_btn.click(\n",
        "            fn=predict_lead_score,\n",
        "            inputs=input_components,\n",
        "            outputs=output\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    interface = create_gradio_interface()\n",
        "    interface.launch(share=True)\n",
        "\n",
        "# Run the app\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DG_KbjdSgbAt",
        "outputId": "d6f0a796-4041-497b-c7a2-83e0b0b05aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/utils.py:1024: UserWarning: Expected 18 arguments for function <function gradio_predict_lead_score at 0x7a90b2264540>, received 15.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/utils.py:1028: UserWarning: Expected at least 18 arguments for function <function gradio_predict_lead_score at 0x7a90b2264540>, received 15.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1c54f79ac5a1fd1b88.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1c54f79ac5a1fd1b88.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1c54f79ac5a1fd1b88.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1c54f79ac5a1fd1b88.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tensorflow.keras.models import load_model\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "# ---------------------------\n",
        "# Your existing functions\n",
        "# ---------------------------\n",
        "def load_and_prepare_models():\n",
        "    # Load hybrid model\n",
        "    hybrid_model = load_model('lead_scoring_hybrid.keras')\n",
        "\n",
        "    # Load XGBoost model\n",
        "    with open('xgb_model.pkl', 'rb') as f:\n",
        "        xgb_model = pickle.load(f)\n",
        "\n",
        "    # Load Random Forest model\n",
        "    with open('rf_model.pkl', 'rb') as f:\n",
        "        rf_model = pickle.load(f)\n",
        "\n",
        "    # Load DistilBERT model and tokenizer\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert_lead_scoring')\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert_lead_scoring')\n",
        "\n",
        "    # Load preprocessor\n",
        "    with open('preprocessor.pkl', 'rb') as f:\n",
        "        preprocessor = pickle.load(f)\n",
        "\n",
        "    # Load ensemble weights\n",
        "    with open('ensemble_weights.pkl', 'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "\n",
        "    return hybrid_model, xgb_model, rf_model, model, tokenizer, preprocessor, weights\n",
        "\n",
        "def predict_lead_score(lead_data, models=None):\n",
        "    \"\"\"\n",
        "    Predict lead score for a single lead record or a dataframe of leads\n",
        "\n",
        "    Parameters:\n",
        "    lead_data (dict or pd.DataFrame): Lead data to score\n",
        "    models (tuple): Tuple of loaded models and preprocessing objects\n",
        "\n",
        "    Returns:\n",
        "    float or np.array: Predicted lead score(s)\n",
        "    \"\"\"\n",
        "    if isinstance(lead_data, dict):\n",
        "        lead_data = pd.DataFrame([lead_data])\n",
        "\n",
        "    if models is None:\n",
        "        hybrid_model, xgb_model, rf_model, bert_model, tokenizer, preprocessor, weights = load_and_prepare_models()\n",
        "    else:\n",
        "        hybrid_model, xgb_model, rf_model, bert_model, tokenizer, preprocessor, weights = models\n",
        "\n",
        "    if 'preferences_specified' not in lead_data.columns:\n",
        "        lead_data['preferences_specified'] = (\n",
        "            (lead_data['food_preferences'] > 0).astype(int) +\n",
        "            (lead_data['transport_preferences'] > 0).astype(int) +\n",
        "            (lead_data['accommodation_preferences'] > 0).astype(int)\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        X_processed = preprocessor.transform(lead_data)\n",
        "        xgb_feature_count = xgb_model.num_features()\n",
        "        if X_processed.shape[1] != xgb_feature_count:\n",
        "            print(f\"Feature mismatch: preprocessor produced {X_processed.shape[1]} features, but XGBoost expects {xgb_feature_count}\")\n",
        "            X_processed_xgb = X_processed[:, :xgb_feature_count]\n",
        "        else:\n",
        "            X_processed_xgb = X_processed\n",
        "        X_reshaped = X_processed.reshape((X_processed.shape[0], X_processed.shape[1], 1))\n",
        "        hybrid_pred = hybrid_model.predict(X_reshaped).flatten()\n",
        "        xgb_pred = xgb_model.predict(X_processed_xgb)\n",
        "        rf_pred = rf_model.predict(X_processed_xgb)\n",
        "\n",
        "        text_data = []\n",
        "        for _, row in lead_data.iterrows():\n",
        "            text = (\n",
        "                f\"Target City: {row['targetCity']}, Current City: {row['currentCity']}, \"\n",
        "                f\"Start Date: {row['startDate']}, Duration: {row['duration']}, \"\n",
        "                f\"Budget: {row['budget']}, Phone Provided: {row['phone_provided']}, \"\n",
        "                f\"Distance: {row['distance']}, Safety: {row['safety']}, \"\n",
        "                f\"Income: {row['income']}, Lifestyle: {row['lifestyle']}, \"\n",
        "                f\"Pages Visited: {row['pages_visited']}, Key Pages: {row['key_pages_visited']}, \"\n",
        "                f\"Food Preferences: {row['food_preferences']}, Transport: {row['transport_preferences']}, \"\n",
        "                f\"Accommodation: {row['accommodation_preferences']}\"\n",
        "            )\n",
        "            text_data.append(text)\n",
        "\n",
        "        encodings = tokenizer(text_data, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            bert_output = bert_model(**encodings)\n",
        "            bert_pred = bert_output.logits.numpy().flatten()\n",
        "\n",
        "        ensemble_pred = (\n",
        "            weights[0] * hybrid_pred +\n",
        "            weights[1] * xgb_pred +\n",
        "            weights[2] * rf_pred +\n",
        "            weights[3] * bert_pred\n",
        "        )\n",
        "\n",
        "        if isinstance(lead_data, pd.DataFrame) and len(lead_data) == 1:\n",
        "            return ensemble_pred[0]\n",
        "        return ensemble_pred\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in prediction: {str(e)}\")\n",
        "        try:\n",
        "            text_data = []\n",
        "            for _, row in lead_data.iterrows():\n",
        "                text = (\n",
        "                    f\"Target City: {row['targetCity']}, Current City: {row['currentCity']}, \"\n",
        "                    f\"Start Date: {row['startDate']}, Duration: {row['duration']}, \"\n",
        "                    f\"Budget: {row['budget']}, Phone Provided: {row['phone_provided']}, \"\n",
        "                    f\"Pages Visited: {row['pages_visited']}, Key Pages: {row['key_pages_visited']}\"\n",
        "                )\n",
        "                text_data.append(text)\n",
        "\n",
        "            encodings = tokenizer(text_data, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "            with torch.no_grad():\n",
        "                bert_output = bert_model(**encodings)\n",
        "                bert_pred = bert_output.logits.numpy().flatten()\n",
        "\n",
        "            scaled_pred = bert_pred * 100\n",
        "            if isinstance(lead_data, pd.DataFrame) and len(lead_data) == 1:\n",
        "                return float(scaled_pred[0])\n",
        "            return scaled_pred\n",
        "\n",
        "        except Exception as fallback_error:\n",
        "            print(f\"Fallback prediction failed: {str(fallback_error)}\")\n",
        "            scores = []\n",
        "            for _, row in lead_data.iterrows():\n",
        "                score = 0\n",
        "                if row['budget'] == 'High':\n",
        "                    score += 30\n",
        "                elif row['budget'] == 'Medium':\n",
        "                    score += 20\n",
        "                else:\n",
        "                    score += 10\n",
        "                if row['phone_provided'] == 'Yes':\n",
        "                    score += 15\n",
        "                score += min(row['pages_visited'] * 2, 20)\n",
        "                score += min(row['key_pages_visited'] * 5, 25)\n",
        "                scores.append(score)\n",
        "            if isinstance(lead_data, pd.DataFrame) and len(lead_data) == 1:\n",
        "                return scores[0]\n",
        "            return np.array(scores)\n",
        "\n",
        "# ---------------------------\n",
        "# Gradio UI Integration\n",
        "# ---------------------------\n",
        "# Load models once for efficiency\n",
        "models = load_and_prepare_models()\n",
        "\n",
        "def predict_from_ui(\n",
        "    targetCity, currentCity, startDate, duration, budget, phone_provided, distance,\n",
        "    safety, income, lifestyle, pages_visited, key_pages_visited, food_preferences,\n",
        "    transport_preferences, accommodation_preferences, key_pages_ratio, budget_income_match,\n",
        "    is_local_travel\n",
        "):\n",
        "    # Prepare input as a dictionary\n",
        "    input_data = {\n",
        "        'targetCity': targetCity,\n",
        "        'currentCity': currentCity,\n",
        "        'startDate': startDate,\n",
        "        'duration': duration,\n",
        "        'budget': budget,\n",
        "        'phone_provided': phone_provided,\n",
        "        'distance': distance,\n",
        "        'safety': safety,\n",
        "        'income': income,\n",
        "        'lifestyle': lifestyle,\n",
        "        'pages_visited': pages_visited,\n",
        "        'key_pages_visited': key_pages_visited,\n",
        "        'food_preferences': food_preferences,\n",
        "        'transport_preferences': transport_preferences,\n",
        "        'accommodation_preferences': accommodation_preferences,\n",
        "        'key_pages_ratio': key_pages_ratio,\n",
        "        'budget_income_match': budget_income_match,\n",
        "        'is_local_travel': is_local_travel\n",
        "    }\n",
        "    score = predict_lead_score(input_data, models)\n",
        "    return score\n",
        "\n",
        "def generate_random_input():\n",
        "    # Generate random values for each field\n",
        "    targetCity = random.choice([\"Mumbai\", \"Pune\", \"Delhi\", \"Not specified\"])\n",
        "    currentCity = random.choice([\"Bangalore\", \"Mumbai\", \"Chennai\", \"Not specified\"])\n",
        "    startDate = random.choice([\"Within 30 days\", \"31-90 days\", \"Not specified\"])\n",
        "    duration = random.choice([\"8-30 days\", \"1-7 days\", \"Not specified\"])\n",
        "    budget = random.choice([\"High\", \"Medium\", \"Low\"])\n",
        "    phone_provided = random.choice([\"Yes\", \"No\"])\n",
        "    distance = random.choice([\"Long\", \"Short\", \"Not specified\"])\n",
        "    safety = random.choice([\"High\", \"Medium\", \"Not specified\"])\n",
        "    income = random.choice([\"High\", \"Medium\", \"Low\"])\n",
        "    lifestyle = random.choice([\"Luxury\", \"Active\", \"Budget\"])\n",
        "    pages_visited = random.randint(0, 10)\n",
        "    key_pages_visited = random.randint(0, 5)\n",
        "    food_preferences = random.randint(0, 3)\n",
        "    transport_preferences = random.randint(0, 3)\n",
        "    accommodation_preferences = random.randint(0, 3)\n",
        "    key_pages_ratio = round(random.uniform(0, 1), 2)\n",
        "    budget_income_match = random.choice([0, 1])\n",
        "    is_local_travel = random.choice([0, 1])\n",
        "\n",
        "    return (targetCity, currentCity, startDate, duration, budget, phone_provided, distance,\n",
        "            safety, income, lifestyle, pages_visited, key_pages_visited, food_preferences,\n",
        "            transport_preferences, accommodation_preferences, key_pages_ratio, budget_income_match,\n",
        "            is_local_travel)\n",
        "\n",
        "# Define the Gradio interface layout\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Lead Scoring Prediction UI\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            targetCity_input = gr.Textbox(label=\"Target City\", value=\"Mumbai\")\n",
        "            currentCity_input = gr.Textbox(label=\"Current City\", value=\"Bangalore\")\n",
        "            startDate_input = gr.Textbox(label=\"Start Date\", value=\"Within 30 days\")\n",
        "            duration_input = gr.Textbox(label=\"Duration\", value=\"8-30 days\")\n",
        "            budget_input = gr.Dropdown(label=\"Budget\", choices=[\"High\", \"Medium\", \"Low\"], value=\"High\")\n",
        "            phone_input = gr.Dropdown(label=\"Phone Provided\", choices=[\"Yes\", \"No\"], value=\"Yes\")\n",
        "            distance_input = gr.Textbox(label=\"Distance\", value=\"Long\")\n",
        "            safety_input = gr.Textbox(label=\"Safety\", value=\"High\")\n",
        "            income_input = gr.Textbox(label=\"Income\", value=\"High\")\n",
        "            lifestyle_input = gr.Textbox(label=\"Lifestyle\", value=\"Luxury\")\n",
        "        with gr.Column():\n",
        "            pages_visited_input = gr.Slider(label=\"Pages Visited\", minimum=0, maximum=10, step=1, value=6)\n",
        "            key_pages_visited_input = gr.Slider(label=\"Key Pages Visited\", minimum=0, maximum=5, step=1, value=3)\n",
        "            food_preferences_input = gr.Slider(label=\"Food Preferences\", minimum=0, maximum=3, step=1, value=2)\n",
        "            transport_preferences_input = gr.Slider(label=\"Transport Preferences\", minimum=0, maximum=3, step=1, value=1)\n",
        "            accommodation_preferences_input = gr.Slider(label=\"Accommodation Preferences\", minimum=0, maximum=3, step=1, value=1)\n",
        "            key_pages_ratio_input = gr.Slider(label=\"Key Pages Ratio\", minimum=0, maximum=1, step=0.01, value=0.5)\n",
        "            budget_income_match_input = gr.Radio(label=\"Budget Income Match\", choices=[0, 1], value=1)\n",
        "            is_local_travel_input = gr.Radio(label=\"Is Local Travel\", choices=[0, 1], value=0)\n",
        "\n",
        "    predict_button = gr.Button(\"Predict Lead Score\")\n",
        "    random_button = gr.Button(\"Generate Random Input\")\n",
        "    output_text = gr.Textbox(label=\"Predicted Lead Score\")\n",
        "\n",
        "    predict_button.click(\n",
        "        predict_from_ui,\n",
        "        inputs=[targetCity_input, currentCity_input, startDate_input, duration_input, budget_input, phone_input,\n",
        "                distance_input, safety_input, income_input, lifestyle_input, pages_visited_input, key_pages_visited_input,\n",
        "                food_preferences_input, transport_preferences_input, accommodation_preferences_input, key_pages_ratio_input,\n",
        "                budget_income_match_input, is_local_travel_input],\n",
        "        outputs=output_text\n",
        "    )\n",
        "\n",
        "    random_button.click(\n",
        "        generate_random_input,\n",
        "        outputs=[targetCity_input, currentCity_input, startDate_input, duration_input, budget_input, phone_input,\n",
        "                 distance_input, safety_input, income_input, lifestyle_input, pages_visited_input, key_pages_visited_input,\n",
        "                 food_preferences_input, transport_preferences_input, accommodation_preferences_input, key_pages_ratio_input,\n",
        "                 budget_income_match_input, is_local_travel_input]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "wKOFmy652gKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}